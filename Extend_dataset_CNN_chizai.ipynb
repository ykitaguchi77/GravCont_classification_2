{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled37.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_2/blob/main/Extend_dataset_CNN_chizai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GO extend datasetMobileNet_for_chizai**"
      ],
      "metadata": {
        "id": "LXR--60tO5mS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5xvbecME5IS",
        "outputId": "f17cdc89-ae82-4139-a834-0715ac847bc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "!pip install albumentations==0.4.6\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "random_seed = 3 #shuffleのシード\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "!nvidia-smi\n",
        "print(torch.cuda.is_available())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m61.4/61.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer) (2.0.1+cu118)\n",
            "Collecting pytorch-ranger>=0.1.1 (from torch_optimizer)\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->torch_optimizer) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->torch_optimizer) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torch_optimizer) (1.3.0)\n",
            "Installing collected packages: pytorch-ranger, torch_optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch_optimizer-0.3.0\n",
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (1.11.3)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (6.0.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (4.8.0.76)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.19.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.31.5)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.0.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (23.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65151 sha256=43a2fb317812fdb8779ced09ed40a00548d993bdc991603285d2cf6adc3cbeae\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/d7/0c/6ed42fd872f7d1af78b25045f8b16be330f2c70ae72c83e37d\n",
            "Successfully built albumentations\n",
            "Installing collected packages: albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.3.1\n",
            "    Uninstalling albumentations-1.3.1:\n",
            "      Successfully uninstalled albumentations-1.3.1\n",
            "Successfully installed albumentations-0.4.6\n",
            "Mon Oct 16 07:29:23 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0ZI4pHmFDXZ"
      },
      "source": [
        "#Google colabをマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkrhEditFGkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7eb3474-5070-4e19-e36d-ab50cb6a162d"
      },
      "source": [
        "'''\n",
        "・dlibを用いて目を切り抜く\n",
        "・横幅を2倍、縦幅を上に1倍追加/下に0.5倍追加した両眼の画像が含まれるように切り取る（目の全幅、眉毛が含まれるように）\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7fAuwXxNka"
      },
      "source": [
        "#残り時間確認\n",
        "!cat /proc/uptime | awk '{printf(\"残り時間 : %.2f\", 12-$1/60/60)}'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSfusHMWPL6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSA2Rm9MFXoZ"
      },
      "source": [
        "# # GO_extended_datasetを colab上のフォルダに展開\n",
        "# zip_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip'\n",
        "# !unzip $zip_path -d \"/content\"\n",
        "# in_path_list  = ['/content/GO_extended_dataset/Control_photo_1886mai', '/content/GO_extended_dataset/treatable']\n",
        "# #保存先フォルダ\n",
        "# out_path_list = ['/content/GO_extended_dataset/cont', '/content/GO_extended_dataset/grav']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MobileNetV3 training用フォルダを作成**\n",
        "\n",
        "datasetをtrainとvalに分ける\n",
        "\n",
        "https://book.st-hakky.com/docs/object-detection-yolov5-tutorial/\n",
        "\n"
      ],
      "metadata": {
        "id": "VPi74ZCZrVDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# periocular_for_YOLOフォルダにすでに展開されているデータセットを用いる\n",
        "dataset_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO\"\n",
        "\n",
        "# def split_dataset(dataset_dir):\n",
        "#     img_list = glob.glob(f\"{dataset_dir}/images/*\")\n",
        "#     img_train, img_test = train_test_split(img_list, test_size=0.3, random_state=0)\n",
        "\n",
        "#     # img_train, img_testに名前が一致するtxtファイルを抜き出す\n",
        "#     label_train = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_train]\n",
        "#     label_test = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_test]\n",
        "\n",
        "#     print(f\"train: {len(label_train)},test: {len(label_test)}\")\n",
        "\n",
        "#     return img_train, img_test, label_train, label_test\n",
        "\n",
        "def make_path_list(dir, class_name):\n",
        "    image_list =  [file for file in glob.glob(f\"{dir}/{class_name}/images/*\") if os.path.isfile(file) == True ]\n",
        "    label_list =  [f\"{dir}/{class_name}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in image_list]\n",
        "\n",
        "    id_list = [os.path.basename(i).split(\"-\")[0].split(\".\")[0] for i in image_list]\n",
        "\n",
        "    index = {}\n",
        "    id_idx = []\n",
        "    for item in id_list:\n",
        "        if item in index:\n",
        "            id_idx.append(index[item])\n",
        "        else:\n",
        "            index[item] = len(index) + 1\n",
        "            id_idx.append(index[item])\n",
        "    id_idx = [int(i) for i in id_idx]\n",
        "\n",
        "    return image_list, label_list, id_idx\n",
        "\n",
        "grav_image_list, grav_label_list, grav_id_idx = make_path_list(dataset_dir, \"grav\")\n",
        "cont_image_list, cont_label_list, cont_id_idx = make_path_list(dataset_dir, \"cont\")\n",
        "\n",
        "print(f\"grav: {len(grav_image_list)}\")\n",
        "print(f\"cont: {len(cont_image_list)}\")"
      ],
      "metadata": {
        "id": "hHiTlYEnLx_u",
        "outputId": "771eccc4-1fb9-48c6-98cf-0e38ac55373e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 1657\n",
            "cont: 1656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "# ディレクトリのパス\n",
        "directory_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO/cont/images_cropped\"\n",
        "\n",
        "# ディレクトリ内のjpgファイルをリストアップ\n",
        "jpg_files = [f for f in os.listdir(directory_path) if f.endswith('.JPG')]\n",
        "\n",
        "# 1つのjpgファイルを表示\n",
        "if len(jpg_files) > 0:\n",
        "    file_to_display = jpg_files[0]  # 1つ目のファイルを表示\n",
        "    file_path = os.path.join(directory_path, file_to_display)\n",
        "    display(Image(filename=file_path))\n",
        "else:\n",
        "    print(\"指定されたディレクトリ内にjpgファイルが見つかりませんでした。\")\n"
      ],
      "metadata": {
        "id": "OiVhW7PAZhsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################\n",
        "# YOLOv5向けにGroupKfoldで仕分けられたデータセットがあるのでこれを用いる　　#\n",
        "######################################################\n",
        "\"\"\"\n",
        "\n",
        "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "-----dataset-----train-----images\n",
        "              |         |--labels\n",
        "              |--valid-----images\n",
        "              |         |--labels\n",
        "              |--dataset.yaml\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lwjK1LdfR4xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MobileNet用に224px四方に成形しておく\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training\"\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "os.makedirs(f\"{dst_folder}/train\")\n",
        "os.makedirs(f\"{dst_folder}/valid\")"
      ],
      "metadata": {
        "id": "miH-lJQvSwfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(in_path, out_path, processing_file):\n",
        "    #処理時間の計測\n",
        "    start = time.time()\n",
        "\n",
        "    l=0\n",
        "    for i in processing_file:\n",
        "          img = Image.open(in_path + '/' + i)\n",
        "          img_new = expand2square(img, (0, 0, 0)).resize((250, 250))\n",
        "          img_new.save(out_path +'/'+ i)\n",
        "          print(out_path +'/'+ i)\n",
        "\n",
        "          #切り取った画像を表示\n",
        "          #plt.imshow(np.asarray(img_new))\n",
        "          #plt.show()\n",
        "\n",
        "    print('Process done!!')\n",
        "    elapsed_time = time.time() - start\n",
        "    print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
        "\n",
        "def expand2square(pil_img, background_color):\n",
        "    width, height = pil_img.size\n",
        "    if width == height:\n",
        "        return pil_img\n",
        "    elif width > height:\n",
        "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
        "        result.paste(pil_img, (0, (width-height)//2))\n",
        "        return result\n",
        "    else:\n",
        "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
        "        result.paste(pil_img, (0, (height - width) // 2))\n",
        "        return result\n",
        "\n",
        "def showInfo(in_path):\n",
        "    #処理するDirectoryの設定\n",
        "    file = os.listdir(in_path)\n",
        "    print(len(file))\n",
        "\n",
        "    #ここにフォルダ番号を記載する (ex. [0:999])\n",
        "    processing_file = file[0:]\n",
        "    print(processing_file)\n",
        "    len(processing_file)\n",
        "    return processing_file"
      ],
      "metadata": {
        "id": "E-rHgY4lSwhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#元画像フォルダ\n",
        "in_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images'\n",
        "\n",
        "#保存先フォルダ\n",
        "out_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/train'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)\n",
        "\n",
        "processing_file = showInfo(in_path)\n",
        "convert(in_path, out_path, processing_file)\n",
        "\n",
        "#元画像フォルダ\n",
        "in_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images'\n",
        "\n",
        "#保存先フォルダ\n",
        "out_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/valid'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)\n",
        "\n",
        "processing_file = showInfo(in_path)\n",
        "convert(in_path, out_path, processing_file)"
      ],
      "metadata": {
        "id": "kkKYHDOASwjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modules**"
      ],
      "metadata": {
        "id": "JKyZzzRveEVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])\n",
        "        return tensor_image, target\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "\n",
        "            #普通はこちらを使う\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            ##################################\n",
        "            ##パラメータのL1ノルムの絶対値を損失関数に足す##\n",
        "            ##################################\n",
        "            # lam=1e-3\n",
        "            # l1_loss = torch.tensor(0., requires_grad=True)\n",
        "            # for w in model_ft.parameters():\n",
        "            #     l1_loss = l1_loss + abs(torch.norm(w))\n",
        "            # loss = loss + lam * l1_loss\n",
        "            ##################################\n",
        "            ##################################\n",
        "\n",
        "            ##################################\n",
        "            ##パラメータのL2ノルムの二乗を損失関数に足す##\n",
        "            ##################################\n",
        "            # lam=1e-3\n",
        "            # l2_loss = torch.tensor(0., requires_grad=True)\n",
        "            # for w in model_ft.parameters():\n",
        "            #     l2_loss = l2_loss + torch.norm(w)**2\n",
        "            # loss = loss + lam * l2_loss\n",
        "            ##################################\n",
        "            ##################################\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "        #print()\n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics\n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "\n",
        "        epoch_len = len(str(num_epochs))\n",
        "\n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}')\n",
        "        print(print_msg)\n",
        "\n",
        "        \"\"\"\n",
        "        #Scheduler step for ReduceLROnPlateau\n",
        "        scheduler.step(valid_loss)\n",
        "        \"\"\"\n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "\n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed,\n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "\n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "\n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TTNNlLU_cp_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "## Deplpy MobileNetV3\n",
        "##############################################\n",
        "\n",
        "!pip install timm --q\n",
        "import timm\n",
        "\n",
        "model_ft = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "!pip install ranger_adabelief --q\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-8, betas=(0.9,0.999), weight_decay=1e-2, weight_decouple=True)\n",
        "\n",
        "# optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min')\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 15\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "TRAIN_CROP_RATE = (0.9, 1.11)\n",
        "PX = 224\n",
        "\n",
        "class GaussianBlur():\n",
        "    def __init__(self, kernel_size, sigma_min=0.1, sigma_max=2.0):\n",
        "        self.sigma_min = sigma_min\n",
        "        self.sigma_max = sigma_max\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        sigma = np.random.uniform(self.sigma_min, self.sigma_max)\n",
        "        img = cv2.GaussianBlur(np.array(img), (self.kernel_size, self.kernel_size), sigma)\n",
        "        return Image.fromarray(img.astype(np.uint8))\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE, ratio=TRAIN_CROP_RATE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomGrayscale(p=0.01),\n",
        "                transforms.RandomEqualize(p=0.01),\n",
        "                transforms.RandomPerspective(distortion_scale=0.6, p=0.1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "train_csv_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train_list.csv\"\n",
        "val_csv_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid_list.csv\"\n",
        "train_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/train\"\n",
        "val_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/valid\"\n",
        "\n",
        "\n",
        "def extract_list(csv_path, parent_path): #parent_pathは画像を格納しているフォルダ\n",
        "    df = pd.read_csv(csv_path, index_col=None)\n",
        "    image_list = [os.path.join(parent_path, os.path.basename(i)) for i in df[\"image_path\"]]\n",
        "    label_list = df[\"label\"]\n",
        "    return image_list, label_list\n",
        "\n",
        "train_list, train_list_label = extract_list(train_csv_path, train_parent_path)\n",
        "val_list, val_list_label = extract_list(val_csv_path, val_parent_path)\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))"
      ],
      "metadata": {
        "id": "eI2_SlJUcqDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=40)\n"
      ],
      "metadata": {
        "id": "eyRGmXWCcqFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28102f7b-4c29-4693-af62-826aebbe5452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "Epoch: [ 0/40\n",
            "train_loss: 0.61335 train_acc: 0.66667\n",
            "valid_loss: 0.40717 valid_acc: 0.86145\n",
            "Validation loss decreased (inf --> 0.407168).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 1/40\n",
            "train_loss: 0.37395 train_acc: 0.84032\n",
            "valid_loss: 0.24501 valid_acc: 0.92169\n",
            "Validation loss decreased (0.407168 --> 0.245006).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 2/40\n",
            "train_loss: 0.28594 train_acc: 0.88411\n",
            "valid_loss: 0.23358 valid_acc: 0.91265\n",
            "Validation loss decreased (0.245006 --> 0.233578).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 3/40\n",
            "train_loss: 0.23888 train_acc: 0.89996\n",
            "valid_loss: 0.23424 valid_acc: 0.90813\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [ 4/40\n",
            "train_loss: 0.21445 train_acc: 0.90827\n",
            "valid_loss: 0.25156 valid_acc: 0.89910\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [ 5/40\n",
            "train_loss: 0.17319 train_acc: 0.93394\n",
            "valid_loss: 0.21677 valid_acc: 0.91265\n",
            "Validation loss decreased (0.233578 --> 0.216766).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 6/40\n",
            "train_loss: 0.17908 train_acc: 0.92676\n",
            "valid_loss: 0.20358 valid_acc: 0.93072\n",
            "Validation loss decreased (0.216766 --> 0.203576).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 7/40\n",
            "train_loss: 0.14128 train_acc: 0.94677\n",
            "valid_loss: 0.25220 valid_acc: 0.90211\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [ 8/40\n",
            "train_loss: 0.12755 train_acc: 0.94866\n",
            "valid_loss: 0.35130 valid_acc: 0.86145\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [ 9/40\n",
            "train_loss: 0.12434 train_acc: 0.95092\n",
            "valid_loss: 0.24372 valid_acc: 0.90361\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [10/40\n",
            "train_loss: 0.10536 train_acc: 0.95998\n",
            "valid_loss: 0.25982 valid_acc: 0.90060\n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [11/40\n",
            "train_loss: 0.09588 train_acc: 0.95961\n",
            "valid_loss: 0.26691 valid_acc: 0.90361\n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [12/40\n",
            "train_loss: 0.09571 train_acc: 0.96225\n",
            "valid_loss: 0.19275 valid_acc: 0.93675\n",
            "Validation loss decreased (0.203576 --> 0.192750).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [13/40\n",
            "train_loss: 0.07129 train_acc: 0.97622\n",
            "valid_loss: 0.32195 valid_acc: 0.90211\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [14/40\n",
            "train_loss: 0.06730 train_acc: 0.97697\n",
            "valid_loss: 0.30370 valid_acc: 0.90361\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [15/40\n",
            "train_loss: 0.05909 train_acc: 0.97924\n",
            "valid_loss: 0.23611 valid_acc: 0.92169\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [16/40\n",
            "train_loss: 0.06027 train_acc: 0.97584\n",
            "valid_loss: 0.36340 valid_acc: 0.87199\n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [17/40\n",
            "train_loss: 0.06573 train_acc: 0.97773\n",
            "valid_loss: 0.26719 valid_acc: 0.92018\n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [18/40\n",
            "train_loss: 0.06566 train_acc: 0.97508\n",
            "valid_loss: 0.28477 valid_acc: 0.92018\n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [19/40\n",
            "train_loss: 0.05077 train_acc: 0.98075\n",
            "valid_loss: 0.25749 valid_acc: 0.91717\n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [20/40\n",
            "train_loss: 0.04894 train_acc: 0.98301\n",
            "valid_loss: 0.26610 valid_acc: 0.91717\n",
            "EarlyStopping counter: 8 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [21/40\n",
            "train_loss: 0.06488 train_acc: 0.97886\n",
            "valid_loss: 0.27474 valid_acc: 0.92018\n",
            "EarlyStopping counter: 9 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [22/40\n",
            "train_loss: 0.04239 train_acc: 0.98301\n",
            "valid_loss: 0.35517 valid_acc: 0.90663\n",
            "EarlyStopping counter: 10 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [23/40\n",
            "train_loss: 0.04676 train_acc: 0.98226\n",
            "valid_loss: 0.28665 valid_acc: 0.92319\n",
            "EarlyStopping counter: 11 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [24/40\n",
            "train_loss: 0.03818 train_acc: 0.98716\n",
            "valid_loss: 0.32874 valid_acc: 0.91416\n",
            "EarlyStopping counter: 12 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [25/40\n",
            "train_loss: 0.03238 train_acc: 0.99018\n",
            "valid_loss: 0.28866 valid_acc: 0.91867\n",
            "EarlyStopping counter: 13 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [26/40\n",
            "train_loss: 0.04297 train_acc: 0.98414\n",
            "valid_loss: 0.26649 valid_acc: 0.92620\n",
            "EarlyStopping counter: 14 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [27/40\n",
            "train_loss: 0.02923 train_acc: 0.99245\n",
            "valid_loss: 0.30264 valid_acc: 0.91114\n",
            "EarlyStopping counter: 15 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [28/40\n",
            "train_loss: 0.05128 train_acc: 0.98075\n",
            "valid_loss: 0.33236 valid_acc: 0.90964\n",
            "EarlyStopping counter: 16 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [29/40\n",
            "train_loss: 0.03485 train_acc: 0.98981\n",
            "valid_loss: 0.28354 valid_acc: 0.92319\n",
            "EarlyStopping counter: 17 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [30/40\n",
            "train_loss: 0.05099 train_acc: 0.98188\n",
            "valid_loss: 0.27109 valid_acc: 0.90663\n",
            "EarlyStopping counter: 18 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [31/40\n",
            "train_loss: 0.04210 train_acc: 0.98414\n",
            "valid_loss: 0.25527 valid_acc: 0.92922\n",
            "EarlyStopping counter: 19 out of 20\n",
            "\n",
            "----------\n",
            "Epoch: [32/40\n",
            "train_loss: 0.02351 train_acc: 0.99245\n",
            "valid_loss: 0.27320 valid_acc: 0.92319\n",
            "EarlyStopping counter: 20 out of 20\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save best model\n",
        "model_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training\"\n",
        "PATH = f\"{model_parent_path}/MobileNetV3_aug3.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)\n"
      ],
      "metadata": {
        "id": "51XIFf-q-3ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# Load model 飛ばして下さい\n",
        "##########################\n",
        "!pip install timm --q\n",
        "import timm\n",
        "\n",
        "model_ft = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "model_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training\"\n",
        "PATH = f\"{model_parent_path}/MobileNetV3_aug2.pth\"\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "WfcuMSDM-3gH",
        "outputId": "57d5718b-178c-41f8-ceb8-28544b24d685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "# Interference MobileNetV3 #\n",
        "######################\n",
        "\n",
        "#define dataset and dataloader\n",
        "test_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "test_loader = DataLoader(val_dataset, batch_size = 1, shuffle = False, pin_memory=True, num_workers=0) #val_datasetを1枚ずつにしてtest_loadeerに格納\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval() # prep model for evaluation\n",
        "targets, probs, preds =[], [], []\n",
        "for image_tensor, target in test_loader:\n",
        "      #target = target.squeeze(1)\n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model_ft(image_tensor)\n",
        "      _, pred = torch.max(output, 1)\n",
        "\n",
        "      prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "      prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "      prob = \"{:.3f}\".format(prob.item())\n",
        "      print(f\"target: {target.item()}, prob: {prob}, pred: {pred.item()}\")\n",
        "\n",
        "\n",
        "      probs.append(float(prob)) #予測確率\n",
        "      preds.append(int(pred))  #予測結果\n",
        "      targets.append(int(target)) #ラベル\n",
        "y_label = np.array(targets)\n",
        "y_pred = np.array(preds)\n",
        "y_prob = np.array(probs)"
      ],
      "metadata": {
        "id": "QvHusSc_-3iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afa16f1-f27e-4c18-bbcc-d1b50ec73add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.997, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.997, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 0.059, pred: 0\n",
            "target: 1, prob: 0.993, pred: 1\n",
            "target: 1, prob: 0.985, pred: 1\n",
            "target: 1, prob: 0.994, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.026, pred: 0\n",
            "target: 1, prob: 0.304, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.810, pred: 1\n",
            "target: 1, prob: 0.028, pred: 0\n",
            "target: 1, prob: 0.932, pred: 1\n",
            "target: 1, prob: 0.623, pred: 1\n",
            "target: 1, prob: 0.785, pred: 1\n",
            "target: 1, prob: 0.951, pred: 1\n",
            "target: 1, prob: 0.935, pred: 1\n",
            "target: 1, prob: 0.990, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.873, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.995, pred: 1\n",
            "target: 1, prob: 0.990, pred: 1\n",
            "target: 1, prob: 0.848, pred: 1\n",
            "target: 1, prob: 0.994, pred: 1\n",
            "target: 1, prob: 0.899, pred: 1\n",
            "target: 1, prob: 0.983, pred: 1\n",
            "target: 1, prob: 0.983, pred: 1\n",
            "target: 1, prob: 0.979, pred: 1\n",
            "target: 1, prob: 0.966, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.996, pred: 1\n",
            "target: 1, prob: 0.984, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 0.974, pred: 1\n",
            "target: 1, prob: 0.636, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.812, pred: 1\n",
            "target: 1, prob: 0.395, pred: 0\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 0.911, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.941, pred: 1\n",
            "target: 1, prob: 0.990, pred: 1\n",
            "target: 1, prob: 0.963, pred: 1\n",
            "target: 1, prob: 0.027, pred: 0\n",
            "target: 1, prob: 0.985, pred: 1\n",
            "target: 1, prob: 0.106, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.996, pred: 1\n",
            "target: 1, prob: 0.982, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.997, pred: 1\n",
            "target: 1, prob: 0.990, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.912, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.868, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 0.955, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.540, pred: 1\n",
            "target: 1, prob: 0.798, pred: 1\n",
            "target: 1, prob: 0.967, pred: 1\n",
            "target: 1, prob: 0.091, pred: 0\n",
            "target: 1, prob: 0.783, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.728, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.995, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.997, pred: 1\n",
            "target: 1, prob: 0.945, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.995, pred: 1\n",
            "target: 1, prob: 0.051, pred: 0\n",
            "target: 1, prob: 0.976, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.995, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 0.979, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.995, pred: 1\n",
            "target: 1, prob: 0.993, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.997, pred: 1\n",
            "target: 1, prob: 0.986, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.968, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.997, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.990, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.602, pred: 1\n",
            "target: 1, prob: 0.992, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.984, pred: 1\n",
            "target: 1, prob: 0.905, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.808, pred: 1\n",
            "target: 1, prob: 0.940, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.988, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.995, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.625, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.992, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.977, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.088, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.017, pred: 0\n",
            "target: 1, prob: 0.009, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.030, pred: 0\n",
            "target: 1, prob: 0.000, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.193, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.246, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.990, pred: 1\n",
            "target: 1, prob: 0.976, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.861, pred: 1\n",
            "target: 1, prob: 0.956, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.830, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.918, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.885, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.055, pred: 0\n",
            "target: 1, prob: 0.605, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.889, pred: 1\n",
            "target: 1, prob: 0.990, pred: 1\n",
            "target: 1, prob: 0.404, pred: 0\n",
            "target: 1, prob: 0.978, pred: 1\n",
            "target: 1, prob: 0.995, pred: 1\n",
            "target: 1, prob: 0.005, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.933, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.989, pred: 1\n",
            "target: 1, prob: 0.850, pred: 1\n",
            "target: 1, prob: 0.934, pred: 1\n",
            "target: 1, prob: 0.232, pred: 0\n",
            "target: 1, prob: 0.997, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.400, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.482, pred: 0\n",
            "target: 1, prob: 0.421, pred: 0\n",
            "target: 1, prob: 0.649, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.995, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.869, pred: 1\n",
            "target: 1, prob: 0.967, pred: 1\n",
            "target: 1, prob: 0.968, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 0.922, pred: 1\n",
            "target: 1, prob: 0.993, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.980, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.992, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.055, pred: 0\n",
            "target: 0, prob: 0.999, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.992, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.963, pred: 1\n",
            "target: 1, prob: 0.026, pred: 0\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.868, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 0.998, pred: 1\n",
            "target: 1, prob: 0.919, pred: 1\n",
            "target: 1, prob: 0.989, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 1, prob: 1.000, pred: 1\n",
            "target: 0, prob: 0.111, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.327, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 1, prob: 0.988, pred: 1\n",
            "target: 1, prob: 0.992, pred: 1\n",
            "target: 1, prob: 0.999, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.040, pred: 0\n",
            "target: 1, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.807, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.006, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.215, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.131, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.078, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.243, pred: 0\n",
            "target: 0, prob: 0.046, pred: 0\n",
            "target: 0, prob: 0.033, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.013, pred: 0\n",
            "target: 0, prob: 0.024, pred: 0\n",
            "target: 0, prob: 0.010, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.045, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.378, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.375, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.101, pred: 0\n",
            "target: 0, prob: 0.008, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.010, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.023, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.038, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.045, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.163, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.046, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.013, pred: 0\n",
            "target: 0, prob: 0.042, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.011, pred: 0\n",
            "target: 0, prob: 0.023, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.009, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.007, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.048, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.026, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.943, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.767, pred: 1\n",
            "target: 0, prob: 0.109, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.013, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.004, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.035, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.007, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.058, pred: 0\n",
            "target: 0, prob: 0.602, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.035, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.016, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.062, pred: 0\n",
            "target: 0, prob: 0.016, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.066, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.006, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.031, pred: 0\n",
            "target: 0, prob: 0.008, pred: 0\n",
            "target: 0, prob: 0.604, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.021, pred: 0\n",
            "target: 0, prob: 0.012, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.006, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.005, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.011, pred: 0\n",
            "target: 0, prob: 0.161, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.096, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.069, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.020, pred: 0\n",
            "target: 0, prob: 0.007, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.004, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.559, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.111, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.120, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.074, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.103, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.118, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.987, pred: 1\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.067, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.031, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.045, pred: 0\n",
            "target: 0, prob: 0.167, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.026, pred: 0\n",
            "target: 0, prob: 0.138, pred: 0\n",
            "target: 0, prob: 0.674, pred: 1\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.390, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.028, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.999, pred: 1\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.896, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.216, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.516, pred: 1\n",
            "target: 0, prob: 0.033, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.020, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.110, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.740, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.015, pred: 0\n",
            "target: 0, prob: 0.047, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.142, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.182, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.014, pred: 0\n",
            "target: 0, prob: 0.051, pred: 0\n",
            "target: 0, prob: 0.008, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.006, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.028, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.009, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.154, pred: 0\n",
            "target: 0, prob: 0.690, pred: 1\n",
            "target: 0, prob: 0.012, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.136, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.850, pred: 1\n",
            "target: 0, prob: 0.099, pred: 0\n",
            "target: 0, prob: 0.005, pred: 0\n",
            "target: 0, prob: 0.162, pred: 0\n",
            "target: 0, prob: 0.815, pred: 1\n",
            "target: 0, prob: 0.003, pred: 0\n",
            "target: 0, prob: 0.198, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.287, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.125, pred: 0\n",
            "target: 0, prob: 0.011, pred: 0\n",
            "target: 0, prob: 0.005, pred: 0\n",
            "target: 0, prob: 0.213, pred: 0\n",
            "target: 0, prob: 0.018, pred: 0\n",
            "target: 0, prob: 0.893, pred: 1\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.018, pred: 0\n",
            "target: 0, prob: 0.012, pred: 0\n",
            "target: 0, prob: 0.015, pred: 0\n",
            "target: 0, prob: 0.125, pred: 0\n",
            "target: 0, prob: 0.929, pred: 1\n",
            "target: 0, prob: 0.006, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.039, pred: 0\n",
            "target: 0, prob: 0.014, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.002, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.821, pred: 1\n",
            "target: 0, prob: 0.024, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.630, pred: 1\n",
            "target: 0, prob: 0.124, pred: 0\n",
            "target: 0, prob: 0.450, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n",
            "target: 0, prob: 0.004, pred: 0\n",
            "target: 0, prob: 0.014, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.025, pred: 0\n",
            "target: 0, prob: 0.150, pred: 0\n",
            "target: 0, prob: 0.000, pred: 0\n",
            "target: 0, prob: 0.001, pred: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_label\n",
        "y_pred\n",
        "y_prob"
      ],
      "metadata": {
        "id": "E0BPaOqaEnM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# #################################################\n",
        "# threshold = 0.5 #判定基準。ここは先に入力しておく\n",
        "# #################################################\n",
        "\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "#TP_list, FN_list, FP_list, FN_list = [], [], [], []\n",
        "#confusion_list = [[] for i in range(4)]  #[[TP],[FN],[FP],[FN]]\n",
        "confusion_arr = np.zeros((2,2))\n",
        "\n",
        "\n",
        "# X = y_prob\n",
        "# Y = y_label\n",
        "\n",
        "# Y_pred_proba = X\n",
        "# Y_pred = np.where(Y_pred_proba >= threshold, 1, 0)\n",
        "\n",
        "acc = accuracy_score(y_label, y_pred)\n",
        "print('Accuracy:',acc)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_label, y_pred).ravel()\n",
        "print(tp, fn, fp, tn)\n",
        "\n",
        "def specificity_score(label, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "print('confusion matrix = \\n', confusion_matrix(y_label, y_pred))\n",
        "print(f'Accuracy : {accuracy_score(y_label, y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(y_label, y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(y_label, y_pred)}')\n",
        "print(f'Specificity : {specificity_score(y_label, y_pred)}')\n",
        "print(f'F1 score : {f1_score(y_label, y_pred)}')\n",
        "\n",
        "#ROC curve\n",
        "\n",
        "# Compute the ROC curve values\n",
        "fpr, tpr, thresholds = roc_curve(y_label, y_prob)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc_score(y_label, y_prob):.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# fpr, tpr, thresholds = roc_curve(y_label, y_pred)\n",
        "# plt.plot(fpr, tpr, marker='o')\n",
        "# plt.xlabel('FPR')\n",
        "# plt.ylabel('TPR')\n",
        "# plt.grid()\n",
        "# print(f'Area_under_ROC : {roc_auc_score(y_label, y_pred)}')\n",
        "#plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "accuracy.append(accuracy_score(y_label, y_pred))\n",
        "precision.append(precision_score(y_label, y_pred))\n",
        "recall.append(recall_score(y_label, y_pred))\n",
        "specificity.append(specificity_score(y_label, y_pred))\n",
        "f1score.append(f1_score(y_label, y_pred))\n",
        "area_u_ROC.append(roc_auc_score(y_label, y_pred))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# confusion matrixをheatmapで表示\n",
        "cm = confusion_matrix(y_label, y_pred, labels=[1, 0])\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False,\n",
        "            xticklabels=['TED', 'control'],\n",
        "            yticklabels=['TED', 'control'])\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1CAhawNTE8k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Export MobileNetV3 model to CoreML**"
      ],
      "metadata": {
        "id": "2HaYNrrUvioo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# Output as CoreML\n",
        "###########################\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "!pip install --quiet coremltools\n",
        "import coremltools as ct\n",
        "\n",
        "# Load a pre-trained version of MobileNetV3\n",
        "class TorchClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchClassificationModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            model_ft,\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "# Set the model in evaluation mode\n",
        "torch_model = TorchClassificationModel().eval()\n",
        "torch_model = torch_model.to(\"cpu\")\n",
        "\n",
        "\n",
        "# Trace with random data\n",
        "example_input = torch.rand(1, 3, 224, 224) # after test, will get 'size mismatch' error message with size 256x256\n",
        "traced_model = torch.jit.trace(torch_model, example_input)\n",
        "\n",
        "\n",
        "# Download class labels (from a separate file)\n",
        "#import urllib\n",
        "#label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "#class_labels = urllib.request.urlopen(label_url).read().decode(\"utf-8\").splitlines()\n",
        "class_labels = [\"cont\", \"grav\"]\n",
        "\n",
        "\n",
        "\n",
        "# Convert to Core ML using the Unified Conversion API\n",
        "# mlmodel = ct.convert(\n",
        "#     traced_model,\n",
        "#     inputs=[ct.ImageType(name=\"input_1\", shape=example_input.shape)], #name \"input_1\" is used in 'quickstart'\n",
        "#     classifier_config = ct.ClassifierConfig(class_labels) # provide only if step 2 was performed\n",
        "# )\n",
        "\n",
        "\n",
        "#Set the image scale and bias for input image preprocessing.\n",
        "scale = 1.0 / (255.0 * 0.226)\n",
        "red_bias = -0.485 / 0.226\n",
        "green_bias = -0.456 / 0.226\n",
        "blue_bias = -0.406 / 0.226\n",
        "\n",
        "mlmodel = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[ct.ImageType(name=\"input_1\", shape=example_input.shape, scale=scale, bias=[red_bias, green_bias, blue_bias])],\n",
        "    classifier_config=ct.ClassifierConfig(class_labels)\n",
        ")\n",
        "\n",
        "# Save model\n",
        "model_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training\"\n",
        "mlmodel.save(f\"{model_parent_path}/MobileNetV3_extended.mlmodel\")\n"
      ],
      "metadata": {
        "id": "Hp2FOqU89Qgh",
        "outputId": "852987b9-62c5-4da4-de93-4fa915bad38e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 467/468 [00:00<00:00, 2854.09 ops/s]\n",
            "Running MIL Common passes: 100%|██████████| 40/40 [00:00<00:00, 76.30 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 11/11 [00:00<00:00, 127.54 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 665/665 [00:00<00:00, 1664.59 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SpdWnl0EhsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WcHCKuiscqHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YPUmFvYREXMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nCSPS2omEXKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcDbxC9OEXG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lIgEoaLwEWsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Make folders for YOLO5 training**"
      ],
      "metadata": {
        "id": "Wmgd-xTbxFMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLOv5トレーニング用\n",
        "#もしdst_folderがあれば削除して新しく作り直す\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\"\n",
        "\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "for i in [\"train\", \"valid\"]:\n",
        "    for j in [\"images\", \"labels\"]:\n",
        "        os.makedirs(f\"{dst_folder}/{i}/{j}\")\n",
        "        #os.makedirs(f\"{dst_folder}/labels\")\n",
        "\n",
        "for file in img_train[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/images/{os.path.basename(file)}\")\n",
        "for file in img_val[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/images/{os.path.basename(file)}\")\n",
        "for file in label_train[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/labels/{os.path.basename(file)}\")\n",
        "for file in label_val[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/labels/{os.path.basename(file)}\")\n"
      ],
      "metadata": {
        "id": "lKe9k8SirUGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $dst_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAUdjy9A0YZw",
        "outputId": "5d8631eb-b096-471d-96c5-0f3913a7ff55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.yaml\n",
        "# path\n",
        "train: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\n",
        "val: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images\n",
        "\n",
        "# num of classes\n",
        "nc: 2\n",
        "\n",
        "#class names\n",
        "names: ['cont', 'grav'] # class名を定義"
      ],
      "metadata": {
        "id": "giDFflceMi9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e0bdb6-f54e-47f9-e9f4-413245975212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Setup YOLOv5**"
      ],
      "metadata": {
        "id": "cdEoEk_996YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjV_xXLpd5__",
        "outputId": "476d809b-269b-4cd6-a0fe-82f4da46dd53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (12 CPUs, 83.5 GB RAM, 31.0/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Train YOLOv5**"
      ],
      "metadata": {
        "id": "shiv0uvTdH7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "!python train.py --img 640 --batch 16 --epochs 100 --data /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/dataset.yaml --weights yolov5n.pt\n"
      ],
      "metadata": {
        "id": "spn1bRX60hYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best.pyをrenameしてgdriveに移動しておく\n",
        "orig_pt = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5/runs/train/exp/weights/best.pt\"\n",
        "dst_pt = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "shutil.copy(orig_pt, dst_pt)"
      ],
      "metadata": {
        "id": "2_mRrhFn-ONj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "951a6753-9a5b-4e71-e026-7416d32bcc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5 Intereference**"
      ],
      "metadata": {
        "id": "kX9AdOK31h1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference (folder内全部)\n",
        "!python detect.py --weights /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt --img 640 --conf 0.25 --source /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images"
      ],
      "metadata": {
        "id": "Du5NiwCDdTcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid = os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images\")\n",
        "train = os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\")\n",
        "\n",
        "print(len(train), len(valid))"
      ],
      "metadata": {
        "id": "oA6h6A4u_K7Z",
        "outputId": "430d02b5-7a51-42f0-f012-cd33f4d3178c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2649 664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interference (per image)\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt\"\n",
        "image_path = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/*\")\n",
        "img = image_path[100]"
      ],
      "metadata": {
        "id": "jmg05lZkDKnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt --img 640 --conf 0.25 --source $img"
      ],
      "metadata": {
        "id": "mQxqh5QMDrYR",
        "outputId": "66105c9d-2766-4fff-ef56-107bb88cda87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt'], source=/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/6540.JPG, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "image 1/1 /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/6540.JPG: 448x640 1 grav, 18.4ms\n",
            "Speed: 0.7ms pre-process, 18.4ms inference, 38.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    print(img_tensor.shape)\n",
        "\n",
        "    print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "mLCs5mn32MvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt\"\n",
        "image_path = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/*\")\n",
        "img = image_path[2]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, weight)\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"診断は %s、確率は%.1f％です。\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img)\n",
        "cv2_imshow(img_cv2)\n"
      ],
      "metadata": {
        "id": "54vbyhSR-EY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference Olympia dataset**"
      ],
      "metadata": {
        "id": "uzZr3wMsrxJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "cpKHAnmE_wFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f69277f-119c-41dc-d348-1bccda7d470d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (12 CPUs, 83.5 GB RAM, 24.9/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "\n",
        "# 横幅を640pxにリサイズしたデータセット\n",
        "dataset_grav = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/treated_640px\"\n",
        "dataset_cont = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/untreated_640px\""
      ],
      "metadata": {
        "id": "CrVmlh1Csdxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "VPTVErBetQT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = glob.glob(f\"{dataset_grav}/*\")\n",
        "img = image_path[100]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, weight)\n",
        "\n",
        "# output result\n",
        "x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"診断は %s、確率は%.1f％です。\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img)\n",
        "\n",
        "# calculate coordinates of the bounding box (640*640にpaddingされている分の座標を足す)\n",
        "img_height, img_width, _ = img_cv2.shape[:3]\n",
        "print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "padding_x = (img_height - min(img_width, img_height))/2\n",
        "padding_y = (img_width - min(img_width, img_height))/2\n",
        "x1 = x1 - padding_x\n",
        "y1 = y1 - padding_y\n",
        "x2 = x2 - padding_x\n",
        "y2 = y2 - padding_y\n",
        "print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "\n",
        "# draw bounding box\n",
        "cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "\n",
        "# show image\n",
        "cv2_imshow(img_cv2)"
      ],
      "metadata": {
        "id": "_NeSLz6rtalH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Export coreML including non-max supression**"
      ],
      "metadata": {
        "id": "g7JhasvF89PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone Yolov5 repo\n",
        "import os\n",
        "%cd /content\n",
        "!git clone https://github.com/hietalajulius/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt -r requirements-export.txt"
      ],
      "metadata": {
        "id": "E7CfdEw-ylvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\""
      ],
      "metadata": {
        "id": "9uFOe6N9Aiwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python export-nms.py --include coreml --weights $weight_path\n"
      ],
      "metadata": {
        "id": "tBf-4p1BArEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference and crop Extended dataset**"
      ],
      "metadata": {
        "id": "mMbAS9qBSXsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "argQTM34hQEI",
        "outputId": "0f8f99ad-cf66-430e-f771-1741a546d52f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (12 CPUs, 83.5 GB RAM, 24.9/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# パスを指定する\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "input_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\"\n",
        "output_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/train\""
      ],
      "metadata": {
        "id": "SK0LQ6a7hpmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "6qZSIfF5hjGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# image_path = glob.glob(f\"{dataset_grav}/*\")\n",
        "# img = image_path[100]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "device = 'cpu' # device = None or 'cpu' or 0 or '0' or '0,1,2,3'\n",
        "device = select_device(device)\n",
        "model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for img in tqdm(glob.glob(f\"{input_folder}/*\")):\n",
        "\n",
        "    pred = interference(img, weight)\n",
        "\n",
        "    # output result\n",
        "    x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "    # probability\n",
        "    prob = pred[0][0][4].item()\n",
        "\n",
        "    # class\n",
        "    class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "    print(\"診断は %s、確率は%.1f％です。\" %(class_name, prob*100))\n",
        "\n",
        "    img_cv2 = cv2.imread(img)\n",
        "\n",
        "    # calculate coordinates of the bounding box (640*640にpaddingされている分の座標を足す)\n",
        "    img_height, img_width, _ = img_cv2.shape[:3]\n",
        "    print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "    padding_x = (img_height - min(img_width, img_height))/2\n",
        "    padding_y = (img_width - min(img_width, img_height))/2\n",
        "    x1 = x1 - padding_x\n",
        "    y1 = y1 - padding_y\n",
        "    x2 = x2 - padding_x\n",
        "    y2 = y2 - padding_y\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "    # draw bounding box\n",
        "    #cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "    # show image\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    # バウンディングボックスで画像を切り抜く」\n",
        "\n",
        "    if x1 < 0: #負の場合のエラー回避\n",
        "        x1 = 0\n",
        "\n",
        "    cropped_image = img_cv2[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "    # 切り抜いた画像を保存する\n",
        "    save_path = f\"{output_folder}/{os.path.basename(img)}\"\n",
        "    print(save_path)\n",
        "    #cv2_imshow(cropped_image)\n",
        "    cv2.imwrite(save_path, cropped_image)"
      ],
      "metadata": {
        "id": "iJqs6HmydRUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rewrite csv file (bootcamp用csvのimage_pathを改変)\n",
        "import pandas as pd\n",
        "\n",
        "csv_1_orig = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train_list.csv\"\n",
        "csv_2_orig = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid_list.csv\"\n",
        "csv_1 = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/train_list.csv\"\n",
        "csv_2 = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/valid_list.csv\"\n",
        "\n",
        "def rewrite_csv(df):\n",
        "    path_list = []\n",
        "    for path in df[\"image_path\"]:\n",
        "        path = path.replace(\"periocular_for_YOLO_training\", \"periocular_cropped_using_YOLO\")\n",
        "        path = path.replace(\"images/\", \"\")\n",
        "        path_list.append(path)\n",
        "    df[\"image_path\"] = path_list\n",
        "    return(df)\n",
        "\n",
        "df = pd.read_csv(csv_1_orig)\n",
        "df = rewrite_csv(df)\n",
        "print(df)\n",
        "df.to_csv(csv_1, index=False)\n",
        "\n",
        "df = pd.read_csv(csv_2_orig)\n",
        "df = rewrite_csv(df)\n",
        "df.to_csv(csv_2,  index=False)"
      ],
      "metadata": {
        "id": "z9kG4PiPlCyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Js-kBmr0vhqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ln9uTV9Nvhrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwPGcLe_vhu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}