{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled37.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5fb4100e328a4f88b393e5a123cd27b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4919d6b2c32c46fe802b865afcfd3f61",
              "IPY_MODEL_5c81b08cd2af447684db19fc25aaf9b7",
              "IPY_MODEL_c427ee2b145a425b8f49b8516da7b819"
            ],
            "layout": "IPY_MODEL_9284e4f96b144ba7b2f1fcc5ff6dc940"
          }
        },
        "4919d6b2c32c46fe802b865afcfd3f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5c0bdb57c7f4e2eb9f3f845bec07e2b",
            "placeholder": "​",
            "style": "IPY_MODEL_74226a252f2b4014ba98207d7d2d53d8",
            "value": "model.safetensors: 100%"
          }
        },
        "5c81b08cd2af447684db19fc25aaf9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be1de2f65ba54e4f8e9e7e3b0dc9d104",
            "max": 22058321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fb38dfb30464b4faa0bda152a0e103d",
            "value": 22058321
          }
        },
        "c427ee2b145a425b8f49b8516da7b819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21c2401c3d1b437eaa4fc6e6a18795ea",
            "placeholder": "​",
            "style": "IPY_MODEL_446540f03ff9410ea5ebf12752ff04c6",
            "value": " 22.1M/22.1M [00:00&lt;00:00, 74.7MB/s]"
          }
        },
        "9284e4f96b144ba7b2f1fcc5ff6dc940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5c0bdb57c7f4e2eb9f3f845bec07e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74226a252f2b4014ba98207d7d2d53d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be1de2f65ba54e4f8e9e7e3b0dc9d104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb38dfb30464b4faa0bda152a0e103d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21c2401c3d1b437eaa4fc6e6a18795ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "446540f03ff9410ea5ebf12752ff04c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GravCont_classification_2/blob/main/Extend_dataset_CNN_chizai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GO extend datasetMobileNet_for_chizai**"
      ],
      "metadata": {
        "id": "LXR--60tO5mS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5xvbecME5IS",
        "outputId": "8aacb05b-90c0-4743-f6e6-eddbd53c227c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torch_optimizer --q\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "!pip install albumentations==0.4.6 --q\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "!pip install mediapipe opencv-python --q\n",
        "import mediapipe as mp\n",
        "\n",
        "\n",
        "random_seed = 3 #shuffleのシード\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "!nvidia-smi\n",
        "print(torch.cuda.is_available())\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMon Oct 23 00:00:38 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0ZI4pHmFDXZ"
      },
      "source": [
        "#Google colabをマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkrhEditFGkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54499d0-169a-4920-b2ab-01094a2a56ed"
      },
      "source": [
        "'''\n",
        "・dlibを用いて目を切り抜く\n",
        "・横幅を2倍、縦幅を上に1倍追加/下に0.5倍追加した両眼の画像が含まれるように切り取る（目の全幅、眉毛が含まれるように）\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7fAuwXxNka"
      },
      "source": [
        "#残り時間確認\n",
        "!cat /proc/uptime | awk '{printf(\"残り時間 : %.2f\", 12-$1/60/60)}'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSfusHMWPL6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSA2Rm9MFXoZ"
      },
      "source": [
        "# # GO_extended_datasetを colab上のフォルダに展開\n",
        "# zip_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/GO_extended_dataset.zip'\n",
        "# !unzip $zip_path -d \"/content\"\n",
        "# in_path_list  = ['/content/GO_extended_dataset/Control_photo_1886mai', '/content/GO_extended_dataset/treatable']\n",
        "# #保存先フォルダ\n",
        "# out_path_list = ['/content/GO_extended_dataset/cont', '/content/GO_extended_dataset/grav']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MobileNetV3 training用フォルダを作成**\n",
        "\n",
        "datasetをtrainとvalに分ける\n",
        "\n",
        "https://book.st-hakky.com/docs/object-detection-yolov5-tutorial/\n",
        "\n"
      ],
      "metadata": {
        "id": "VPi74ZCZrVDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# periocular_for_YOLOフォルダにすでに展開されているデータセットを用いる\n",
        "dataset_dir = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO\"\n",
        "\n",
        "# def split_dataset(dataset_dir):\n",
        "#     img_list = glob.glob(f\"{dataset_dir}/images/*\")\n",
        "#     img_train, img_test = train_test_split(img_list, test_size=0.3, random_state=0)\n",
        "\n",
        "#     # img_train, img_testに名前が一致するtxtファイルを抜き出す\n",
        "#     label_train = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_train]\n",
        "#     label_test = [f\"{dataset_dir}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in img_test]\n",
        "\n",
        "#     print(f\"train: {len(label_train)},test: {len(label_test)}\")\n",
        "\n",
        "#     return img_train, img_test, label_train, label_test\n",
        "\n",
        "def make_path_list(dir, class_name):\n",
        "    image_list =  [file for file in glob.glob(f\"{dir}/{class_name}/images/*\") if os.path.isfile(file) == True ]\n",
        "    label_list =  [f\"{dir}/{class_name}/labels/{os.path.basename(i).split('.')[0]}.txt\" for i in image_list]\n",
        "\n",
        "    id_list = [os.path.basename(i).split(\"-\")[0].split(\".\")[0] for i in image_list]\n",
        "\n",
        "    index = {}\n",
        "    id_idx = []\n",
        "    for item in id_list:\n",
        "        if item in index:\n",
        "            id_idx.append(index[item])\n",
        "        else:\n",
        "            index[item] = len(index) + 1\n",
        "            id_idx.append(index[item])\n",
        "    id_idx = [int(i) for i in id_idx]\n",
        "\n",
        "    return image_list, label_list, id_idx\n",
        "\n",
        "grav_image_list, grav_label_list, grav_id_idx = make_path_list(dataset_dir, \"grav\")\n",
        "cont_image_list, cont_label_list, cont_id_idx = make_path_list(dataset_dir, \"cont\")\n",
        "\n",
        "print(f\"grav: {len(grav_image_list)}\")\n",
        "print(f\"cont: {len(cont_image_list)}\")"
      ],
      "metadata": {
        "id": "hHiTlYEnLx_u",
        "outputId": "ab7b63ab-c22d-45de-af9b-a3525ad4a614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grav: 1657\n",
            "cont: 1656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "# ディレクトリのパス\n",
        "directory_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO/cont/images_cropped\"\n",
        "\n",
        "# ディレクトリ内のjpgファイルをリストアップ\n",
        "jpg_files = [f for f in os.listdir(directory_path) if f.endswith('.JPG')]\n",
        "\n",
        "# 1つのjpgファイルを表示\n",
        "if len(jpg_files) > 0:\n",
        "    file_to_display = jpg_files[0]  # 1つ目のファイルを表示\n",
        "    file_path = os.path.join(directory_path, file_to_display)\n",
        "    display(Image(filename=file_path))\n",
        "else:\n",
        "    print(\"指定されたディレクトリ内にjpgファイルが見つかりませんでした。\")\n"
      ],
      "metadata": {
        "id": "OiVhW7PAZhsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################\n",
        "# YOLOv5向けにGroupKfoldで仕分けられたデータセットがあるのでこれを用いる　　#\n",
        "######################################################\n",
        "\"\"\"\n",
        "\n",
        "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "-----dataset-----train-----images\n",
        "              |         |--labels\n",
        "              |--valid-----images\n",
        "              |         |--labels\n",
        "              |--dataset.yaml\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lwjK1LdfR4xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MobileNet用に224px四方に成形しておく\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training\"\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "os.makedirs(f\"{dst_folder}/train\")\n",
        "os.makedirs(f\"{dst_folder}/valid\")"
      ],
      "metadata": {
        "id": "miH-lJQvSwfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(in_path, out_path, processing_file):\n",
        "    #処理時間の計測\n",
        "    start = time.time()\n",
        "\n",
        "    l=0\n",
        "    for i in processing_file:\n",
        "          img = Image.open(in_path + '/' + i)\n",
        "          img_new = expand2square(img, (0, 0, 0)).resize((250, 250))\n",
        "          img_new.save(out_path +'/'+ i)\n",
        "          print(out_path +'/'+ i)\n",
        "\n",
        "          #切り取った画像を表示\n",
        "          #plt.imshow(np.asarray(img_new))\n",
        "          #plt.show()\n",
        "\n",
        "    print('Process done!!')\n",
        "    elapsed_time = time.time() - start\n",
        "    print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
        "\n",
        "def expand2square(pil_img, background_color):\n",
        "    width, height = pil_img.size\n",
        "    if width == height:\n",
        "        return pil_img\n",
        "    elif width > height:\n",
        "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
        "        result.paste(pil_img, (0, (width-height)//2))\n",
        "        return result\n",
        "    else:\n",
        "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
        "        result.paste(pil_img, (0, (height - width) // 2))\n",
        "        return result\n",
        "\n",
        "def showInfo(in_path):\n",
        "    #処理するDirectoryの設定\n",
        "    file = os.listdir(in_path)\n",
        "    print(len(file))\n",
        "\n",
        "    #ここにフォルダ番号を記載する (ex. [0:999])\n",
        "    processing_file = file[0:]\n",
        "    print(processing_file)\n",
        "    len(processing_file)\n",
        "    return processing_file"
      ],
      "metadata": {
        "id": "E-rHgY4lSwhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#元画像フォルダ\n",
        "in_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images'\n",
        "\n",
        "#保存先フォルダ\n",
        "out_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/train'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)\n",
        "\n",
        "processing_file = showInfo(in_path)\n",
        "convert(in_path, out_path, processing_file)\n",
        "\n",
        "#元画像フォルダ\n",
        "in_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images'\n",
        "\n",
        "#保存先フォルダ\n",
        "out_path = '/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/valid'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)\n",
        "\n",
        "processing_file = showInfo(in_path)\n",
        "convert(in_path, out_path, processing_file)"
      ],
      "metadata": {
        "id": "kkKYHDOASwjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modules**"
      ],
      "metadata": {
        "id": "JKyZzzRveEVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])\n",
        "        return tensor_image, target\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "\n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "\n",
        "            #普通はこちらを使う\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            ##################################\n",
        "            ##パラメータのL1ノルムの絶対値を損失関数に足す##\n",
        "            ##################################\n",
        "            # lam=1e-3\n",
        "            # l1_loss = torch.tensor(0., requires_grad=True)\n",
        "            # for w in model_ft.parameters():\n",
        "            #     l1_loss = l1_loss + abs(torch.norm(w))\n",
        "            # loss = loss + lam * l1_loss\n",
        "            ##################################\n",
        "            ##################################\n",
        "\n",
        "            ##################################\n",
        "            ##パラメータのL2ノルムの二乗を損失関数に足す##\n",
        "            ##################################\n",
        "            # lam=1e-3\n",
        "            # l2_loss = torch.tensor(0., requires_grad=True)\n",
        "            # for w in model_ft.parameters():\n",
        "            #     l2_loss = l2_loss + torch.norm(w)**2\n",
        "            # loss = loss + lam * l2_loss\n",
        "            ##################################\n",
        "            ##################################\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "        #print()\n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics\n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "\n",
        "        epoch_len = len(str(num_epochs))\n",
        "\n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}')\n",
        "        print(print_msg)\n",
        "\n",
        "        \"\"\"\n",
        "        #Scheduler step for ReduceLROnPlateau\n",
        "        scheduler.step(valid_loss)\n",
        "        \"\"\"\n",
        "\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "\n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed,\n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "\n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "\n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TTNNlLU_cp_b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "## Deplpy MobileNetV3\n",
        "##############################################\n",
        "\n",
        "!pip install timm --q\n",
        "import timm\n",
        "\n",
        "model_ft = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "!pip install ranger_adabelief --q\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-8, betas=(0.9,0.999), weight_decay=1e-2, weight_decouple=True)\n",
        "\n",
        "# optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min')\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 15\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "TRAIN_CROP_RATE = (0.9, 1.11)\n",
        "PX = 224\n",
        "\n",
        "class GaussianBlur():\n",
        "    def __init__(self, kernel_size, sigma_min=0.1, sigma_max=2.0):\n",
        "        self.sigma_min = sigma_min\n",
        "        self.sigma_max = sigma_max\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        sigma = np.random.uniform(self.sigma_min, self.sigma_max)\n",
        "        img = cv2.GaussianBlur(np.array(img), (self.kernel_size, self.kernel_size), sigma)\n",
        "        return Image.fromarray(img.astype(np.uint8))\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE, ratio=TRAIN_CROP_RATE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomGrayscale(p=0.01),\n",
        "                transforms.RandomEqualize(p=0.01),\n",
        "                transforms.RandomPerspective(distortion_scale=0.6, p=0.1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "train_csv_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train_list.csv\"\n",
        "val_csv_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid_list.csv\"\n",
        "train_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/train\"\n",
        "val_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/valid\"\n",
        "\n",
        "\n",
        "def extract_list(csv_path, parent_path): #parent_pathは画像を格納しているフォルダ\n",
        "    df = pd.read_csv(csv_path, index_col=None)\n",
        "    image_list = [os.path.join(parent_path, os.path.basename(i)) for i in df[\"image_path\"]]\n",
        "    label_list = df[\"label\"]\n",
        "    return image_list, label_list\n",
        "\n",
        "train_list, train_list_label = extract_list(train_csv_path, train_parent_path)\n",
        "val_list, val_list_label = extract_list(val_csv_path, val_parent_path)\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))"
      ],
      "metadata": {
        "id": "eI2_SlJUcqDX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "5fb4100e328a4f88b393e5a123cd27b2",
            "4919d6b2c32c46fe802b865afcfd3f61",
            "5c81b08cd2af447684db19fc25aaf9b7",
            "c427ee2b145a425b8f49b8516da7b819",
            "9284e4f96b144ba7b2f1fcc5ff6dc940",
            "c5c0bdb57c7f4e2eb9f3f845bec07e2b",
            "74226a252f2b4014ba98207d7d2d53d8",
            "be1de2f65ba54e4f8e9e7e3b0dc9d104",
            "1fb38dfb30464b4faa0bda152a0e103d",
            "21c2401c3d1b437eaa4fc6e6a18795ea",
            "446540f03ff9410ea5ebf12752ff04c6"
          ]
        },
        "outputId": "48e2f47e-1c98-45b6-c16e-17d1b39b0bda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/22.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fb4100e328a4f88b393e5a123cd27b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "2649\n",
            "664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=20, num_epochs=40)\n"
      ],
      "metadata": {
        "id": "eyRGmXWCcqFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save best model\n",
        "model_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training\"\n",
        "PATH = f\"{model_parent_path}/MobileNetV3_aug3.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)\n"
      ],
      "metadata": {
        "id": "51XIFf-q-3ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# Load model 飛ばして下さい\n",
        "##########################\n",
        "!pip install timm --q\n",
        "import timm\n",
        "\n",
        "model_ft = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
        "num_ftrs = model_ft.classifier.in_features\n",
        "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#ネットワークの読み込み\n",
        "model_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training\"\n",
        "PATH = f\"{model_parent_path}/MobileNetV3_aug3.pth\"\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "WfcuMSDM-3gH",
        "outputId": "1ed5350c-4b77-415e-c4be-6788b7348ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dShbfug9CYD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft"
      ],
      "metadata": {
        "id": "uJp342k-ICo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "##################\n",
        "## Define GradCAM ##\n",
        "##################\n",
        "\n",
        "def compute_gradcam(model, image_tensor, target_class=None):\n",
        "    model.eval()\n",
        "\n",
        "    features = None\n",
        "    grads = None\n",
        "\n",
        "    def hook_feature(module, input, output):\n",
        "        nonlocal features\n",
        "        features = output\n",
        "\n",
        "    def hook_grad(module, grad_in, grad_out):\n",
        "        nonlocal grads\n",
        "        grads = grad_out[0]\n",
        "\n",
        "    final_conv = model.blocks[-1]  # この部分はモデルの構造により調整が必要\n",
        "    final_conv.register_forward_hook(hook_feature)\n",
        "    final_conv.register_backward_hook(hook_grad)\n",
        "\n",
        "    output = model(image_tensor)\n",
        "    if target_class is None:\n",
        "        target_class = output.argmax().item()\n",
        "\n",
        "    model.zero_grad()\n",
        "    one_hot = torch.zeros_like(output)\n",
        "    one_hot[0][target_class] = 1\n",
        "    output.backward(gradient=one_hot)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        activations = features.cpu().numpy()\n",
        "        grad_values = grads.cpu().numpy()\n",
        "        weights = np.mean(grad_values, axis=(2, 3))[0, :]\n",
        "        cam = np.zeros_like(activations[0, 0, :, :], dtype=np.float32)\n",
        "        for i, w in enumerate(weights):\n",
        "            cam += w * activations[0, i, :, :]\n",
        "        cam = np.maximum(cam, 0)\n",
        "        cam = cv2.resize(cam, (image_tensor.shape[2], image_tensor.shape[3]))\n",
        "        cam = cam - np.min(cam)\n",
        "        cam = cam / np.max(cam)\n",
        "\n",
        "    # Memory clean-up\n",
        "    del features, grads, activations, grad_values, weights\n",
        "    torch.cuda.empty_cache()  # If you're using CUDA\n",
        "\n",
        "    return cam\n"
      ],
      "metadata": {
        "id": "hzvNpNeravOw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dlibを用いた眼周囲抜き出し\n",
        "\n",
        "こちらの方がmediapipeより検出率、精度が高い"
      ],
      "metadata": {
        "id": "mqchGqI3SZT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dlib --q\n",
        "!pip install opencv-python --q\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bunzip2 shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "# カスケードファイルのパス\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "# righteye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_righteye_2splits.xml'\n",
        "# lefteye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_lefteye_2splits.xml'\n",
        "\n",
        "# カスケード分類器の特徴量取得\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "# righteye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "# lefteye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq_FRvcq0Ilw",
        "outputId": "b2b2544a-72ac-447e-d4ce-30bf9845a46f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-23 00:02:12--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  31.9MB/s    in 1.9s    \n",
            "\n",
            "2023-10-23 00:02:14 (31.9 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval()  # prep model for evaluation\n",
        "\n",
        "# misclassified = [17, 24, 25, 28, 68, 70, 101, 121, 200, 210, 211, 214, 215, 218, 221, 271, 291, 316, 323, 343, 344, 363, 384, 440, 448, 485, 526, 531, 544, 546, 558, 561, 568, 586, 617, 627, 629, 641, 649]\n",
        "# image_indices = misclassified\n",
        "\n",
        "#image_indices = list(range(0, 665))\n",
        "image_indices = list(range(0, 665))\n",
        "\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "counter_1 = 0  # img_label == pred.item()\n",
        "counter_2 = 0  # img_label == mask_diagnosis\n",
        "counter_3_same_pred_and_mask = 0  # pred.item() == mask_diagnosis and img_label == pred.item()\n",
        "counter_3_total_same_pred_and_mask = 0  # pred.item() == mask_diagnosis\n",
        "counter_4_diff_pred_and_mask = 0  # pred.item() != mask_diagnosis and img_label == pred.item()\n",
        "counter_4_total_diff_pred_and_mask = 0  # pred.item() != mask_diagnosis\n",
        "mismatched_indices = []\n",
        "\n",
        "def crop_bilateral(in_path):\n",
        "    img = cv2.imread(in_path)\n",
        "    grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    mask = np.zeros_like(grayscale_img)\n",
        "    eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(40, 40))\n",
        "    for (x, y, w, h) in eye_list:\n",
        "        mask[y:y+h, int(x+w/4):int(x+3*w/4)] = 255\n",
        "    return mask\n",
        "\n",
        "for i, (img_path, img_label) in enumerate(zip(val_list, val_list_label)):\n",
        "    if i in image_indices:\n",
        "        #GradCAM\n",
        "        pilr_image = Image.open(img_path).convert(\"RGB\")\n",
        "        numpy_image = np.array(pilr_image)\n",
        "        cv2_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
        "        image_tensor = test_data_transforms(pilr_image)\n",
        "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "        output = model_ft(image_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        prob = nn.Softmax(dim=1)(output)[0][1].cpu().detach().item()\n",
        "\n",
        "        cam_class_0 = compute_gradcam(model_ft, image_tensor, target_class=0)\n",
        "        cam_class_1 = compute_gradcam(model_ft, image_tensor, target_class=1)\n",
        "\n",
        "        #注目部位を２値化して表示\n",
        "        mask_0 = np.where(cam_class_0 > 0.5, 1, 0).astype(np.uint8)\n",
        "        mask_1 = np.where(cam_class_1 > 0.5, 1, 0).astype(np.uint8)\n",
        "\n",
        "        mask_0_resized = cv2.resize(mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        mask_1_resized = cv2.resize(mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        # inverse_mask_0_resized = cv2.resize(inverse_mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        # inverse_mask_1_resized = cv2.resize(inverse_mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "\n",
        "        #HaarCascadeによる眼周囲抜き出し\n",
        "        periocular_mask = crop_bilateral(img_path)\n",
        "\n",
        "        #GradCAM、眼周囲領域の共通点をマスク化する\n",
        "        common_mask_0 = cv2.bitwise_and(mask_0_resized, periocular_mask)\n",
        "        common_mask_1 = cv2.bitwise_and(mask_1_resized, periocular_mask)\n",
        "\n",
        "        area_common_mask_0 = np.sum(common_mask_0) / 255\n",
        "        area_common_mask_1 = np.sum(common_mask_1) / 255\n",
        "        mask_diagnosis = 0 if area_common_mask_0 > area_common_mask_1 else 1\n",
        "\n",
        "\n",
        "\n",
        "        # Convert the common masks to 3-channel images for visualization\n",
        "        common_mask_0 = np.stack([common_mask_0]*3, axis=-1) * 255\n",
        "        common_mask_1 = np.stack([common_mask_1]*3, axis=-1) * 255\n",
        "\n",
        "        heatmap_0 = cv2.applyColorMap(np.uint8(255 * cam_class_0), cv2.COLORMAP_JET)\n",
        "        heatmap_1 = cv2.applyColorMap(np.uint8(255 * cam_class_1), cv2.COLORMAP_JET)\n",
        "\n",
        "        heatmap_0_resized = cv2.resize(heatmap_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        heatmap_1_resized = cv2.resize(heatmap_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "\n",
        "        overlayed_image_0 = cv2.addWeighted(cv2_image, 0.5, heatmap_0_resized, 0.5, 0)\n",
        "        overlayed_image_1 = cv2.addWeighted(cv2_image, 0.5, heatmap_1_resized, 0.5, 0)\n",
        "\n",
        "        # 1. 3チャンネルの画像に変換\n",
        "        periocular_colored_mask = cv2.cvtColor(periocular_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # 2. overlayed_image_1にperiocular_maskをオーバーレイ\n",
        "        overlayed_image_1_with_mask = cv2.addWeighted(overlayed_image_1, 0.7, periocular_colored_mask, 0.3, 0)\n",
        "\n",
        "        # 3. overlayed_image_0にperiocular_maskをオーバーレイ\n",
        "        overlayed_image_0_with_mask = cv2.addWeighted(overlayed_image_0, 0.7, periocular_colored_mask, 0.3, 0)\n",
        "\n",
        "        # 結果の表示\n",
        "        result_with_mask = np.hstack([cv2_image, overlayed_image_1_with_mask, overlayed_image_0_with_mask, common_mask_1, common_mask_0])\n",
        "\n",
        "\n",
        "\n",
        "        # Inside your loop\n",
        "        if img_label == pred.item():\n",
        "            counter_1 += 1\n",
        "        if img_label == mask_diagnosis:\n",
        "            counter_2 += 1\n",
        "        if pred.item() == mask_diagnosis:\n",
        "            counter_3_total_same_pred_and_mask += 1\n",
        "            if img_label == pred.item():\n",
        "                counter_3_same_pred_and_mask += 1\n",
        "        if pred.item() != mask_diagnosis:\n",
        "            counter_4_total_diff_pred_and_mask += 1\n",
        "            if img_label == pred.item():\n",
        "                counter_4_diff_pred_and_mask += 1\n",
        "        if img_label != pred.item():\n",
        "            mismatched_indices.append(i)\n",
        "\n",
        "        print(f\"{i}\")\n",
        "        print(f\"{os.path.basename(img_path)}\")\n",
        "        print(f\"target: {img_label}, prob: {prob}, pred: {pred.item()}\")\n",
        "        print(f\"mask_diagnosis = {mask_diagnosis}\")\n",
        "        #cv2_imshow(result_with_mask)\n",
        "        print(\"\")\n",
        "\n",
        "total_images = len(image_indices)\n",
        "ratio_1 = counter_1 / total_images * 100\n",
        "ratio_2 = counter_2 / total_images * 100\n",
        "ratio_3 = (counter_3_same_pred_and_mask / counter_3_total_same_pred_and_mask) * 100 if counter_3_total_same_pred_and_mask != 0 else 0\n",
        "ratio_4 = (counter_4_diff_pred_and_mask / counter_4_total_diff_pred_and_mask) * 100 if counter_4_total_diff_pred_and_mask != 0 else 0\n",
        "print(f\"Model accuracy: {ratio_1:.2f}% ({counter_1}/{total_images})\")\n",
        "print(f\"GradCAM area judgement: {ratio_2:.2f}% ({counter_2}/{total_images})\")\n",
        "print(f\"Accuracy in which model and GradCAM judgement match: {ratio_3:.2f}% ({counter_3_same_pred_and_mask}/{counter_3_total_same_pred_and_mask})\")\n",
        "print(f\"Accuracy in which model and GradCAM judgement do'nt match: {ratio_4:.2f}% ({counter_4_diff_pred_and_mask}/{counter_4_total_diff_pred_and_mask})\")\n",
        "print(f\"Mismatched indices: {mismatched_indices}\")\n",
        "print(f\"Matrix:\\n\")\n",
        "print(f\"{'':<30} | {'model_diagnosisがmask_diagnosisと一致':<25} | {'model_diagnosisがmask_diagnosisと不一致':<25}\")\n",
        "print(f\"{'-'*90}\")\n",
        "print(f\"{'modelで正解':<30} | {counter_3_same_pred_and_mask:<25} | {counter_1 - counter_3_same_pred_and_mask:<25}\")\n",
        "print(f\"{'modelで不正解':<30} | {counter_4_diff_pred_and_mask:<25} | {counter_4_total_diff_pred_and_mask - counter_4_diff_pred_and_mask:<25}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "m-m3ZFMou287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28fcddb-5160-4078-dfce-6c3eeca5d68c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "9727-20200122-45-090724_4cb44937d9d63a3e14223b9d4fd2bbbeda74969c91228008b6474e9a98ebcb8c.JPG\n",
            "target: 1, prob: 0.9999775886535645, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "1\n",
            "9727-20191120-45-095912_4d49c51c280d6736791ea8c01838e046d7f4dbe382442ff3e3492bdf34c7e881.JPG\n",
            "target: 1, prob: 0.9867652654647827, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "2\n",
            "9727-20200226-45-090852_586f24fb20abd942f28aae5ff3b230ad82a4b700cf26ae84f7e0c208a1f2cc53.JPG\n",
            "target: 1, prob: 0.9999130964279175, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "3\n",
            "9727-20200115-45-084704_278336c304649ea1ca19b4c4af098fad8fd5b591633404c19657f55d0fdf987b.JPG\n",
            "target: 1, prob: 0.9999798536300659, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "4\n",
            "9727-20191218-45-093258_09baca96e5ddc21802a8e2a6ef470e27f2ac43f4cd01a13fb69415df071c2c72.JPG\n",
            "target: 1, prob: 0.9999469518661499, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "5\n",
            "9727-20210519-46-092033_b0ea4e6397f27437156c6bbdb26f3ea28421fae645c35d3a03c2fb8f59b7b636.JPG\n",
            "target: 1, prob: 0.9999603033065796, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "6\n",
            "9727-20210120-46-084859_3afb5d0a049c0f3def28a2a8e476e4e7db742ef9186b420332200929e3561fc6.JPG\n",
            "target: 1, prob: 0.9999980926513672, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "7\n",
            "9727-20210317-46-085246_2a9c829efcfcdddbcb5aacc49bda0854d330d43b042f87b4fca0e523e35edc63.JPG\n",
            "target: 1, prob: 0.9998824596405029, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "8\n",
            "9727-20210519-46-092033_ef10394b6fa2fda08e47f797e4ab24ed2bb63558b3413b279fa8aca8d60a5098.JPG\n",
            "target: 1, prob: 0.999995231628418, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "9\n",
            "9727-20201125-46-085506_57483f4baa6a272cbb28ad961b126e95a408478c708bb67711b807ac58c59e7b.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "10\n",
            "9824-20191127-53-091351_f5169e42dba889ab0a2cf13525484b681989f388566a0d1486f2854b0638cd4b.JPG\n",
            "target: 1, prob: 0.9999804496765137, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "11\n",
            "9824-20191016-53-093331_d2300488a23d3c9b9e938594cdf3ad04a5a135cdcdf885cc4ee60d733677786a.JPG\n",
            "target: 1, prob: 0.9999908208847046, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "12\n",
            "9824-20191016-53-093331_8882a923786c13d5bab7dfec81af2cca801980ac491e00bb310ab038b2393e02.JPG\n",
            "target: 1, prob: 0.998468816280365, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "13\n",
            "9727-20201021-46-085417_92cfdf289ccd5b1656468e7bbbff6c1d991bd0cdab8a511ebd429f67c264e7da.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "14\n",
            "9727-20200722-46-092102_cceabdc09d3b5959f0a637cdfea4f8caa49faa1f6c96dda22ce8872b329156bf.JPG\n",
            "target: 1, prob: 0.9999761581420898, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "15\n",
            "9727-20200610-45-092252_acc0686575c2c649362004ca86fc6042deac027380ee17e82ce3f39fb09d53e0.JPG\n",
            "target: 1, prob: 0.9999983310699463, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "16\n",
            "9642-20201202-57-140656_1daf9f216dccd12826f643091a5badad368bf30eba751d2761b199233552fa1e.JPG\n",
            "target: 1, prob: 0.9988014698028564, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "17\n",
            "9691-20200219-38-103859_9e18e8a505645235e3b6926d502108b57d254e43baf7a60a7128e4510a1a521b.JPG\n",
            "target: 1, prob: 0.06291189044713974, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "18\n",
            "9642-20210310-57-134951_ab5213d4978bd6c8f00bbb1144a873da39beaa1baf29982fef4be1d2f299afda.JPG\n",
            "target: 1, prob: 0.9961875081062317, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "19\n",
            "9691-20200108-38-100642_300e4294885745af417476b329912eb7881582d601b5b8db55adf00264220fb9.JPG\n",
            "target: 1, prob: 0.977817714214325, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "20\n",
            "9642-20200902-57-135430_55d26fb4754f0eae96888e8c4bc7010a510662f06996aaece459c4c8ca704197.JPG\n",
            "target: 1, prob: 0.9999958276748657, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "21\n",
            "9727-20200902-46-085317_5f939c3e47823767be5bf3dff6255886ae24e85103ab85528d25be842a5f1dcd.JPG\n",
            "target: 1, prob: 0.9997989535331726, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "22\n",
            "9727-20200422-45-091939_88741dcecf986054fa59da87ef4dacd2b870e29d41062728c3575f5da3e6f117.JPG\n",
            "target: 1, prob: 0.999794065952301, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "23\n",
            "9727-20191009-45-110922_9a0cec69b436d2c4ff3734998d05b0aab57483d551b0db6e36817981728fe2e6.JPG\n",
            "target: 1, prob: 0.999987006187439, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "24\n",
            "9691-20210317-39-122052_1039478821cca4dedd1aa059dbebf22f0ea8554e2f68043fae03597709376873.JPG\n",
            "target: 1, prob: 0.22989167273044586, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "25\n",
            "9691-20200501-38-093858_cb3c6fecffabffb38a11b2ec86165085d8b5f7143d3f7d11399dac00e10a5a9f.JPG\n",
            "target: 1, prob: 0.30516618490219116, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "26\n",
            "9727-20200401-45-091458_50c65874bc489c1e225e23f8c62d4025a57fc9891da532fca35d6c2520b4ecec.JPG\n",
            "target: 1, prob: 0.9999127388000488, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "27\n",
            "9691-20210317-39-122052_92f21c73774a5569765ffd774aedcc9a50f01895b23d7096156878320e8be71a.JPG\n",
            "target: 1, prob: 0.5852926969528198, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "28\n",
            "9691-20200501-38-093858_1baedc5538a7d793173f036794d81c1ced5febdd30b450136b2c6b59ae4c4f6e.JPG\n",
            "target: 1, prob: 0.03005957417190075, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "29\n",
            "9592-20210624-55-103206_6d8e6e1d8d66a504d4fe90ba1e30d96e7b0c70d854c11151d78be40bba46a5eb.JPG\n",
            "target: 1, prob: 0.9692112803459167, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "30\n",
            "9592-20201029-55-110211_0fc861c5e5e2952c09d2ab11907d9921deb64ee2545bfe3d3312baae224d7956.JPG\n",
            "target: 1, prob: 0.9886024594306946, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "31\n",
            "9642-20191030-56-132730_2df4e2995bea35e78432bd019d50d8305ee8d503f90918846b3e6b721d4ea7de.JPG\n",
            "target: 1, prob: 0.9356877207756042, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "32\n",
            "9642-20191114-56-112207_509582479f1b15a6a65a9113d6229ec085823ebb8071a46f959a25ed40bd481a.JPG\n",
            "target: 1, prob: 0.9994099140167236, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "33\n",
            "9592-20201008-55-121032_a626e4fb0a575e34037351f3cfa6f3a4df5309c73a746616178e272e028fb6bf.JPG\n",
            "target: 1, prob: 0.9856895208358765, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "34\n",
            "9642-20200312-56-105617_22a8983877e35a6f98f69a1ab950cef98a8717c6fecc18f259aab6185be7083a.JPG\n",
            "target: 1, prob: 0.9957407712936401, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "35\n",
            "9642-20200409-56-131432_1d9e82fde5626956444907ac87adfe7e573d8f69a5a805672fa0421a78440d3f.JPG\n",
            "target: 1, prob: 0.999743640422821, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "36\n",
            "9691-20200325-38-111049_bf1c4e5f7ee37c948f37c28a6948b09bb1f458ee05d388dce80668e5fbf321fc.JPG\n",
            "target: 1, prob: 0.963475227355957, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "37\n",
            "9642-20200624-56-134857_e9c2f6b17a824db0dc55f0737ca3186c9131424bb443615d03f7d3a8e697163b.JPG\n",
            "target: 1, prob: 0.9997888207435608, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "38\n",
            "8721-20210521-18-104424_5810331eadb48aa353de8a517a47f05e7e5c401809756aaf67cc7141915e4d8c.JPG\n",
            "target: 1, prob: 0.9999498128890991, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "39\n",
            "8565-20201204-53-152448_4b97ae37ca6c187ade3108dc58e41f4db14f54a357dde47317616e08b735b958.JPG\n",
            "target: 1, prob: 0.9998410940170288, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "40\n",
            "8565-20210416-53-151347_1486d9480c6d48884d06f33f42ff9b0456d4393981d83be45a73989757a9fd7f.JPG\n",
            "target: 1, prob: 0.9926377534866333, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "41\n",
            "8565-20210618-54-124304_89cf8d83dc172b2cbf2ffc9c0868b06d48076c6064fd9227d69536d25e5fa1b9.JPG\n",
            "target: 1, prob: 0.9894118905067444, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "42\n",
            "8565-20210319-53-152823_aba85e610ec126f823146ebeb7ed46912017275238c50fa6aa6de2de746836c6.JPG\n",
            "target: 1, prob: 0.9913429021835327, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "43\n",
            "950-20040928-33-091533_6ffa9471efe3324ca8ddf29365fdb2819b9328b27210e6d77be9f6570726b484.JPG\n",
            "target: 1, prob: 0.9702430367469788, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "44\n",
            "950-20050913-34-120832_f0a0c94b0946325ed513e5dc69a96d5503e71e96bcf2af3d778059dd70b0bb1d.JPG\n",
            "target: 1, prob: 0.9898697733879089, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "45\n",
            "950-20041109-33-144208_cc81a8b5fb1367cc6de07b9ddf1998365edc757a32753d0f00fc72a5e3121233.JPG\n",
            "target: 1, prob: 0.9996931552886963, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "46\n",
            "950-20040706-33-093042_a41ecc9e3babc818120bacad265bd605287cd00da9180d07ac1a908509b2efc9.JPG\n",
            "target: 1, prob: 0.9953716397285461, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "47\n",
            "950-20041214-34-104614_f0877fea5cbb86e478b0de3f10df1cc1c4f4583e3e1d21627eb9ad37b4c6ff7d.JPG\n",
            "target: 1, prob: 0.998492956161499, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "48\n",
            "9642-20200520-56-132159_1956d77522d2ac4d29cecee57877999d17c408e54e953a75b1717ed7e58c92d2.JPG\n",
            "target: 1, prob: 0.9999648332595825, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "49\n",
            "9642-20200109-56-105601_8bcf706a3b03aa507d8335497ae1b7d21d558d2b6190d1b63780fa34510eb02e.JPG\n",
            "target: 1, prob: 0.9999167919158936, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "50\n",
            "9592-20201008-55-121032_0f021eb622f135a69a3009aa9add129bbef4c3d34f32716fae244214b5208948.JPG\n",
            "target: 1, prob: 0.9992735981941223, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "51\n",
            "9642-20191128-56-110509_fbf10a147d590f66485eb2b949c037a2f97ca46c568e584523ae4d917c16b372.JPG\n",
            "target: 1, prob: 0.9964333772659302, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "52\n",
            "9592-20200730-55-124408_57ea0b885c19cc442a113cc7f9b70263e7b2ca49547c0bdba2587754e759c753.JPG\n",
            "target: 1, prob: 0.9999744892120361, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "53\n",
            "9592-20200820-55-122941_0ebe11a4e33a749021602b3e94aeffdab7e7e0dd8bd11378f4c9d5853c947130.JPG\n",
            "target: 1, prob: 0.9978454113006592, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "54\n",
            "9465-20201202-43-090550_8064c22abe3e5e30f19591d79eb8d2e9274ebde2e1744cda4207b1f821f927e1.JPG\n",
            "target: 1, prob: 0.994422972202301, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "55\n",
            "9190-20210319-67-132838_95271587cbda7edca78c061c2068ac587a6ab362c087e2de25ed6749fdd1dbd3.JPG\n",
            "target: 1, prob: 0.6713878512382507, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "56\n",
            "9462-20200909-36-130338_5e6387487974bfb1d48bfbc67423e209a6b124b341891dd1e2f7ea04f08fac56.JPG\n",
            "target: 1, prob: 0.9994738698005676, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "57\n",
            "9190-20201218-67-133935_f72ea665df00cb6b13bb2f697fc012a706636d61208f340161b4a3c017ec4803.JPG\n",
            "target: 1, prob: 0.877742350101471, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "58\n",
            "9465-20201021-43-102816_b25c2b19c3c4c9ec9106a496d907d9f3fd008cae0b3e6a7c3fc6ff3c35a2ab8d.JPG\n",
            "target: 1, prob: 0.9970728158950806, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "59\n",
            "9592-20200910-55-115132_1bb043f1cdd0c5031fc516677827196713c38819404e63a7deb645ba0e8a5f87.JPG\n",
            "target: 1, prob: 0.9994878768920898, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "60\n",
            "950-20081008-37-143305_05f7ba4aecf6257a2f620736ebcd3821cce8d085e48f08c826881c5a219efa9f.JPG\n",
            "target: 1, prob: 0.9993858337402344, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "61\n",
            "950-20031112-33-111716_ae02ddd778db5d129aa8441ce7846a1c876f37fc1ae8d4277a35dcbcac1a2493.JPG\n",
            "target: 1, prob: 0.9998753070831299, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "62\n",
            "950-20031209-33-100600_527fac563a5d5bc312b754aa359f08c49b1ff3d75123a029865b9b5d3ba1242c.JPG\n",
            "target: 1, prob: 0.9986347556114197, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "63\n",
            "950-20070912-36-150513_17f85cb76dceb24dd3049319ebc3ef98302d6d1e9810d8d00d7fb4ff9a695579.JPG\n",
            "target: 1, prob: 0.9999879598617554, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "64\n",
            "950-20040127-33-091511_bb41a6d10e05419eafce48bcde4e78bda3f2806a9018bfe823007124ba096871.JPG\n",
            "target: 1, prob: 0.9999493360519409, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "65\n",
            "9465-20210618-44-153346_88d826ac77f604bca08b1da5b5e63edaf12ee41786c61a9e760107c2e1328dbf.JPG\n",
            "target: 1, prob: 0.8991013169288635, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "66\n",
            "9465-20210402-43-162602_93049e96957cb5cfb32df7477275d33748c0b28460a6c11d74c3a09a591bf81d.JPG\n",
            "target: 1, prob: 0.9924445748329163, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "67\n",
            "9190-20200918-66-125351_a85620f64ec290dc26d8195bdc7d1f9dfa54170a3730248214ed7470201d5e3a.JPG\n",
            "target: 1, prob: 0.8289129137992859, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "68\n",
            "9190-20200819-66-125209_4083e0d80b744b3c2cca36de3a45955bb8613ee09438fb47e2defad5642d0995.JPG\n",
            "target: 1, prob: 0.45509615540504456, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "69\n",
            "9465-20210217-43-153900_b28a780ab50e1afb6a338e8d497a10a70657f4bdacd66b3051b051f7cd3a8c6a.JPG\n",
            "target: 1, prob: 0.9975765347480774, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "70\n",
            "9190-20201016-66-134338_9592e46c45439de3eea907a21ae9550d5763ec9fb3e00eaaeddca7ccfd1b28b5.JPG\n",
            "target: 1, prob: 0.1411963552236557, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "71\n",
            "8381-20210324-53-095657_afea3b4de8fc159fddaf54f37a9584e219fdaba6077072bdd0e7678ffb2bd155.JPG\n",
            "target: 1, prob: 0.9998764991760254, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "72\n",
            "8381-20210407-53-135707_b99e942326fa6872760730c65173b374455f44f4ecb9a034e885d4f927c4ebf3.JPG\n",
            "target: 1, prob: 0.9985051155090332, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "73\n",
            "8381-20210630-53-103801_10d6c0437172927bd931523ad7ec79e54dc324703d6933312a6ee98cc27e4739.JPG\n",
            "target: 1, prob: 0.9986270666122437, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "74\n",
            "8381-20210402-53-124527_cac6b4f69466bc96b3d304c98f7e77641b9396e688af3170fdd2ed26cbc989a2.JPG\n",
            "target: 1, prob: 0.9997797608375549, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "75\n",
            "8168-20021224-51-095200_d3fcba24e18d9e520743bbe83ff54191a78e11a9eb7ff1f4d4ea6d5374adea1a.JPG\n",
            "target: 1, prob: 0.9995179176330566, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "76\n",
            "9001-20210623-58-122354_beb825e46b94cbfeaeb141c906b38d09cb4253e926d66970a610357d80f8f0b6.JPG\n",
            "target: 1, prob: 0.9949198365211487, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "77\n",
            "9001-20210526-58-103753_06bf6095623d8d8a4f9e28147d74431b521f4780783e851739f60aa9bfa9bfb3.JPG\n",
            "target: 1, prob: 0.9982303977012634, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "78\n",
            "9001-20210609-58-120007_703cb3dda5f6a6cfe296a21606d0e79eb6dfcd9a334b69a18b60f46150bcc665.JPG\n",
            "target: 1, prob: 0.9999818801879883, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "79\n",
            "8565-20200918-53-123210_4ebd563784162623c3c6d20f83c900bf421a2d60a9647772f200a5e4115f0056.JPG\n",
            "target: 1, prob: 0.9999961853027344, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "80\n",
            "8565-20200812-53-105911_861d7951bac3f34b2f0baf4880ebd4982c8991f5f3ec975404ad9e6fc276cffb.JPG\n",
            "target: 1, prob: 0.9999514818191528, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "81\n",
            "8565-20201016-53-132053_426c2c20300b315e843411e177593a857be3bceb4cb2822b7f01047774bdca5e.JPG\n",
            "target: 1, prob: 0.999692440032959, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "82\n",
            "8565-20200701-53-122950_5b345273f21e1a3cbc00ab1192bf16cfad9444d5e07cd14134c9004966e364d2.JPG\n",
            "target: 1, prob: 0.9993247985839844, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "83\n",
            "8527-20210707-43-122445_3f5cee101db4626616516970d84332280101174293dcee217239c1907b8de649.JPG\n",
            "target: 1, prob: 0.9016810059547424, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "84\n",
            "7455-20060222-42-104847_6ea9a8030463ad6b46b8d93b9e7b52697e5386d622d06365f3ce702f2443233b.JPG\n",
            "target: 1, prob: 0.9999775886535645, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "85\n",
            "7455-20051122-42-111733_ca4f2665058651d6333cc7ba658e92ae00d5f1091e6232a44d1eda5d3bbf28b6.JPG\n",
            "target: 1, prob: 0.9999444484710693, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "86\n",
            "7552-20080603-59-115144_b318325a3ecea8ec4980338945c3203a71507d5a9069d074192d2412f61432ff.JPG\n",
            "target: 1, prob: 0.9990346431732178, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "87\n",
            "7455-20060927-42-105923_327c4f5f77cb49725929e10da90a3db9742974f62cd1656074631636058facec.JPG\n",
            "target: 1, prob: 0.9999843835830688, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "88\n",
            "7455-20070418-43-102737_da3b9bc6f0acc847d60e0b7b46c02a802af945a1a5f2f8345ec6c32bcb84c544.JPG\n",
            "target: 1, prob: 0.9999809265136719, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "89\n",
            "7800-20041005-15-093749_0f794453ad9c70dd5987f3a06ff5d2f0d1b3b6b5f6538fa32c1b36c1dfeccbb8.JPG\n",
            "target: 1, prob: 0.7990260124206543, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "90\n",
            "8168-20021126-51-105344_e96372e36173843915e843db4e627c818c786629108f5e79a027d9d8b124b3ea.JPG\n",
            "target: 1, prob: 0.999958872795105, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "91\n",
            "8184-20020305-50-144449_96eac32752f5535cb9559f779ce289abf806547e43fcaadb483e4dca681378b5.JPG\n",
            "target: 1, prob: 0.9999277591705322, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "92\n",
            "7709-20151028-52-104805_0d928bdfd37624acf47d98d5b6d05f93676ad8479dafc3e2062754807c7c2f8c.JPG\n",
            "target: 1, prob: 0.946316123008728, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "93\n",
            "7765-20140108-39-103721_9cba34972653b4379d8a2be491e4514ab8edf45bf313fe762a31542fece1f812.JPG\n",
            "target: 1, prob: 0.9950293898582458, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "94\n",
            "7349-20170426-52-112739_3e567ae51f26d24de1124dbf6e14bfebf50a818f59768f22143354556df9cc7f.JPG\n",
            "target: 1, prob: 0.998465895652771, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "95\n",
            "7349-20170628-53-084428_f6e95bc3db2cb8121bbe80bb8ce20093be492a9a8717a07b32d20f50a4795386.JPG\n",
            "target: 1, prob: 0.9037243723869324, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "96\n",
            "7349-20170524-52-094106_1e762d7108626c5c4ebe1f6644185481a88d44d02cc4fa3b137dda8357125a68.JPG\n",
            "target: 1, prob: 0.9999797344207764, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "97\n",
            "7349-20170920-53-093607_feb19dfc99f71409fe001eeea3fd930c25264a8de59255582d817561145f471d.JPG\n",
            "target: 1, prob: 0.9980239868164062, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "98\n",
            "7349-20180725-54-102850_023e18bfc92627169944678b59445d3f56ba7bbb63133f4073c1378315543df5.JPG\n",
            "target: 1, prob: 0.9865542650222778, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "99\n",
            "7436-20200605-66-103323_91a56c6a08596bbc9df8be6ac1b872d10ec1e54fe5df654995ebd765c3a88b52.JPG\n",
            "target: 1, prob: 0.9775940179824829, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "100\n",
            "7436-20190125-65-112422_5c8d54a342837b2712c509c2b5b263b16aafcbcc613dac426c5e9a7af070d4d2.JPG\n",
            "target: 1, prob: 0.9724595546722412, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "101\n",
            "7436-20190918-66-105918_07a6610f87c9e5b97c0c5f513be92e2a382d560e00ac3a3ff08f47c551a564ca.JPG\n",
            "target: 1, prob: 0.09384799748659134, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "102\n",
            "7709-20150930-52-104212_c488e22fd06de2c04ed3487babb246d44eddf933d4ee2e5492fe17568902d01d.JPG\n",
            "target: 1, prob: 0.9737453460693359, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "103\n",
            "7349-20160914-52-100416_9710fe317b0184226f614adb5488eaf77b1b45dd0b970937ab648876f0f40ccb.JPG\n",
            "target: 1, prob: 0.9999268054962158, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "104\n",
            "7349-20160831-52-091556_cfaf760aeaeb50426b4e22c76ec754ef81b50bd66d68f82f90df242df84fd11d.JPG\n",
            "target: 1, prob: 0.9999958276748657, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "105\n",
            "7349-20160928-52-100000_e0e10bbe2bf09b7da5ebfc3e23919478c241f9a1b5a42480536af1def645d2bc.JPG\n",
            "target: 1, prob: 0.9999978542327881, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "106\n",
            "7349-20160802-52-153841_10ea642c91b433cb98beb1b8e6fb9653b35a1719338f6f7da54892e39af95a8a.JPG\n",
            "target: 1, prob: 0.9999990463256836, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "107\n",
            "7349-20160802-52-153841_f5b6ba1391d79ba0d67fc86c6b92368927437f2154dc557f952823df8bea4735.JPG\n",
            "target: 1, prob: 0.9999961853027344, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "108\n",
            "7436-20181107-65-115255_6c74e80f30d9122a5a7777f1f2ad0f0a91c83ee9dec9860f8c9f7c1a69c1af5c.JPG\n",
            "target: 1, prob: 0.9980344176292419, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "109\n",
            "7349-20170125-52-110907_4b088355904d46e80c905da0e312966b7f77f172343a7a78db7f8104a7483081.JPG\n",
            "target: 1, prob: 0.9999903440475464, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "110\n",
            "7349-20161228-52-111636_e0085799d160a6fcd3b604e74dcf4596d239bd07d19b389e50356fa77d2e4f0c.JPG\n",
            "target: 1, prob: 0.9999983310699463, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "111\n",
            "7436-20191113-66-115758_8a28cb07bf57b453c44ddab0256896af9adf986578eb3a7f59bb24ea608546c8.JPG\n",
            "target: 1, prob: 0.5097496509552002, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "112\n",
            "7436-20181107-65-115255_57a00f5de77daebdff687179ff7bc54886d53ad00588c25f24c0b22711a56fa4.JPG\n",
            "target: 1, prob: 0.9984955787658691, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "113\n",
            "6599-20200402-70-085513_2b0f62fb41362956d11e8aade865aaedafcddee0af5fdc014dfacaa3f6ce278e.JPG\n",
            "target: 1, prob: 0.9999991655349731, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "114\n",
            "6599-20210318-70-084950_989e7c176f308d4a7221b42dd5d28047a27ab68ba3d671e65ae2f6bd3d1a2389.JPG\n",
            "target: 1, prob: 0.9998993873596191, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "115\n",
            "6788-20030826-25-122252_2688c214dd736ee1386838a425653f25ff43d83f7aced3e5132fa4f0f429709e.JPG\n",
            "target: 1, prob: 0.9996864795684814, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "116\n",
            "6788-20030715-25-091233_52b23e732475902e91f588ca219ebba249fd4c5f404af60d7cdeccf2eba2dfbe.JPG\n",
            "target: 1, prob: 0.999515175819397, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "117\n",
            "6599-20191002-69-085246_9f1be3816bf28e9ef7f1aeb288edf069d1e83b4bee24b21ef67b798458c5f1ed.JPG\n",
            "target: 1, prob: 0.99338299036026, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "118\n",
            "7044-20190731-54-122517_63b9160e8b110271a1a009e42bc07bcffe65d37642461d186152946c0956cbea.JPG\n",
            "target: 1, prob: 0.9994569420814514, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "119\n",
            "7044-20200417-55-115247_7cf6981233ecd3547cac76a5e61c59c425bd4522f56c715ba6db873ee1de90eb.JPG\n",
            "target: 1, prob: 0.9997290968894958, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "120\n",
            "7044-20190723-54-093219_d4d912a185eaa2bef8e82defb2efa7552c4b3abc4bb23dfa20e52622c43e2237.JPG\n",
            "target: 1, prob: 0.9969350099563599, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "121\n",
            "7044-20200117-55-115539_9b79b455516203e202c8ff9b0146d8075e7d7eed53128035df606e5efb3af785.JPG\n",
            "target: 1, prob: 0.06610686331987381, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "122\n",
            "7044-20201016-56-115256_5af00c98ad096060ba87799bcedd62b63c8b667471a98e0c30f4d3a122db325d.JPG\n",
            "target: 1, prob: 0.9580582976341248, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "123\n",
            "7349-20170201-52-093426_99f50f99ade67a9b2ffeee5a7d932a6e912fbaeb09226fd97031927d16edcbed.JPG\n",
            "target: 1, prob: 0.9999985694885254, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "124\n",
            "7349-20161130-52-112238_ed95995be9a48cafcd1d9a41787fca3538381c8c2efa4162e0f9e88428b3b6e2.JPG\n",
            "target: 1, prob: 0.999993085861206, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "125\n",
            "7349-20161026-52-105614_81b4333c43661c9384c0bfee61f093a12d4c830c55da723caea7ab2dd2115f07.JPG\n",
            "target: 1, prob: 0.9880632758140564, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "126\n",
            "7349-20160615-52-092932_32560302c29b2de3757956fe1d70d5260cbc4ef43aa1f4927d696eaa2e9a25cc.JPG\n",
            "target: 1, prob: 0.9989306330680847, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "127\n",
            "7349-20160525-52-120046_506e7cacd3e402d922e6b1282c87698f178ed52c06450cd0c676b00758fdcb31.JPG\n",
            "target: 1, prob: 0.9923920035362244, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "128\n",
            "7349-20160928-52-100307_43262b9a96f851d290897be0b722a78588516967157ef1ec04db6906e6971d17.JPG\n",
            "target: 1, prob: 0.9999463558197021, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "129\n",
            "7349-20160608-52-090341_843c827686b76f86d460945d27a8bf77e5e38c2bba243260d64e605581bf409b.JPG\n",
            "target: 1, prob: 0.9999822378158569, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "130\n",
            "7349-20160629-52-101409_f3405034329a849ff4c1f7ea67d6a70b208e36ff17ef29477dd5b88c4da8b276.JPG\n",
            "target: 1, prob: 0.9999250173568726, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "131\n",
            "7295-20150225-27-130004_e7e8e7ded29c914f56fc28d09710f8839e238103ac890ca20cc270b5245673dd.JPG\n",
            "target: 1, prob: 0.9916611909866333, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "132\n",
            "7044-20190717-54-092656_8f100fc367b72c377785a6fd1a291807c58837775c25f55de3eb55e9ea2b23c1.JPG\n",
            "target: 1, prob: 0.9995119571685791, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "133\n",
            "7044-20190710-54-100043_b3497bf9ad4764bb1a603b618c927ae36d12666a4fef6830e12bf77786bde075.JPG\n",
            "target: 1, prob: 0.9999784231185913, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "134\n",
            "7044-20201204-56-161006_1942e69094ac9a2bf57b9679cea36fe7b4c6c0655f138c1103e888fa98d95c47.JPG\n",
            "target: 1, prob: 0.9999889135360718, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "135\n",
            "7044-20191018-55-105247_88e9624ce6e92aa8415ab2d7c02f78851683d25a495e29cc453bd186c518d2c8.JPG\n",
            "target: 1, prob: 0.985716700553894, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "136\n",
            "7044-20190723-54-093219_6c34d4b40549d0acbd87caf28fb25faba8fae2fbc1c55ed578396aa657b9623e.JPG\n",
            "target: 1, prob: 0.9994833469390869, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "137\n",
            "7044-20190703-54-155954_314dd23933842be854af6866ca3408c6adcbcf7dabe069acfa3e3e32c616b20a.JPG\n",
            "target: 1, prob: 0.9995338916778564, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "138\n",
            "6599-20121012-62-130503_1d89aae6acb606b3f6bd637c41630411e36b95aef7dcfede83f285eb7221aeca.JPG\n",
            "target: 1, prob: 0.9999988079071045, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "139\n",
            "6599-20130619-63-084908_73634c6bd81f607bf7e7ba41caf3b4a196b0da4ea20c185e5f421ec099cb582f.JPG\n",
            "target: 1, prob: 0.9999929666519165, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "140\n",
            "6599-20140305-63-090619_187a2689b3c330ce1d8277196edc877351d8e8f6a9dc48ab192e540443137eae.JPG\n",
            "target: 1, prob: 0.9998624324798584, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "141\n",
            "6599-20110722-61-000000_a52ff6237571c9578f1f7525e8458dbf2596ecefb8c0ec6810e935e72ea6b5dc.JPG\n",
            "target: 1, prob: 0.9999797344207764, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "142\n",
            "6599-20131023-63-084647_e6b2d45085ed04d6177f40089641328c231afe510b1b2cea60d7dc4d114c3bac.JPG\n",
            "target: 1, prob: 0.999629020690918, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "143\n",
            "6599-20180927-68-085535_7203a9f94a4f4f84a65252d16dbd10a2b7eaf58f7e51bdbd10ac6d654c85e269.JPG\n",
            "target: 1, prob: 0.9999738931655884, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "144\n",
            "6599-20180322-67-084644_9097e36c815cec156e2775b04ff4faaedb3065a14aa9c63ff6368cd9670c9e6a.JPG\n",
            "target: 1, prob: 0.9990052580833435, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "145\n",
            "6788-20031202-25-115435_0e779ae8c09e4d6389511057819e7c6ba303ebe31f84fe3d00502adb8889a93f.JPG\n",
            "target: 1, prob: 0.9998905658721924, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "146\n",
            "6599-20190404-68-084952_0aa338aab824fbdbb04b780fdc4a768b8a52cdd1aad6049b7a5da0483239bb4e.JPG\n",
            "target: 1, prob: 0.9971635937690735, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "147\n",
            "6518-20070605-49-142047_1829ba081eddd5ba516140295b8a7681cb4629a5bdbc5a4b13d094424c02ab3b.JPG\n",
            "target: 1, prob: 0.999862790107727, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "148\n",
            "6599-20100531-60-092536_8cc1efc41109bff55ff9345135cb5e172432f4dbadcd1d24e6bf19066db32603.JPG\n",
            "target: 1, prob: 0.9999984502792358, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "149\n",
            "6513-20090304-45-103211_67b17b0bf265778830fff0ddc4a2ad5a1d6add6ca9dc7822b9c3073b9596ebf0.JPG\n",
            "target: 1, prob: 0.9997195601463318, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "150\n",
            "6518-20070320-49-121440_cc0ae00135b5c10316376eee0d94e94a2ebeb84df5d864137999964f31c90ac9.JPG\n",
            "target: 1, prob: 0.9999966621398926, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "151\n",
            "6489-20000516-51-120837_ddd2c9e800d1d193e8068812747f24336de4fca3a7e6f2a3c18153f7050521ed.JPG\n",
            "target: 1, prob: 0.9999710321426392, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "152\n",
            "6599-20170316-66-084913_78814416484a68aff93a2870163a6ceccf3768e72595752ae423eb9be34751f1.JPG\n",
            "target: 1, prob: 0.9999986886978149, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "153\n",
            "6599-20170921-67-084834_a150cd306d4582ea64e053dcde3922909f54b1f8d34dc8a3dabe9e0fabe33df0.JPG\n",
            "target: 1, prob: 0.9999978542327881, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "154\n",
            "6599-20160317-65-084419_975db7199ff9726c5d427a5fb0fd41b4227e7772ce3848496518f84f6c5cbf5e.JPG\n",
            "target: 1, prob: 0.7404605746269226, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "155\n",
            "6599-20140917-64-084308_e38736803f1e54e8e76747262d27ee0b8bb0b060be951c25c6fb3125e7ce11e3.JPG\n",
            "target: 1, prob: 0.9987630844116211, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "156\n",
            "6599-20160915-66-085242_17aa86a67720f7a347cd155ce526fc88150eebde6028eaaa9f7a03033bcd254f.JPG\n",
            "target: 1, prob: 0.9998119473457336, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "157\n",
            "6599-20100614-60-085456_d9ddfd875877de4be4aae378abbd4885aacd3effacaa0bca450aab0342928142.JPG\n",
            "target: 1, prob: 0.9999761581420898, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "158\n",
            "6599-20100720-60-144133_89a17d60dc877ee6164fa2e32d77b9457880907cded269db3e4a777fe41d5d88.JPG\n",
            "target: 1, prob: 0.9999898672103882, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "159\n",
            "6599-20150317-64-085616_568a78e545c8434dba591adf73ccc60aee24244738c66b9f2f4337663fdf6c2e.JPG\n",
            "target: 1, prob: 0.9999961853027344, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "160\n",
            "6599-20101012-60-152819_6535526313dbde212777ad1d44cb78f6956d5a823820bc8b0ad7ee642d7c0b70.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "161\n",
            "6599-20100914-60-150552_c297e5a96b892e50bb095ab5375fdf0e2573a290d3654ae883b8b18a45138a4b.JPG\n",
            "target: 1, prob: 0.9999982118606567, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "162\n",
            "6599-20100628-60-085022_df1c68d12ca985d1ac87fa4038f6087816e3f4adf43b611bbcfaef7a016fb743.JPG\n",
            "target: 1, prob: 0.9999978542327881, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "163\n",
            "6599-20100817-60-143618_ff44ba8695b5420006e9fce799100930bbb5dd98dba08575fa30a1d2307bc0c4.JPG\n",
            "target: 1, prob: 0.9999994039535522, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "164\n",
            "6297-20190328-62-150559_c2835f175335ad4a067d89f23ae719b89b4133703c990b38a9be8034ad860989.JPG\n",
            "target: 1, prob: 0.9808366894721985, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "165\n",
            "6297-20190822-63-155834_7e1a7ecb9c7eb687e6e07e5411621dc92fb7d2a70d0d38116066397d44b58cbd.JPG\n",
            "target: 1, prob: 0.9795971512794495, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "166\n",
            "6297-20190926-63-151906_11b3cb15517a6bf0b48a8ebc14791207bb917db6aa13018d8786194eab10b252.JPG\n",
            "target: 1, prob: 0.9974637031555176, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "167\n",
            "6297-20190718-62-150316_3893eec91c7d40fbeaa0e990a330865968b99b83248ed7c8ff739199b735a741.JPG\n",
            "target: 1, prob: 0.9999861717224121, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "168\n",
            "6297-20190620-62-144457_bb4bd4db9dbceb4e57d776ee7fcd7896176dbf502fc4a36a2e78f193e95c22da.JPG\n",
            "target: 1, prob: 0.9999816417694092, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "169\n",
            "5913-20190703-23-084042_12a682aa4ec96fd24c8ee3ad706ec92213f6dc75a3cfb9409d48ae755a3b4832.JPG\n",
            "target: 1, prob: 0.9999599456787109, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "170\n",
            "5913-20190621-23-100241_81e63395f36fb4771f58fc1c49a50a219199440e300d5595948953f42382bef4.JPG\n",
            "target: 1, prob: 0.999308705329895, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "171\n",
            "5913-20191008-23-100425_4f611be95bb75ecbb126e535149855ac3ee3d3b570bc404655d75f2f80614350.JPG\n",
            "target: 1, prob: 0.994831919670105, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "172\n",
            "5913-20190821-23-090659_3817129120c0d22aeffd26b05b7fbf0e379474304dbbe6d3cbdf60f2178f90ff.JPG\n",
            "target: 1, prob: 0.9999734163284302, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "173\n",
            "5913-20191115-23-102736_51eb38f2a91198869360f7eb8091755d1783e115785564b4aa160893c333ddcc.JPG\n",
            "target: 1, prob: 0.8357606530189514, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "174\n",
            "6489-20000404-51-150053_81f802978e6c926458469e9e1c1a0354c3b192f07ba759967fa5a004feec8f04.JPG\n",
            "target: 1, prob: 0.9999972581863403, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "175\n",
            "6297-20200319-63-133702_924efa7ca49929a090c79fa570495a318322a102ba22661cdc35587a9724c7e6.JPG\n",
            "target: 1, prob: 0.9967345595359802, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "176\n",
            "6297-20200123-63-143919_e26076c2add9d4888ead130f17de3845b88b388cd4a28318265ac01d818c0706.JPG\n",
            "target: 1, prob: 0.9999902248382568, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "177\n",
            "466-20120525-24-161722_e0d902823385b8c9baecbb998560353cfd4b2edd74ff630411111a1cbb483753.JPG\n",
            "target: 1, prob: 0.9999995231628418, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "178\n",
            "466-20120720-25-155410_5a671a27d5ad2127726d9b5377ac5e1aa6d88dcc057c9143769f96b5f14bf73b.JPG\n",
            "target: 1, prob: 0.9999990463256836, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "179\n",
            "466-20120330-24-154422_df6e94b3494f4208bade664eb763f1a35cd9b5976a22f7e6833bcd0f82b57e8c.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "180\n",
            "466-20120622-25-154501_c2db73893cb46a005c185692c7afcc0a33ad36e5aab69fb1958b203e86cdbe29.JPG\n",
            "target: 1, prob: 0.9999996423721313, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "181\n",
            "466-20120928-25-152015_3f07586695fae118a68890e32b5e4b498f63e62402abd02a2618f0243935289a.JPG\n",
            "target: 1, prob: 0.9999995231628418, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "182\n",
            "6486-20011205-39-112916_cbf8daeda33f069052ad0315ca57fe8bfdace7da1a3dd9779772ce14da695cf9.JPG\n",
            "target: 1, prob: 0.9998677968978882, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "183\n",
            "6486-20011024-39-113607_4cd00e24c81cef9ffe0ec9656a77fdc42c0d6734cd4fb15a4ac577deb50240d7.JPG\n",
            "target: 1, prob: 0.9999712705612183, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "184\n",
            "6297-20190515-62-132014_fcd9fd3c48b64dd4f453b6c0e2ddc4e15d43a50b624f74ca559038f394544127.JPG\n",
            "target: 1, prob: 0.985346794128418, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "185\n",
            "6297-20190130-62-122238_b8086e7d9caa03de8ae9410880244970973461c635624a5489750a277e612a77.JPG\n",
            "target: 1, prob: 0.999881386756897, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "186\n",
            "5913-20200407-24-092730_141466f4cb102dee9fb49c0a0b3a3667f466996a3c412f58754cdfa6af50b95e.JPG\n",
            "target: 1, prob: 0.9822238087654114, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "187\n",
            "6297-20191121-63-143245_3d2f5f88f35d45f8604e64c8f3ae685907bd80227be8a3e8d60250e18e6c20ff.JPG\n",
            "target: 1, prob: 0.9992303848266602, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "188\n",
            "5913-20181219-22-094638_4a491501ab000f2f0050ac34ddc153746cbbc0569f0cc093449774caeb3b97b6.JPG\n",
            "target: 1, prob: 0.999961256980896, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "189\n",
            "6297-20190228-62-145433_7c989997a5a822e81286a8af535f8192c017df4e5165773f40f263b40dde1e42.JPG\n",
            "target: 1, prob: 0.9999827146530151, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "190\n",
            "555-20011030-54-100509_e8f161278fbcf526adc6230bcbb124860947bf6c87935fb65d96577582da551d.JPG\n",
            "target: 1, prob: 0.9929797053337097, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "191\n",
            "5913-20171226-22-122450_afc9a9d93884035880cd36f24ce5124e43339395d71bc02e8a98659a27aa89ef.JPG\n",
            "target: 1, prob: 0.9999597072601318, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "192\n",
            "5913-20171226-22-122450_ca1a7d1c8d46118589979462ac6a97150c89830ad28edc4ca5016302ae4e7e24.JPG\n",
            "target: 1, prob: 0.999932050704956, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "193\n",
            "555-20020723-54-103940_ec45bd3e4660382ed3a5622330b8c15d2ceac0809d66ef551b26c6f2b6467de4.JPG\n",
            "target: 1, prob: 0.9984122514724731, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "194\n",
            "5888-20090106-52-110956_f64050e0d2980a80d055c2cbd8a9f3ebeb27330a96e22e8ea1cb1bdf2f50270f.JPG\n",
            "target: 1, prob: 0.9999966621398926, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "195\n",
            "6297-20190207-62-134201_0c0f89599031cffcca5d523b8221ef1a2fb8c2582c74bef787faa151e7c3718d.JPG\n",
            "target: 1, prob: 0.9999768733978271, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "196\n",
            "5913-20180919-22-092503_ba7b602365c5249794cc5649bd5d307e8f0791c5886c49b61fb9ec32d51cbe19.JPG\n",
            "target: 1, prob: 0.9999617338180542, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "197\n",
            "5913-20200221-24-103529_808035888f8a9b2d3f0268d69e4700a10310e721d1dbbe9c0de89d0625ea061d.JPG\n",
            "target: 1, prob: 0.9990261793136597, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "198\n",
            "5913-20180411-22-085039_c366d1a3b664a2a406d21de33b178a8cccdf6c3990424df3881289b1253c3ffe.JPG\n",
            "target: 1, prob: 0.9999250173568726, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "199\n",
            "5913-20180725-22-090732_b1c81885ea3fce60fcc0ba60a09b5dbd31161e0fdb378cfeabae85102318e6cb.JPG\n",
            "target: 1, prob: 0.9999986886978149, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "200\n",
            "4939-20090701-46-114530_7b001c93df3aed9109f3a6b67baab8567fe0603a41b567639fa00379d763f957.JPG\n",
            "target: 1, prob: 0.23955389857292175, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "201\n",
            "466-20180704-31-124749_4661a97b66be354ea7b9dd5b18848c8b17abecff165a0a3c8bd8d5d0d33221ab.JPG\n",
            "target: 1, prob: 0.999782383441925, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "202\n",
            "5021-20100414-40-105421_47f1b0eb16bc9c721bbf56dd1453f6f2621c630e383b518e6b42a5540a4fa5a2.JPG\n",
            "target: 1, prob: 0.9996249675750732, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "203\n",
            "5021-20070718-38-102740_e90ac7cd71f7ed2ccf3360ceeb6b31b56204ed65c70c348b34227b118ac3f665.JPG\n",
            "target: 1, prob: 0.9999183416366577, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "204\n",
            "5021-20080213-38-165836_a2d651f1811016cdf931969caade75d18c27450b534bc348e2094e8c6d29a01c.JPG\n",
            "target: 1, prob: 0.9999886751174927, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "205\n",
            "466-20140416-26-100135_ec0bdcaa6b02a04fa7a08031195cf5e8310d4cc1d72ffe787d8f8819b53a697b.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "206\n",
            "466-20150225-27-121630_7a09394a0252d45752f55820491f46131085cf0ed01cefa6fa4b091142a8fb4f.JPG\n",
            "target: 1, prob: 0.9999980926513672, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "207\n",
            "466-20131211-26-101408_afb71074c086b0400f92358262d947166f70ade8a48f4663f17316c2ee9697b6.JPG\n",
            "target: 1, prob: 0.9999990463256836, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "208\n",
            "466-20140827-27-124242_a1540f4c89240e9a9f38f3084c22f1c16b4b9ebb6720f71a9a18496189ee9877.JPG\n",
            "target: 1, prob: 0.9999977350234985, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "209\n",
            "466-20140827-27-124242_eb9b143fae3aafc040d8580704c2224b948deb6cdccb040e762780181cf9f1db.JPG\n",
            "target: 1, prob: 0.9999878406524658, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "210\n",
            "5337-20180110-54-115311_cdef94a2e7ecb8fe53a9c0a7e9109f948fd417d405f5f1b61dc1ce622e406b45.JPG\n",
            "target: 1, prob: 0.49073195457458496, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "211\n",
            "5337-20190514-55-104708_fa78275e51586cfc77425584a9f55878e64b992a3cebbe816e177bc687bfd395.JPG\n",
            "target: 1, prob: 0.002943947445601225, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "212\n",
            "5913-20171227-22-123452_0eeb9418a8089595e2e2f0aac2edfc226ab658fe0fa7cfeecb3ea1ff4cdb88bf.JPG\n",
            "target: 1, prob: 0.999994158744812, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "213\n",
            "5913-20180110-22-122548_88f45ebb9cdb47b50986ab36e6b56d28ed70136d1349c7c989e2e1b0541b8c96.JPG\n",
            "target: 1, prob: 0.999993085861206, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "214\n",
            "5546-20170406-80-104959_399ced20a4855e00ff8ffd862c6dc7f87a2d8994b6992ecde7197c44efee3035.JPG\n",
            "target: 1, prob: 0.04582896828651428, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "215\n",
            "5546-20170209-80-104147_fd54949e07305c05fb62923736b9d752de6ac84bceb208e5b34aa3e9138912a1.JPG\n",
            "target: 1, prob: 6.28878187853843e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "216\n",
            "466-20130524-25-155703_4823eeec895bff81c8c6d2ff366645210b47469e90079bbfbf844178979b9777.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "217\n",
            "466-20130308-25-160113_493df3176fa84ced088f557d76865c6821df61d5dff37e869024328e2812cc5b.JPG\n",
            "target: 1, prob: 0.9999984502792358, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "218\n",
            "5260-20120725-55-121924_d8b51d83ee79d9bcb13f9cc9aa663ddc8c6f6df6acea0d05499e3ded8c0c9515.JPG\n",
            "target: 1, prob: 0.2635308802127838, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "219\n",
            "466-20160224-28-132646_3e839bbe4dd4a0eecfb1304778e6a8073502054a0769f3e26d7ae57846d4609e.JPG\n",
            "target: 1, prob: 0.9999991655349731, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "220\n",
            "466-20170222-29-131213_1fad70fb4c83dbba769ffb2543ecec8797065665075bb7ec376c97f7b1e7b4b1.JPG\n",
            "target: 1, prob: 0.9999996423721313, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "221\n",
            "5051-20170104-28-133542_eb307659dead6493510b6135035231512b263366146ac1f031eb51bb7fb9f9de.JPG\n",
            "target: 1, prob: 0.2075602114200592, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "222\n",
            "466-20111130-24-000000_7a96ed80109b9a9eed4a521bb7e49c5b8131c8f0071e21da7b1ef44b253f7350.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "223\n",
            "466-20111228-24-124454_af2a544459ad078a77f803703d9a77071396728a9a7ae5cefc4d93c90b6df199.JPG\n",
            "target: 1, prob: 0.9999511241912842, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "224\n",
            "466-20120210-24-162440_688324533e842099f02aedd7d7e000d84947338c21bbd6b6b406deaecc7307ac.JPG\n",
            "target: 1, prob: 0.9999992847442627, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "225\n",
            "466-20180221-30-141111_c0630c3efdadb3b2ec8491524b3a54a192ec8bae86a5a82c5ac5b97e06acdaf6.JPG\n",
            "target: 1, prob: 0.9999898672103882, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "226\n",
            "466-20170823-30-140320_5bada852900e4d82430ca853d9c73f8cf8503a145a46d314848025566cda10fc.JPG\n",
            "target: 1, prob: 0.9999992847442627, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "227\n",
            "466-20110916-24-000000_2ee45b29e15f113542dd7ee67780ac6d8e84d9167e8ef4a6906ee2b92b644561.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "228\n",
            "466-20110930-24-000000_e22dadb07f1e534a9f180eca8e6054d6f46397e6aaa64e59152c34b605b0eb82.JPG\n",
            "target: 1, prob: 0.9999963045120239, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "229\n",
            "466-20110902-24-000000_584813e8582d00d385ff8a3e9ab242acb52e666ab8acb2d26108996cdefa3ecd.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "230\n",
            "466-20110810-24-000000_995cc27ce6d5c98ab3111cec621f11031a2c1d4520de747a08d6e685d1b11339.JPG\n",
            "target: 1, prob: 0.9999996423721313, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "231\n",
            "466-20110819-24-000000_f7d950d042ca18beca8f8b2b85b3fc280e4debfc8a650c05124bd9d5c2865816.JPG\n",
            "target: 1, prob: 0.9999978542327881, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "232\n",
            "466-20160824-29-133302_f4a547e32de7d46d074e6a12dbc5dd1c05cae03f84eea620ff3cf2e6f3cbcc69.JPG\n",
            "target: 1, prob: 0.9999978542327881, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "233\n",
            "466-20150826-28-134258_93b2342cb56aa0186eb13e50d16b3efb7a893ddb99a86bfd617a957447f49412.JPG\n",
            "target: 1, prob: 0.9999986886978149, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "234\n",
            "4209-20021001-49-083602_1276229ff8af77143406ca643b05301c73717fc8832b29d3f90a2fb4f396d882.JPG\n",
            "target: 1, prob: 0.999997615814209, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "235\n",
            "4209-20010313-48-165201_e823603be81ca6460543b4f19ed6a18b508250f811c906c65fa4d89052e32781.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "236\n",
            "4209-20021029-49-084436_d82c30913e6d4e20a6d2792b78634c8be67383d6d89408f57341bd767e4b43e7.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "237\n",
            "4209-20010130-48-134007_73ef4cdd7f34ecf5c70c955139b6829aadcdf3fc9f2e311b14979969a6f6c3ea.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "238\n",
            "3976-20000822-27-121350_5a2e2688231996d5629d6251559e2f5e3bc499499b1ff6cf6e823533b46646f4.JPG\n",
            "target: 1, prob: 0.9999964237213135, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "239\n",
            "466-20130925-26-121402_bd8d52f6d008806bf3956dd5a4457384d820dad7594cf0565c2d3cfa954d883a.JPG\n",
            "target: 1, prob: 0.9999933242797852, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "240\n",
            "466-20130731-26-122418_d2e82b25ef64e4fa1e3aef4b35e8d1157971e299e1629a1152d584043ce0ee5d.JPG\n",
            "target: 1, prob: 0.9999960660934448, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "241\n",
            "466-20110810-24-000000_ecfdff53e2eae618856b23be4ba08199cf3295a046552ba60d4d8d901f021436.JPG\n",
            "target: 1, prob: 0.9999902248382568, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "242\n",
            "466-20121130-25-154223_f477889895077fc8afd45f5a3d05c4c57b0bec54c11325a0e2c15fea72217394.JPG\n",
            "target: 1, prob: 0.9999996423721313, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "243\n",
            "466-20121026-25-153906_462caaca25d108fc6a37357c27ec18d106a229078edeadff6c904a94aeea6a2b.JPG\n",
            "target: 1, prob: 0.9999977350234985, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "244\n",
            "4616-20090107-58-142553_7f21162dfc536c6e9ab0d0fe8d12bf5723f1e0bb905c205b6fce37bdd2e5e276.JPG\n",
            "target: 1, prob: 0.995705783367157, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "245\n",
            "4382-20181114-42-133407_7ec561744e66ff5de3ff2a2e369f41bbd02b374de5adab2bbf1077011deb3147.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "246\n",
            "4577-20070320-44-095848_179cc7d2aa03f642457c2f0f05e1c21114c57f7788b1aa4479f5331df932ad96.JPG\n",
            "target: 1, prob: 0.9991497993469238, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "247\n",
            "4616-20090225-58-094820_1eb69df1f28a478d181ad708a05f45940c92e32ab1efff38220eefd242f4cdb3.JPG\n",
            "target: 1, prob: 0.9945237636566162, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "248\n",
            "4382-20190222-42-120941_61c5ea6a5ccac63885f5639936b0bbd47b31a3ed91940fe8963c8988ca972c6d.JPG\n",
            "target: 1, prob: 0.999921441078186, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "249\n",
            "466-20120125-24-122027_70aa4fa43f2cfb748c241d967b3144423e451fc8689884721ec2fd949fa9468b.JPG\n",
            "target: 1, prob: 0.9999496936798096, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "250\n",
            "466-20111019-24-000000_ac4bad1a6632682062d93e4c3476127e15a8d43b32dabbdc7d7cc214d93c1a86.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "251\n",
            "466-20111102-24-000000_1e32bf46d373f683e494ae8f39f166dcb094016544f34eb4334e451a3751edfc.JPG\n",
            "target: 1, prob: 0.9999978542327881, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "252\n",
            "466-20110624-24-000000_20d7a70815a0b8e0adb52d5e8157965aa701c21f940fb1e846438354df5f236e.JPG\n",
            "target: 1, prob: 0.9999970197677612, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "253\n",
            "466-20110715-24-000000_6b734cf698b4e458cee39aae0501bcdb2721bbbf704a11152deb5c241418c0bc.JPG\n",
            "target: 1, prob: 0.9999985694885254, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "254\n",
            "466-20110803-24-000000_7ff2c3799fdf41e433ab5e0125ec4d01c6f7b984e8b513f8f3c8da5b9bda9abe.JPG\n",
            "target: 1, prob: 0.9999985694885254, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "255\n",
            "466-20110531-24-000000_64ea2fcfaa64b81be0561536626d6ba711f243871206e846e1c5401aae898cad.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "256\n",
            "4382-20181003-42-101554_4b22ca7e43d1d84a123a439de3e495da00c788e971f6bf21bf9bf7558d988375.JPG\n",
            "target: 1, prob: 0.9999959468841553, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "257\n",
            "4652-20170405-40-094316_4a4f1d477593397c2be03fa882f8f5719cd380b60c838d9350e79da3a94d4142.JPG\n",
            "target: 1, prob: 0.6520099639892578, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "258\n",
            "4263-20170222-65-105624_3ae346a5dc3a4bf223178d73dd4869e28c23b731c95b3d456588b1c42d44b03b.JPG\n",
            "target: 1, prob: 0.9283891916275024, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "259\n",
            "4263-20170308-65-102929_30b2e0ed9e8a5050435c1023dbaffb2c2f6ac829bfbd1674154be32979c71bd9.JPG\n",
            "target: 1, prob: 0.9999836683273315, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "260\n",
            "4359-20090911-21-124731_f803767de922243c1f08de9999a153655a48dd6203cd59b93d3a135f4ae5b5d7.JPG\n",
            "target: 1, prob: 0.9999841451644897, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "261\n",
            "374-20121107-47-132847_c084dafdc6b2023c79f1e836fb7688cfd29dabe29401064d2b82009f14d25d3e.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "262\n",
            "3609-20070529-37-130219_09e44c94e120e10bfd61c88569a82f66b0e0e4e654365e8c6a2c5fe38589f9a7.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "263\n",
            "3543-20200205-59-152735_beb73bcb347e43fc64e231be8cca2210c396fb270625b9a9bccfc5d0231c643b.JPG\n",
            "target: 1, prob: 0.9763121604919434, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "264\n",
            "374-20121121-47-124340_ac7191fc38e1f0a9f40fd21e90e6bfe157e71edf1d68b8e637c64fead29ae2cb.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "265\n",
            "374-20121114-47-125926_93e40898c716fc0a9d3257e00aacdbddf000d21350ad207f061e2c9db02e08b2.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "266\n",
            "425-20060606-65-111257_2e4b2f2b49ae947efee810b3ae39b989c3d5cf7dbdb778f102d21eca86aac51d.JPG\n",
            "target: 1, prob: 0.9501376748085022, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "267\n",
            "3976-20000725-27-111425_e2c11050baee18cb4e7544172afe59bc20fa48cb681fdfc568f31b4146101cd4.JPG\n",
            "target: 1, prob: 0.9999575614929199, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "268\n",
            "3472-20160720-69-111639_931574da47401188e5fdf7b41b76ce4d99cc1c75ec6e38f5327a9fee0bd21100.JPG\n",
            "target: 1, prob: 0.9822182059288025, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "269\n",
            "4209-20021105-49-091217_9bf9f7f7150ba94c8d9d7d5a060d7329048fa882b0c133eba9c90ae73e690cbe.JPG\n",
            "target: 1, prob: 0.9999986886978149, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "270\n",
            "3783-20181128-24-125455_8eb933de9f3dd0a5f12e3a2141e6b955155f9ad8d07aab87cce013e4b028259c.JPG\n",
            "target: 1, prob: 0.9999772310256958, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "271\n",
            "3875-20051213-74-101605_7072f24f0b53e98d9d2ab51e5e40ab3e0f1c6d09fd1ff3f601dc6834699c7015.JPG\n",
            "target: 1, prob: 0.29648730158805847, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "272\n",
            "3875-20051213-74-101605_a0a0fe8fc663cc0cecde13490c5115c575e19fd80c5a0ae09aaac1e59712fdef.JPG\n",
            "target: 1, prob: 0.525349497795105, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "273\n",
            "374-20141126-49-112833_e543ebeb942c92d1817033d7cb9a9e902f46dc7666ec95d6ffcc4ccb4fd3f7bc.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "274\n",
            "2900-20091124-26-132857_d79a904809d4be27fdea0ac8aaa2a538b6a6435bc428136d9a6aee4e579063f2.JPG\n",
            "target: 1, prob: 0.9999984502792358, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "275\n",
            "3077-20180221-65-113956_0f1c17451cdfb004508a5950518bf2ebda61e371d41754dcd9e258ff4a0d41ce.JPG\n",
            "target: 1, prob: 0.9821841716766357, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "276\n",
            "3543-20180704-57-150430_9f0a104f9590d03c12faf70cd3e55aedcc3927920097d86cff24d824ca8aa421.JPG\n",
            "target: 1, prob: 0.9995706677436829, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "277\n",
            "3472-20161221-69-162624_8df5ccb89404aafbcd07d83997c8affdfc50c31bd8301ef87b4ea1a759cbbd0f.JPG\n",
            "target: 1, prob: 0.5095565319061279, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "278\n",
            "3528-20200221-19-094349_58e5ae8e53e092953afc79f4236357a6bcbd04ef66020b41ff08d08ddb30684a.JPG\n",
            "target: 1, prob: 0.9938082098960876, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "279\n",
            "3543-20180418-57-132750_128ab25b79159e4b8615cb42a4d9f3ef52b22d015946ad46bdf08b8d4d4388f4.JPG\n",
            "target: 1, prob: 0.9922686219215393, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "280\n",
            "3528-20190821-18-085434_f57cce1e3d66b41d34344c7462eb1ea1303682f7afdaa9fd017801be6442f38f.JPG\n",
            "target: 1, prob: 0.7473104596138, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "281\n",
            "374-20130205-47-145047_1a9760adaee7edb64778a7b355d1e6e889b8eda18de284a768f84b62f37d6429.JPG\n",
            "target: 1, prob: 1.0, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "282\n",
            "3543-20181219-57-150941_3b05c9734a90414fa5413280fa34965a589f29cf84c9c6661a533dde3da8119a.JPG\n",
            "target: 1, prob: 0.9995718598365784, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "283\n",
            "3543-20181121-57-152114_36c3a4f420d2ff0a3a7b085694c2465fb66e92af610f9a6fd9989c3ba9601b7f.JPG\n",
            "target: 1, prob: 0.9992592930793762, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "284\n",
            "3543-20191106-58-153338_30d05ea172054e464fe8d39ccac7f2726c4689b17df6f688c8e32b63337d4469.JPG\n",
            "target: 1, prob: 0.9783172607421875, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "285\n",
            "3543-20180919-57-144010_8544de83c55f21941bd520422615f693d52efe79e3d6416a1e2808720e21aa44.JPG\n",
            "target: 1, prob: 0.8697414994239807, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "286\n",
            "3543-20190130-57-145900_30fe61c54619efeb34f2063ff8483aa29753a1464fb9df3860dabf5f00a2fd6d.JPG\n",
            "target: 1, prob: 0.9985106587409973, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "287\n",
            "3472-20160622-69-104035_2fb262b059bb6bd66d9a1fb5c67c5b7f2f2f51887dbe3f6632c3ebab586e56f2.JPG\n",
            "target: 1, prob: 0.5017744898796082, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "288\n",
            "3472-20160525-69-114311_e3b3eef32be66eb3f5616b842704049ca9a25f10c4b2a9ddc43c649dd1d20843.JPG\n",
            "target: 1, prob: 0.9986041188240051, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "289\n",
            "3217-20030319-30-095345_cfc9822b8221bfd5458accbcbf48321090b63a61604043ac73f7596ef6b0d8e5.JPG\n",
            "target: 1, prob: 0.9999994039535522, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "290\n",
            "3217-20020910-30-113320_707b862b3a7ab6049a3b36ea786476d7445f825adc788518f45564f389f9e06b.JPG\n",
            "target: 1, prob: 0.9999949932098389, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "291\n",
            "3237-20060228-23-154207_1dd034bcc8e4eb438f4cc69985215cb32689727eb9586afef38c9a47beffc4df.JPG\n",
            "target: 1, prob: 0.4507698118686676, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "292\n",
            "3217-20021001-30-095553_7105b21ccbb43e345fb177134c6cde4216f59374a20633e802f41cf6ea7f63e0.JPG\n",
            "target: 1, prob: 0.9999998807907104, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "293\n",
            "3217-20050817-32-095528_9641e0d60b4a8ef5f31731d2a88ccd30f27f3d4a3b8f6d7c249b27c7dd3b356f.JPG\n",
            "target: 1, prob: 0.9999996423721313, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "294\n",
            "3543-20180801-57-151252_12e19c18e989e9c805278ae30bafb098c9c4eced31fe2e53c76e527f0e4ce0ca.JPG\n",
            "target: 1, prob: 0.9999303817749023, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "295\n",
            "3528-20181221-17-123344_52c304cbcd516b806a0fe63f380c93d9a4d082768faa7ff7af8d0cac70012633.JPG\n",
            "target: 1, prob: 0.760357141494751, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "296\n",
            "3472-20160418-69-114421_ddf94240af7b9df84ef0de28da7fbbe0b34c95b7ded5121f9af607d4738b42b2.JPG\n",
            "target: 1, prob: 0.7723789215087891, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "297\n",
            "3276-20010424-61-135429_e811d4bcd5df843952f62358c479bff9db9dc2404edaa288516c1d568244ecaa.JPG\n",
            "target: 1, prob: 0.7072704434394836, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "298\n",
            "2407-20070529-24-085351_2660fb87cbc39b005efab44a04f63019433e1d11de54e95fbd8eee8ea071b7a5.JPG\n",
            "target: 1, prob: 0.9998880624771118, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "299\n",
            "2407-20070710-24-100400_5f8817048fbd3a9578c64c57944ad2d93d3d8475d19ed742cacb90a0f9cd9ff0.JPG\n",
            "target: 1, prob: 0.9991777539253235, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "300\n",
            "2407-20070515-24-093610_dafb232db0b36c26f6778b1e0b29d3544b325a4d930686bacaa6301a9dd9e9af.JPG\n",
            "target: 1, prob: 0.9999516010284424, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "301\n",
            "2630-20120418-43-101904_4309e655d0d1c1b7593ba01a112adc6626f711bc982447453a8217d6585db0a7.JPG\n",
            "target: 1, prob: 0.9129982590675354, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "302\n",
            "2307-20190515-37-104336_765f5a59f05804a36978b74f2fd238a9cfaae55d0fcb396aeb70b16609849994.JPG\n",
            "target: 1, prob: 0.9979197382926941, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "303\n",
            "2794-20200312-54-090241_960d7b82be8c7121abc0671c86333309f0c8db9a826308a2afd71d8d8d048244.JPG\n",
            "target: 1, prob: 0.9570493102073669, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "304\n",
            "2794-20190508-53-104821_d44754d6113686a8e9c3a6a21d2c69600244fca36d8673233e4b071578fd2522.JPG\n",
            "target: 1, prob: 0.9997939467430115, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "305\n",
            "2794-20200212-54-155215_e29971a1eb0227a073fb6a2c8dc7aa8b7c5fb9fdb73f54725211a4c141c5886a.JPG\n",
            "target: 1, prob: 0.9805561900138855, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "306\n",
            "2794-20200512-54-131740_e0734d19844766a7cf5a7adb05b49c5f45ebd99d451d829d57863b26e61bf993.JPG\n",
            "target: 1, prob: 0.9556214213371277, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "307\n",
            "2794-20191113-54-100523_ab1913329e4eb77efffbfebe428a4846d4d07d85c502c454f0b2f37e65602c5b.JPG\n",
            "target: 1, prob: 0.984224796295166, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "308\n",
            "3077-20180418-65-122454_011159c0653a21b8f8fe911d920e5f139bbc47ad892064c7c50650205d6df365.JPG\n",
            "target: 1, prob: 0.9999991655349731, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "309\n",
            "2794-20210609-56-162202_5e170c7e5fa32ee2740b28802e86eea9dcef6568450adedb7ce1c1942cf04665.JPG\n",
            "target: 1, prob: 0.9331672191619873, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "310\n",
            "2900-20090519-26-121450_945fe8e0676cd874dd9f6ba2a737827bcc7bad591a1de38f151e70ba56b3cd75.JPG\n",
            "target: 1, prob: 0.9977953433990479, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "311\n",
            "2794-20181205-53-104121_9241f18964c0ae4d96f09cce923763bae355923729c065e458383e523746443e.JPG\n",
            "target: 1, prob: 0.9998868703842163, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "312\n",
            "2794-20181114-53-101625_e056d62a10ad8015c140d3b0d1f2960558dbdcaedb80e8428f718b110a18a9f1.JPG\n",
            "target: 1, prob: 0.9679582715034485, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "313\n",
            "9739-20201202-25-141110_f2836e510d760f77874178f643e4ac0c618d2e002b4bccdf23fe434b244e0533.JPG\n",
            "target: 0, prob: 0.0007458182517439127, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "314\n",
            "9759-20191009-6-104753_19b006e6b8795990c1356b6e05288ddf25fb79cfabc5749cd69462c6f3f6b0ba.JPG\n",
            "target: 0, prob: 3.713980277098017e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "315\n",
            "9750-20191009-46-100212_352291c4a03506665f2251ea7dd53a59ac399c16d54d68b6b847456cff5fe207.JPG\n",
            "target: 0, prob: 0.29451948404312134, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "316\n",
            "9774-20200722-39-120943_1a7af7f1824769a07d63f88d5f58ad4f3f7df2993bad3f7fd7e76a536ebb86a4.JPG\n",
            "target: 0, prob: 0.9969912767410278, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "317\n",
            "9743-20200930-2-123943_73e4a5afeacd3591d7f6e0c53faddea471fef1fb52d5d536958958a1a9da8296.JPG\n",
            "target: 0, prob: 6.15119824942667e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "318\n",
            "2794-20190227-53-093627_ce0e7374120b62232f632ec75e6fe3d7fad1e4f8bf5fd9208e033e84858a32ec.JPG\n",
            "target: 1, prob: 0.9999336004257202, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "319\n",
            "2794-20190109-53-101844_a65bfafce09117d601c1e1b5315252548dd63947d666f2b3790d47110b18798f.JPG\n",
            "target: 1, prob: 0.9997395873069763, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "320\n",
            "1037-20160629-21-101747_decd212b67f1fd3a6ed70c31a261d183343a650e6e58b967917a6502aedb0edb.JPG\n",
            "target: 1, prob: 0.998353123664856, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "321\n",
            "1037-20170119-21-115932_9f2f310177e32b622d1b3b5cefdb8f43a5a0ddc9dac4531c10607a8ff112288e.JPG\n",
            "target: 1, prob: 0.9999973773956299, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "322\n",
            "1743-20040728-33-100536_184b1f5842ff715d7a26fbe74fbf8366044762338d4e4cb6e616da6a28b411dc.JPG\n",
            "target: 1, prob: 0.9976643323898315, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "323\n",
            "1378-20051011-23-130543_7d88914bae992cc07df016231b185df475b853aa25c19816e6da3ae75a8cb496.JPG\n",
            "target: 1, prob: 0.04578123986721039, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "324\n",
            "1037-20160817-21-095823_d1ee88e4a69f9d26c25a43444f41ba7a0f279fb02bd69e67095c9b10a94b3f80.JPG\n",
            "target: 1, prob: 0.9999909400939941, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "325\n",
            "2794-20181031-53-095715_d54719e0c060c6735d3755392577e79a03207cd6f1488fd4e4b980ef7638e5ba.JPG\n",
            "target: 1, prob: 0.7698517441749573, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "326\n",
            "2644-20091228-69-123418_fa243e46eff9e1a30994335887d863cd57e7ff8d5d8c1698cc82ed3da8418ec0.JPG\n",
            "target: 1, prob: 0.9999995231628418, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "327\n",
            "2644-20120330-71-121710_aed5efa6d2377f153deb0866e0e5e5e8854cb7c7d545406ccd3f746fc02d95cd.JPG\n",
            "target: 1, prob: 0.999698281288147, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "328\n",
            "2794-20181017-53-115613_f15ee453de506d468b09c37add3f5c7a5177e57bc2f7392cd638107762a3f089.JPG\n",
            "target: 1, prob: 0.9996514320373535, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "329\n",
            "2307-20181012-37-105440_ea7eb77c0ceb6a6f08a0cebe0b9e2b3d33b265f99555108d469f2a3d2412430b.JPG\n",
            "target: 1, prob: 0.9705969095230103, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "330\n",
            "2307-20181031-37-102845_af4cfe94abbb8da27218a013eb1762c3bcc85a3f0a428d5502e9592b6e1f141e.JPG\n",
            "target: 1, prob: 0.9999697208404541, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "331\n",
            "2644-20091130-69-105224_f39c8b6835b2cc5fb169a967caa31f0a3786fe30357b897593b2fe3f951020b9.JPG\n",
            "target: 1, prob: 0.9999468326568604, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "332\n",
            "2644-20091102-69-123626_64d4dcfe4d5af0306c725772f4a1373bed702a0a9c95e3d3dc594602aee47522.JPG\n",
            "target: 1, prob: 0.9999996423721313, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "333\n",
            "9610-20200812-81-084933_b87e5c51b0e375a6094dab2a1a0058b0ed4c86e4da2e196ac292e593a4019928.JPG\n",
            "target: 0, prob: 0.07054270058870316, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "334\n",
            "956.JPG\n",
            "target: 0, prob: 0.00015579062164761126, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "335\n",
            "9567-20191212-45-104032_16328527bcbaa82f59177ed03ad51cdc2034e36d2ec9dbdfe2c41609c8025152.JPG\n",
            "target: 0, prob: 0.3691127598285675, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "336\n",
            "9623-20191204-2-100944_cfbd575130544a6995fe10dcae0f7a565f735358eefaf26fc8d03b8e643e6c83.JPG\n",
            "target: 0, prob: 0.00013722386211156845, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "337\n",
            "9587-20210421-7-145206_c8f4640283e90459b7187d5e47604383176a233e3277f7089c63434be7f2e4ac.JPG\n",
            "target: 0, prob: 1.5585546861984767e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "338\n",
            "2307-20190213-37-103631_9de0bdc09c445c069a3e4d358970292c825d118424dfdceb0ed8a157cc66377b.JPG\n",
            "target: 1, prob: 0.9986960291862488, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "339\n",
            "2307-20181128-37-115019_959980df598f06b438b53fa6e58f280a162cb4bcc34ba2bd303a06111a81aa11.JPG\n",
            "target: 1, prob: 0.9827205538749695, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "340\n",
            "2307-20180830-37-113157_1ba277c882288a174da82b406cd0d1a41ef2de8338ea05aec8a42d0a73ec6b45.JPG\n",
            "target: 1, prob: 0.9955804944038391, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "341\n",
            "9814-20200610-3-112208_8bdb0db149a1d6cd95d20596ab29367f0e1834f6a37e7ba04431c6cbfcfcefe4.JPG\n",
            "target: 0, prob: 4.019595144200139e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "342\n",
            "9822-20191009-38-132229_3dfb77e1962c5433c28e43bba8db909417ff3556f671b1c1b3415722cd1d8a1f.JPG\n",
            "target: 0, prob: 0.039571117609739304, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "343\n",
            "1841-20130410-26-102817_7d9b8b4157c1efdd3573b2d1537a79c029ef3cea82577f3433c6716edd23a2e4.JPG\n",
            "target: 1, prob: 0.0055614798329770565, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "344\n",
            "996.JPG\n",
            "target: 0, prob: 0.8471929430961609, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "345\n",
            "9833-20191211-31-145018_9b196a8e871dccec87f87f70e8ffb2429a3c0f4a747d0204b327e3f94159cf5c.JPG\n",
            "target: 0, prob: 0.0005127595504745841, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "346\n",
            "981.JPG\n",
            "target: 0, prob: 0.0009247625712305307, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "347\n",
            "9447-20200819-80-121147_3807cc8b8e8859893ca6258c3fc49828facef5dd170ed7a670ca9756644717ef.JPG\n",
            "target: 0, prob: 2.044763823505491e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "348\n",
            "9460-20210127-48-112348_c2aa7edf51d123f48183f89f9fee78501cbeaa859daf25c9e64c2346f5f38ece.JPG\n",
            "target: 0, prob: 0.0012078523868694901, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "349\n",
            "9433-20200910-11-105902_75a69696920194b5aab772a74c1e40ecf7452bf3b823f05230e46bd637704cd9.JPG\n",
            "target: 0, prob: 0.0006449604406952858, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "350\n",
            "9476-20210219-90-135029_8e1bb8351329965b93019d7bd76330073f33cd033f8a0f3257ecc5c5c9d533c1.JPG\n",
            "target: 0, prob: 0.007636678870767355, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "351\n",
            "9400-20201112-25-142818_d3ebb0bfe120ff9f4d601564c3d0b3325f0b70642585b3f41fcb6c0fad2dd9f5.JPG\n",
            "target: 0, prob: 7.552159513579682e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "352\n",
            "9660-20191113-66-100457_c28c7cccaf4688d376b788ba30069ab3c7ca02e1e9390a6fa00720adda9c9651.JPG\n",
            "target: 0, prob: 0.007095013745129108, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "353\n",
            "9684-20210113-69-135743_d6232614defe41e154d727902198c97564fadbe08e46d7d919c6052f909d0bfb.JPG\n",
            "target: 0, prob: 0.1373370736837387, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "354\n",
            "9803-20200129-10-092734_c09ab0e13a02e1307f0bc8d15a90934c42a2e87cc848b3ed6e554f641cf1958e.JPG\n",
            "target: 0, prob: 1.1543734217411838e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "355\n",
            "9728-20200220-70-092633_9cf66571c9d199443474a6325cde9e1d2e5d39641abce0ca5b528f22fb017b93.JPG\n",
            "target: 0, prob: 0.00034328855690546334, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "356\n",
            "9720-20200612-62-100616_45383c9cf1edfe6ac0874d378682f3cbd588424e977a029e56eac9bd737accea.JPG\n",
            "target: 0, prob: 0.0033457898534834385, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "357\n",
            "9652-20201216-38-093931_b2f3168ce9eca2dc7889b96de691b3d5c79ebe1e725a674832678e70985560ab.JPG\n",
            "target: 0, prob: 3.9987429772736505e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "358\n",
            "9546-20201223-13-094923_4abef8ebd04cabe4acbe7072c537b73ba46afd745ca2353899cb43b74c1a8caa.JPG\n",
            "target: 0, prob: 0.00010679821571102366, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "359\n",
            "9517-20191023-19-101340_fedc7b6ff62002eaa3cf9d6a4871a4cdec4fbbf59ae7346334739b866e9f3081.JPG\n",
            "target: 0, prob: 0.000261499808402732, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "360\n",
            "9504-20210428-14-104056_d5b2449142196b7b3cc90521577a6af96b96e5f5a1d781f9cdbc4fc3a3050711.JPG\n",
            "target: 0, prob: 0.0002643225307110697, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "361\n",
            "9634-20201006-78-103606_d535db4308ef304ecc62dc1bf6fb9fb5e2833f514e829825e54a9350a69dc006.JPG\n",
            "target: 0, prob: 2.2583404643228278e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "362\n",
            "9523-20210428-10-140328_a71d5119ca5662e721e0dbf820a9cb5e691267dedaae35e118c7499248697186.JPG\n",
            "target: 0, prob: 7.358165748883039e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "363\n",
            "9382-20200402-15-144452_e585a944c82b3f3a9511c4e77dc69147f9fd30e7bc68994c77db3b426df68f1f.JPG\n",
            "target: 0, prob: 0.8579522967338562, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "364\n",
            "9396-20200923-6-110138_1fdb116844a9c838acd48f292999defc02bd68b4aa79a5367139f92675353291.JPG\n",
            "target: 0, prob: 5.284821236273274e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "365\n",
            "9255-20210416-70-131533_5c8bbbadcb51079a5c84009e4933533f6bbc57cfed27fa7e2780640621503b6c.JPG\n",
            "target: 0, prob: 2.8629065127461217e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "366\n",
            "9313-20210630-87-123848_87135f5dcfcd8a03d9a074a7d6e09fca9ea6382069c570d1af4c0e772f73dc65.JPG\n",
            "target: 0, prob: 0.19654271006584167, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "367\n",
            "9246-20210217-84-084925_d313b56b7e346f7be67d7791853870417fe3bbae77c153f8ef9ff642640c7b8f.JPG\n",
            "target: 0, prob: 0.45199090242385864, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "368\n",
            "9298-20210616-9-095233_6ccff7539c379a62fe4d76085d3aaa9cc8e439715a1ae58b4f221c3789e7c638.JPG\n",
            "target: 0, prob: 0.01607949286699295, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "369\n",
            "9317-20210630-72-122847_737dc366b9f4491dcd78b10a64809a1cabcb2b4758b91c35fc47236888ec07f7.JPG\n",
            "target: 0, prob: 0.004748137667775154, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "370\n",
            "9489-20191113-6-110100_7f3e2d58ed1341d767620c99c1414eea4caf4cbedd7bf59c05fd83af509eb18d.JPG\n",
            "target: 0, prob: 0.00013742604642175138, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "371\n",
            "9400-20201112-25-142818_d3ebb0bfe120ff9f4d601564c3d0b3325f0b70642585b3f41fcb6c0fad2dd9f5 - ГRГsБ[.JPG\n",
            "target: 0, prob: 7.552159513579682e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "372\n",
            "948.JPG\n",
            "target: 0, prob: 0.4642135798931122, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "373\n",
            "9361-20201014-67-135420_cc3aa1b5f1ad2cd16eb1900b100ecab1d79b1227ceaf6993ff728158779158bd.JPG\n",
            "target: 0, prob: 0.017313353717327118, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "374\n",
            "7429.JPG\n",
            "target: 0, prob: 0.007854476571083069, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "375\n",
            "746.JPG\n",
            "target: 0, prob: 0.0068122465163469315, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "376\n",
            "7405.JPG\n",
            "target: 0, prob: 0.02817346341907978, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "377\n",
            "7402.JPG\n",
            "target: 0, prob: 8.225255442084745e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "378\n",
            "7511.JPG\n",
            "target: 0, prob: 0.0002809048455674201, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "379\n",
            "9338-20201209-2-114220_48989f065207903a1d98bc0982cdf4f16a8b310c9b7bb5d70bead84755c983e6.JPG\n",
            "target: 0, prob: 1.3439454960462172e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "380\n",
            "8072.JPG\n",
            "target: 0, prob: 0.04445338249206543, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "381\n",
            "8117.JPG\n",
            "target: 0, prob: 5.6546556152170524e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "382\n",
            "821.JPG\n",
            "target: 0, prob: 0.45876312255859375, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "383\n",
            "8183.JPG\n",
            "target: 0, prob: 1.0052242942037992e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "384\n",
            "8138.JPG\n",
            "target: 0, prob: 0.9270060062408447, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "385\n",
            "9203-20210317-14-111216_99f92358c290a8b57956d0a9e6fb6a7db9c0269aa6db1ea2c6757b5662f8d573.JPG\n",
            "target: 0, prob: 0.0012667974224314094, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "386\n",
            "9222-20200819-16-101307_c8721e23affbd5e09a2fdc4ab8c1fe7c62e90d754d8ad7ca0921a2d9920b9223.JPG\n",
            "target: 0, prob: 0.00010002413182519376, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "387\n",
            "9320-20210106-25-121252_d52e8ef6408deb2146c885e527b56463e7d63b8e1d40863e3cc6624acee5a0e1.JPG\n",
            "target: 0, prob: 0.01308352965861559, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "388\n",
            "871.JPG\n",
            "target: 0, prob: 0.0002353973686695099, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "389\n",
            "9122-20210624-9-103313_9342fc0822a3fd1968f2dd276c522371e08d9296bae9a62daac15a8282ddba6d.JPG\n",
            "target: 0, prob: 0.00012198693730169907, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "390\n",
            "9227-20201021-50-111116_a1bc2eefdfa25d9d0be8ae309264dfb69713ea86f43146627f2b6f366836acf8.JPG\n",
            "target: 0, prob: 0.16620412468910217, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "391\n",
            "9158-20201202-7-095947_edd31f255f765cc2ac8fb02bc919279782a566cbd77fc1a83cc7f1904465adc9.JPG\n",
            "target: 0, prob: 1.6055393643910065e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "392\n",
            "9144-20210630-10-155038_f0e98703387150c45c5b0f1c36df4e3930b86118e13771ec2838584b9718e851.JPG\n",
            "target: 0, prob: 5.588673229794949e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "393\n",
            "7741.JPG\n",
            "target: 0, prob: 0.00031683355337008834, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "394\n",
            "785.JPG\n",
            "target: 0, prob: 0.001243859762325883, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "395\n",
            "7762.JPG\n",
            "target: 0, prob: 0.0013489684788510203, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "396\n",
            "7809.JPG\n",
            "target: 0, prob: 0.13552328944206238, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "397\n",
            "7889.JPG\n",
            "target: 0, prob: 0.004949039779603481, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "398\n",
            "8098.JPG\n",
            "target: 0, prob: 4.5365628466242924e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "399\n",
            "914.JPG\n",
            "target: 0, prob: 4.2229330574627966e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "400\n",
            "861.JPG\n",
            "target: 0, prob: 0.00022303880541585386, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "401\n",
            "8024.JPG\n",
            "target: 0, prob: 7.3790638452919666e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "402\n",
            "8008.JPG\n",
            "target: 0, prob: 5.244906424195506e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "403\n",
            "7986.JPG\n",
            "target: 0, prob: 0.003867252031341195, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "404\n",
            "7954.JPG\n",
            "target: 0, prob: 0.22786913812160492, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "405\n",
            "7649.JPG\n",
            "target: 0, prob: 0.0003125976654700935, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "406\n",
            "7905.JPG\n",
            "target: 0, prob: 0.0014362343354150653, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "407\n",
            "7606.JPG\n",
            "target: 0, prob: 6.296931678662077e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "408\n",
            "7594.JPG\n",
            "target: 0, prob: 4.480656571104191e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "409\n",
            "7691.JPG\n",
            "target: 0, prob: 0.16048720479011536, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "410\n",
            "7571.JPG\n",
            "target: 0, prob: 0.000811989710200578, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "411\n",
            "701.JPG\n",
            "target: 0, prob: 6.348331226035953e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "412\n",
            "6980.JPG\n",
            "target: 0, prob: 0.0036813272163271904, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "413\n",
            "7037.JPG\n",
            "target: 0, prob: 0.03533133119344711, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "414\n",
            "6946.JPG\n",
            "target: 0, prob: 0.004128690809011459, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "415\n",
            "7070.JPG\n",
            "target: 0, prob: 5.85877296543913e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "416\n",
            "7526.JPG\n",
            "target: 0, prob: 0.14572305977344513, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "417\n",
            "7146.JPG\n",
            "target: 0, prob: 0.04083123058080673, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "418\n",
            "7230.JPG\n",
            "target: 0, prob: 0.0028512836433947086, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "419\n",
            "7364.JPG\n",
            "target: 0, prob: 0.060545556247234344, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "420\n",
            "6561.JPG\n",
            "target: 0, prob: 0.00017726108490023762, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "421\n",
            "6605.JPG\n",
            "target: 0, prob: 0.0031061661429703236, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "422\n",
            "6521.JPG\n",
            "target: 0, prob: 0.17348726093769073, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "423\n",
            "6653.JPG\n",
            "target: 0, prob: 0.00014086480950936675, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "424\n",
            "6650.JPG\n",
            "target: 0, prob: 0.003382098628208041, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "425\n",
            "7258.JPG\n",
            "target: 0, prob: 0.0005264326464384794, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "426\n",
            "7191.JPG\n",
            "target: 0, prob: 0.0024613486602902412, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "427\n",
            "6913.JPG\n",
            "target: 0, prob: 0.0015678687486797571, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "428\n",
            "6880.JPG\n",
            "target: 0, prob: 0.009876413270831108, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "429\n",
            "7103.JPG\n",
            "target: 0, prob: 3.924051998183131e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "430\n",
            "5827.JPG\n",
            "target: 0, prob: 0.00026057346258312464, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "431\n",
            "5782.JPG\n",
            "target: 0, prob: 0.0019775070250034332, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "432\n",
            "5714.JPG\n",
            "target: 0, prob: 0.0068626427091658115, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "433\n",
            "5727.JPG\n",
            "target: 0, prob: 0.0011825613910332322, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "434\n",
            "5759.JPG\n",
            "target: 0, prob: 0.0007204011781141162, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "435\n",
            "6941.JPG\n",
            "target: 0, prob: 0.0018964975606650114, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "436\n",
            "6768.JPG\n",
            "target: 0, prob: 0.000803460949100554, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "437\n",
            "6852.JPG\n",
            "target: 0, prob: 0.005639014765620232, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "438\n",
            "6659.JPG\n",
            "target: 0, prob: 0.006431603338569403, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "439\n",
            "6720.JPG\n",
            "target: 0, prob: 4.398180317366496e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "440\n",
            "605.JPG\n",
            "target: 0, prob: 0.9580779671669006, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "441\n",
            "6017.JPG\n",
            "target: 0, prob: 8.086871821433306e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "442\n",
            "604.JPG\n",
            "target: 0, prob: 0.002562240231782198, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "443\n",
            "5942.JPG\n",
            "target: 0, prob: 0.0010159217054024339, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "444\n",
            "5977.JPG\n",
            "target: 0, prob: 0.008038369007408619, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "445\n",
            "6371.JPG\n",
            "target: 0, prob: 1.7131947970483452e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "446\n",
            "6396.JPG\n",
            "target: 0, prob: 0.00042447695159353316, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "447\n",
            "6210.JPG\n",
            "target: 0, prob: 1.6425332432845607e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "448\n",
            "6255.JPG\n",
            "target: 0, prob: 0.8357968330383301, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "449\n",
            "6287.JPG\n",
            "target: 0, prob: 0.28509917855262756, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "450\n",
            "6329.JPG\n",
            "target: 0, prob: 0.0004266653850208968, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "451\n",
            "6229.JPG\n",
            "target: 0, prob: 0.005293956957757473, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "452\n",
            "6684.JPG\n",
            "target: 0, prob: 1.9354807591298595e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "453\n",
            "6742.JPG\n",
            "target: 0, prob: 0.0266735702753067, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "454\n",
            "6465.JPG\n",
            "target: 0, prob: 1.2959581908944529e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "455\n",
            "6433.JPG\n",
            "target: 0, prob: 4.0614479075884447e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "456\n",
            "6169.JPG\n",
            "target: 0, prob: 0.1054115816950798, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "457\n",
            "6160.JPG\n",
            "target: 0, prob: 0.0021099115256220102, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "458\n",
            "6416.JPG\n",
            "target: 0, prob: 0.00013604943524114788, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "459\n",
            "6362.JPG\n",
            "target: 0, prob: 0.016503671184182167, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "460\n",
            "6193.JPG\n",
            "target: 0, prob: 0.0006286311545409262, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "461\n",
            "6181.JPG\n",
            "target: 0, prob: 0.00013156890054233372, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "462\n",
            "5545.JPG\n",
            "target: 0, prob: 0.18006938695907593, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "463\n",
            "5917.JPG\n",
            "target: 0, prob: 0.2853316068649292, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "464\n",
            "5486.JPG\n",
            "target: 0, prob: 1.4586065844923723e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "465\n",
            "5513.JPG\n",
            "target: 0, prob: 2.0825169485760853e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "466\n",
            "5414.JPG\n",
            "target: 0, prob: 0.005136291030794382, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "467\n",
            "5471.JPG\n",
            "target: 0, prob: 0.0002617904101498425, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "468\n",
            "544.JPG\n",
            "target: 0, prob: 9.08385991351679e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "469\n",
            "6135.JPG\n",
            "target: 0, prob: 0.007195398677140474, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "470\n",
            "6063.JPG\n",
            "target: 0, prob: 0.012684994377195835, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "471\n",
            "5878.JPG\n",
            "target: 0, prob: 0.0012003147276118398, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "472\n",
            "5857.JPG\n",
            "target: 0, prob: 8.37615953059867e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "473\n",
            "5848.JPG\n",
            "target: 0, prob: 3.661676964838989e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "474\n",
            "591.JPG\n",
            "target: 0, prob: 0.13090580701828003, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "475\n",
            "5845.JPG\n",
            "target: 0, prob: 0.003799016820266843, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "476\n",
            "5638.JPG\n",
            "target: 0, prob: 0.0159560889005661, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "477\n",
            "5635.JPG\n",
            "target: 0, prob: 1.1559101949387696e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "478\n",
            "5688.JPG\n",
            "target: 0, prob: 0.047069001942873, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "479\n",
            "5661.JPG\n",
            "target: 0, prob: 0.07610364258289337, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "480\n",
            "5623.JPG\n",
            "target: 0, prob: 0.0005202444735914469, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "481\n",
            "5229.JPG\n",
            "target: 0, prob: 0.01146603375673294, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "482\n",
            "5246.JPG\n",
            "target: 0, prob: 0.00899284053593874, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "483\n",
            "5183.JPG\n",
            "target: 0, prob: 0.24957747757434845, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "484\n",
            "5212.JPG\n",
            "target: 0, prob: 0.0006261932430788875, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "485\n",
            "5191.JPG\n",
            "target: 0, prob: 0.5715572237968445, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "486\n",
            "5300.JPG\n",
            "target: 0, prob: 0.0002562848385423422, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "487\n",
            "5332.JPG\n",
            "target: 0, prob: 0.010214434005320072, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "488\n",
            "5106.JPG\n",
            "target: 0, prob: 0.004556475207209587, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "489\n",
            "5089.JPG\n",
            "target: 0, prob: 2.480994226061739e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "490\n",
            "5391.JPG\n",
            "target: 0, prob: 0.0002799492795020342, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "491\n",
            "5130.JPG\n",
            "target: 0, prob: 1.5139640709094238e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "492\n",
            "5281.JPG\n",
            "target: 0, prob: 0.009417455643415451, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "493\n",
            "4922.JPG\n",
            "target: 0, prob: 0.00166926602832973, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "494\n",
            "4960.JPG\n",
            "target: 0, prob: 0.2512422800064087, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "495\n",
            "4909.JPG\n",
            "target: 0, prob: 7.171131528593833e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "496\n",
            "4892.JPG\n",
            "target: 0, prob: 8.072179480222985e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "497\n",
            "4897.JPG\n",
            "target: 0, prob: 3.6884630389977247e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "498\n",
            "5361.JPG\n",
            "target: 0, prob: 0.003982861991971731, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "499\n",
            "5260.JPG\n",
            "target: 0, prob: 0.2635308802127838, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "500\n",
            "5153.JPG\n",
            "target: 0, prob: 0.00039607929647900164, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "501\n",
            "5079.JPG\n",
            "target: 0, prob: 2.003749250434339e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "502\n",
            "4996.JPG\n",
            "target: 0, prob: 0.00015680940123274922, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "503\n",
            "5060.JPG\n",
            "target: 0, prob: 0.03419557213783264, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "504\n",
            "4737.JPG\n",
            "target: 0, prob: 0.0032306613866239786, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "505\n",
            "4712.JPG\n",
            "target: 0, prob: 6.781107458664337e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "506\n",
            "4654.JPG\n",
            "target: 0, prob: 0.055270299315452576, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "507\n",
            "4740.JPG\n",
            "target: 0, prob: 6.1609025578945875e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "508\n",
            "4635.JPG\n",
            "target: 0, prob: 0.0012464782921597362, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "509\n",
            "5074.JPG\n",
            "target: 0, prob: 0.019268987700343132, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "510\n",
            "498.JPG\n",
            "target: 0, prob: 0.018254851922392845, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "511\n",
            "4873.JPG\n",
            "target: 0, prob: 0.015160963870584965, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "512\n",
            "4417.JPG\n",
            "target: 0, prob: 0.0046241492964327335, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "513\n",
            "4380.JPG\n",
            "target: 0, prob: 7.807528891135007e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "514\n",
            "4405.JPG\n",
            "target: 0, prob: 0.0007113171741366386, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "515\n",
            "4462.JPG\n",
            "target: 0, prob: 0.001680808956734836, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "516\n",
            "4441.JPG\n",
            "target: 0, prob: 0.08079656958580017, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "517\n",
            "4829.JPG\n",
            "target: 0, prob: 8.802187949186191e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "518\n",
            "4788.JPG\n",
            "target: 0, prob: 0.08501435816287994, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "519\n",
            "4786.JPG\n",
            "target: 0, prob: 0.0001742205786285922, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "520\n",
            "4753.JPG\n",
            "target: 0, prob: 0.014330144971609116, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "521\n",
            "4807.JPG\n",
            "target: 0, prob: 0.002302786335349083, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "522\n",
            "4514.JPG\n",
            "target: 0, prob: 0.00010508709237910807, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "523\n",
            "4529.JPG\n",
            "target: 0, prob: 0.003816796001046896, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "524\n",
            "477.JPG\n",
            "target: 0, prob: 0.0006829918711446226, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "525\n",
            "4151.JPG\n",
            "target: 0, prob: 8.52105313242646e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "526\n",
            "4135.JPG\n",
            "target: 0, prob: 0.60528564453125, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "527\n",
            "4178.JPG\n",
            "target: 0, prob: 0.0009967901278287172, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "528\n",
            "4194.JPG\n",
            "target: 0, prob: 0.022916754707694054, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "529\n",
            "4114.JPG\n",
            "target: 0, prob: 1.454569701309083e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "530\n",
            "4596.JPG\n",
            "target: 0, prob: 0.00011560098937479779, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "531\n",
            "4497.JPG\n",
            "target: 0, prob: 0.9898878931999207, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "532\n",
            "4569.JPG\n",
            "target: 0, prob: 0.03896218165755272, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "533\n",
            "4471.JPG\n",
            "target: 0, prob: 0.00046528561506420374, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "534\n",
            "4334.JPG\n",
            "target: 0, prob: 0.08179391175508499, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "535\n",
            "4357.JPG\n",
            "target: 0, prob: 1.726002483337652e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "536\n",
            "4035.JPG\n",
            "target: 0, prob: 0.028598733246326447, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "537\n",
            "4060.JPG\n",
            "target: 0, prob: 7.748865755274892e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "538\n",
            "3974.JPG\n",
            "target: 0, prob: 0.00015905380132608116, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "539\n",
            "402.JPG\n",
            "target: 0, prob: 0.01102458219975233, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "540\n",
            "3995.JPG\n",
            "target: 0, prob: 0.10617251694202423, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "541\n",
            "4389.JPG\n",
            "target: 0, prob: 0.00037261086981743574, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "542\n",
            "4324.JPG\n",
            "target: 0, prob: 0.049905091524124146, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "543\n",
            "4302.JPG\n",
            "target: 0, prob: 0.31018322706222534, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "544\n",
            "4240.JPG\n",
            "target: 0, prob: 0.9852277040481567, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "545\n",
            "4222.JPG\n",
            "target: 0, prob: 0.00035864717210642993, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "546\n",
            "4279.JPG\n",
            "target: 0, prob: 0.501409113407135, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "547\n",
            "3481.JPG\n",
            "target: 0, prob: 0.004156138747930527, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "548\n",
            "3556.JPG\n",
            "target: 0, prob: 0.0006450483342632651, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "549\n",
            "3538.JPG\n",
            "target: 0, prob: 0.0007487280527129769, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "550\n",
            "3634.JPG\n",
            "target: 0, prob: 0.0012833263026550412, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "551\n",
            "3587.JPG\n",
            "target: 0, prob: 0.002041266532614827, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "552\n",
            "4201.JPG\n",
            "target: 0, prob: 0.21203994750976562, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "553\n",
            "410.JPG\n",
            "target: 0, prob: 0.00021756516071036458, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "554\n",
            "3917.JPG\n",
            "target: 0, prob: 9.136330481851473e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "555\n",
            "3940.JPG\n",
            "target: 0, prob: 0.015615924261510372, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "556\n",
            "4098.JPG\n",
            "target: 0, prob: 0.060983795672655106, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "557\n",
            "4085.JPG\n",
            "target: 0, prob: 7.717282278463244e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "558\n",
            "3870.JPG\n",
            "target: 0, prob: 0.9971988201141357, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "559\n",
            "3685.JPG\n",
            "target: 0, prob: 0.0028488733805716038, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "560\n",
            "3951.JPG\n",
            "target: 0, prob: 0.004477956797927618, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "561\n",
            "3805.JPG\n",
            "target: 0, prob: 0.7896222472190857, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "562\n",
            "3291.JPG\n",
            "target: 0, prob: 0.003446251153945923, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "563\n",
            "3222.JPG\n",
            "target: 0, prob: 0.1617291271686554, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "564\n",
            "3311.JPG\n",
            "target: 0, prob: 0.005707980133593082, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "565\n",
            "3263.JPG\n",
            "target: 0, prob: 6.670649781881366e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "566\n",
            "3247.JPG\n",
            "target: 0, prob: 0.0016186630818992853, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "567\n",
            "3711.JPG\n",
            "target: 0, prob: 0.0001308397768298164, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "568\n",
            "3761.JPG\n",
            "target: 0, prob: 0.5802868604660034, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "569\n",
            "3784.JPG\n",
            "target: 0, prob: 0.0058932192623615265, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "570\n",
            "3396.JPG\n",
            "target: 0, prob: 3.6441611882764846e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "571\n",
            "343.JPG\n",
            "target: 0, prob: 0.05890633165836334, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "572\n",
            "3658.JPG\n",
            "target: 0, prob: 5.503860302269459e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "573\n",
            "3514.JPG\n",
            "target: 0, prob: 0.0018274890026077628, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "574\n",
            "3368.JPG\n",
            "target: 0, prob: 0.0017412190791219473, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "575\n",
            "3459.JPG\n",
            "target: 0, prob: 0.3331964612007141, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "576\n",
            "3342.JPG\n",
            "target: 0, prob: 0.005447783973067999, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "577\n",
            "2969.JPG\n",
            "target: 0, prob: 0.49336159229278564, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "578\n",
            "2902.JPG\n",
            "target: 0, prob: 0.0008293818100355566, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "579\n",
            "2992.JPG\n",
            "target: 0, prob: 0.0006138444878160954, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "580\n",
            "3011.JPG\n",
            "target: 0, prob: 0.004715633578598499, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "581\n",
            "2952.JPG\n",
            "target: 0, prob: 0.24530404806137085, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "582\n",
            "3109.JPG\n",
            "target: 0, prob: 0.001715450664050877, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "583\n",
            "3151.JPG\n",
            "target: 0, prob: 0.16607902944087982, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "584\n",
            "3198.JPG\n",
            "target: 0, prob: 1.121989498642506e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "585\n",
            "3095.JPG\n",
            "target: 0, prob: 0.001816786709241569, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "586\n",
            "3057.JPG\n",
            "target: 0, prob: 0.6856996417045593, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "587\n",
            "2766.JPG\n",
            "target: 0, prob: 4.498158523347229e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "588\n",
            "2798.JPG\n",
            "target: 0, prob: 0.0010758164571598172, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "589\n",
            "2607.JPG\n",
            "target: 0, prob: 0.22521467506885529, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "590\n",
            "2634.JPG\n",
            "target: 0, prob: 0.019084036350250244, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "591\n",
            "2679.JPG\n",
            "target: 0, prob: 0.037992700934410095, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "592\n",
            "2585.JPG\n",
            "target: 0, prob: 0.000389003602322191, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "593\n",
            "2584.JPG\n",
            "target: 0, prob: 0.003471494186669588, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "594\n",
            "2785.JPG\n",
            "target: 0, prob: 7.160804671002552e-05, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "595\n",
            "3039.JPG\n",
            "target: 0, prob: 0.09583426266908646, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "596\n",
            "2862.JPG\n",
            "target: 0, prob: 7.568178989458829e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "597\n",
            "2555.JPG\n",
            "target: 0, prob: 0.0008357883780263364, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "598\n",
            "2500.JPG\n",
            "target: 0, prob: 0.002644359366968274, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "599\n",
            "2340.JPG\n",
            "target: 0, prob: 0.000686858082190156, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "600\n",
            "2323.JPG\n",
            "target: 0, prob: 0.0009759013191796839, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "601\n",
            "2214.JPG\n",
            "target: 0, prob: 6.706754356855527e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "602\n",
            "2299.JPG\n",
            "target: 0, prob: 0.01693958416581154, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "603\n",
            "2268.JPG\n",
            "target: 0, prob: 1.4089147043705452e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "604\n",
            "2824.JPG\n",
            "target: 0, prob: 0.039366986602544785, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "605\n",
            "2731.JPG\n",
            "target: 0, prob: 0.059879597276449203, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "606\n",
            "2567.JPG\n",
            "target: 0, prob: 0.00034731646883301437, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "607\n",
            "2546.JPG\n",
            "target: 0, prob: 0.010882122442126274, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "608\n",
            "2083.JPG\n",
            "target: 0, prob: 0.04429608955979347, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "609\n",
            "2021.JPG\n",
            "target: 0, prob: 9.438049892196432e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "610\n",
            "2043.JPG\n",
            "target: 0, prob: 0.0035012036096304655, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "611\n",
            "2085.JPG\n",
            "target: 0, prob: 0.18022315204143524, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "612\n",
            "200.JPG\n",
            "target: 0, prob: 0.002090770984068513, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "613\n",
            "2450.JPG\n",
            "target: 0, prob: 0.43612194061279297, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "614\n",
            "2406.JPG\n",
            "target: 0, prob: 0.015012976713478565, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "615\n",
            "2473.JPG\n",
            "target: 0, prob: 0.007336957845836878, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "616\n",
            "2150.JPG\n",
            "target: 0, prob: 0.08043940365314484, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "617\n",
            "2169.JPG\n",
            "target: 0, prob: 0.5089584589004517, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "618\n",
            "2467.JPG\n",
            "target: 0, prob: 0.009059317409992218, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "619\n",
            "2197.JPG\n",
            "target: 0, prob: 0.27001169323921204, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "620\n",
            "2377.JPG\n",
            "target: 0, prob: 0.00017850362928584218, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "621\n",
            "2353.JPG\n",
            "target: 0, prob: 0.34290361404418945, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "622\n",
            "2137.JPG\n",
            "target: 0, prob: 0.0027287276461720467, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "623\n",
            "1811.JPG\n",
            "target: 0, prob: 0.01069187093526125, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "624\n",
            "179.JPG\n",
            "target: 0, prob: 0.1039157286286354, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "625\n",
            "1768.JPG\n",
            "target: 0, prob: 0.03226272016763687, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "626\n",
            "1821.JPG\n",
            "target: 0, prob: 0.038996778428554535, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "627\n",
            "1867.JPG\n",
            "target: 0, prob: 0.5092835426330566, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "628\n",
            "2188.JPG\n",
            "target: 0, prob: 0.015046452172100544, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "629\n",
            "1936.JPG\n",
            "target: 0, prob: 0.9857494831085205, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "630\n",
            "1900.JPG\n",
            "target: 0, prob: 0.004890556912869215, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "631\n",
            "1918.JPG\n",
            "target: 0, prob: 0.00015108933439478278, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "632\n",
            "2100.JPG\n",
            "target: 0, prob: 0.00011257227743044496, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "633\n",
            "1980.JPG\n",
            "target: 0, prob: 0.00010560686496319249, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "634\n",
            "1957.JPG\n",
            "target: 0, prob: 0.0013708311598747969, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "635\n",
            "1715.JPG\n",
            "target: 0, prob: 0.00016286075697280467, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "636\n",
            "1719.JPG\n",
            "target: 0, prob: 6.827269680798054e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "637\n",
            "1424.JPG\n",
            "target: 0, prob: 0.00042458236566744745, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "638\n",
            "149.JPG\n",
            "target: 0, prob: 0.17442066967487335, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "639\n",
            "1542.JPG\n",
            "target: 0, prob: 0.015080899000167847, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "640\n",
            "1381.JPG\n",
            "target: 0, prob: 0.4143063426017761, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "641\n",
            "1531.JPG\n",
            "target: 0, prob: 0.9225758910179138, pred: 1\n",
            "mask_diagnosis = 1\n",
            "\n",
            "642\n",
            "190.JPG\n",
            "target: 0, prob: 0.03333248943090439, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "643\n",
            "1676.JPG\n",
            "target: 0, prob: 1.7335343045488116e-06, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "644\n",
            "1759.JPG\n",
            "target: 0, prob: 0.1437707394361496, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "645\n",
            "1066.JPG\n",
            "target: 0, prob: 0.015082230791449547, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "646\n",
            "112.JPG\n",
            "target: 0, prob: 0.0012638079933822155, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "647\n",
            "1145.JPG\n",
            "target: 0, prob: 0.00039114439277909696, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "648\n",
            "1045.JPG\n",
            "target: 0, prob: 0.007499457336962223, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "649\n",
            "110.JPG\n",
            "target: 0, prob: 0.8640796542167664, pred: 1\n",
            "mask_diagnosis = 0\n",
            "\n",
            "650\n",
            "132.JPG\n",
            "target: 0, prob: 0.3729921579360962, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "651\n",
            "13.JPG\n",
            "target: 0, prob: 1.682581569184549e-05, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "652\n",
            "1601.JPG\n",
            "target: 0, prob: 0.3135332465171814, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "653\n",
            "158.JPG\n",
            "target: 0, prob: 0.4453531503677368, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "654\n",
            "1348.JPG\n",
            "target: 0, prob: 0.4608701169490814, pred: 0\n",
            "mask_diagnosis = 1\n",
            "\n",
            "655\n",
            "1266.JPG\n",
            "target: 0, prob: 0.00012815241643693298, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "656\n",
            "1244.JPG\n",
            "target: 0, prob: 0.0013581442181020975, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "657\n",
            "119.JPG\n",
            "target: 0, prob: 0.004914790391921997, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "658\n",
            "1224.JPG\n",
            "target: 0, prob: 0.016892598941922188, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "659\n",
            "1241.JPG\n",
            "target: 0, prob: 0.00019229680765420198, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "660\n",
            "118.JPG\n",
            "target: 0, prob: 0.003237886121496558, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "661\n",
            "1029.JPG\n",
            "target: 0, prob: 0.021023858338594437, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "662\n",
            "1017.JPG\n",
            "target: 0, prob: 0.0006588431424461305, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "663\n",
            "1000.JPG\n",
            "target: 0, prob: 0.00024305110855493695, pred: 0\n",
            "mask_diagnosis = 0\n",
            "\n",
            "Model accuracy: 93.98% (625/665)\n",
            "GradCAM area judgement: 81.65% (543/665)\n",
            "Accuracy in which model and GradCAM judgement match: 96.15% (525/546)\n",
            "Accuracy in which model and GradCAM judgement do'nt match: 84.75% (100/118)\n",
            "Mismatched indices: [17, 24, 25, 28, 68, 70, 101, 121, 200, 210, 211, 214, 215, 218, 221, 271, 291, 316, 323, 343, 344, 363, 384, 440, 448, 485, 526, 531, 544, 546, 558, 561, 568, 586, 617, 627, 629, 641, 649]\n",
            "Matrix:\n",
            "\n",
            "                               | model_diagnosisがmask_diagnosisと一致 | model_diagnosisがmask_diagnosisと不一致\n",
            "------------------------------------------------------------------------------------------\n",
            "modelで正解                       | 525                       | 100                      \n",
            "modelで不正解                      | 100                       | 18                       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###叩き台（ボツ）のコード達\n",
        "\n",
        "Google mediapipeは顔面メッシュが検出できない症例が多いため採用せず"
      ],
      "metadata": {
        "id": "7GOZBL9t-pOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import mediapipe as mp\n",
        "# import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# # 読み込む画像ファイル\n",
        "# IMAGE_FILES = val_list[0]\n",
        "\n",
        "# # Google Mediapipe periocular landmarks #\n",
        "# mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# with mp_face_mesh.FaceMesh(\n",
        "#     static_image_mode=True,\n",
        "#     max_num_faces=1,\n",
        "#     refine_landmarks=True,\n",
        "#     min_detection_confidence=0.5) as face_mesh:\n",
        "\n",
        "#     image = cv2.imread(IMAGE_FILES)\n",
        "#     results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "#     if not results.multi_face_landmarks:\n",
        "#       exit(\"No landmarks detected\")\n",
        "\n",
        "#     landmarks_list_right = [\n",
        "#         33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
        "#         173, 157, 158, 159, 160, 161, 246\n",
        "#     ]\n",
        "\n",
        "#     landmarks_list_left = [\n",
        "#         466, 388, 387, 386, 385, 384, 398,\n",
        "#         263, 249, 390, 373, 374, 380, 381, 382, 362\n",
        "#     ]\n",
        "\n",
        "#     mask = np.zeros_like(image)\n",
        "\n",
        "#     for face_landmarks in results.multi_face_landmarks:\n",
        "#         points_right = []\n",
        "#         points_left = []\n",
        "\n",
        "#         for idx in landmarks_list_right:\n",
        "#             loc_x = int(face_landmarks.landmark[idx].x * image.shape[1])\n",
        "#             loc_y = int(face_landmarks.landmark[idx].y * image.shape[0])\n",
        "#             points_right.append([loc_x, loc_y])\n",
        "\n",
        "#         for idx in landmarks_list_left:\n",
        "#             loc_x = int(face_landmarks.landmark[idx].x * image.shape[1])\n",
        "#             loc_y = int(face_landmarks.landmark[idx].y * image.shape[0])\n",
        "#             points_left.append([loc_x, loc_y])\n",
        "\n",
        "#         cv2.fillPoly(mask, [np.array(points_right)], (255,255,255))\n",
        "#         cv2.fillPoly(mask, [np.array(points_left)], (255,255,255))\n",
        "\n",
        "#     masked_image = cv2.bitwise_and(mask, np.ones_like(image) * 255)\n",
        "#     cv2_imshow(masked_image)\n"
      ],
      "metadata": {
        "id": "vkojIsOFugFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install mediapipe opencv-python --q\n",
        "\n",
        "# import mediapipe as mp\n",
        "# import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# import glob\n",
        "\n",
        "# #########################################################\n",
        "# # Google Mediapipe periocular landmarks ※landmarkを検出できない症例がある#\n",
        "# #########################################################\n",
        "\n",
        "# mp_drawing = mp.solutions.drawing_utils\n",
        "# mp_drawing_styles = mp.solutions.drawing_styles\n",
        "# mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# # For static images:\n",
        "\n",
        "# import glob\n",
        "# val_list = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training/valid/*\")[0:100]\n",
        "# IMAGE_FILES = val_list\n",
        "# print(IMAGE_FILES)\n",
        "\n",
        "# drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
        "# with mp_face_mesh.FaceMesh(\n",
        "#     static_image_mode=True,\n",
        "#     max_num_faces=1,\n",
        "#     refine_landmarks=True,\n",
        "#     min_detection_confidence=0.15,\n",
        "#     min_tracking_confidence=0.1) as face_mesh:\n",
        "\n",
        "#   for idx, file in enumerate(IMAGE_FILES):\n",
        "#     print(file)\n",
        "#     image = cv2.imread(file)\n",
        "#     # Convert the BGR image to RGB before processing.\n",
        "#     results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "#     # Print and draw face mesh landmarks on the image.\n",
        "#     if not results.multi_face_landmarks:\n",
        "#       print(\"no landmark detected\")\n",
        "#       continue\n",
        "#     annotated_image = image.copy()\n",
        "\n",
        "#     landmarks_list_right = [\n",
        "#         33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
        "#         173, 157, 158, 159, 160, 161, 246,\n",
        "#     ]\n",
        "\n",
        "#     landmarks_list_left = [\n",
        "#     466, 388, 387, 386, 385, 384, 398,\n",
        "#     263, 249, 390, 373, 374, 380, 381, 382, 362\n",
        "#     ]\n",
        "\n",
        "#     for face_landmarks in results.multi_face_landmarks:\n",
        "#       for idx in landmarks_list_right:\n",
        "#         loc_x = int(face_landmarks.landmark[idx].x * image.shape[1])\n",
        "#         loc_y = int(face_landmarks.landmark[idx].y * image.shape[0])\n",
        "#         #print(loc_x, loc_y)\n",
        "#         cv2.circle(annotated_image,(loc_x, loc_y), 2, (255,0,255), 2)\n",
        "\n",
        "#       for idx in landmarks_list_left:\n",
        "#         loc_x = int(face_landmarks.landmark[idx].x * image.shape[1])\n",
        "#         loc_y = int(face_landmarks.landmark[idx].y * image.shape[0])\n",
        "#         #print(loc_x, loc_y)\n",
        "#         cv2.circle(annotated_image,(loc_x, loc_y), 2, (0,255,255), 2)\n",
        "\n",
        "#     cv2_imshow(annotated_image)\n"
      ],
      "metadata": {
        "id": "3yqasLAdGt9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import gc  # Import garbage collector module\n",
        "\n",
        "##############################################\n",
        "# Inference MobileNetV3 with GradCAM ※メモリ対策バージョン#\n",
        "##############################################\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval()  # prep model for evaluation\n",
        "targets, probs, preds, misclassified_indices = [], [], [], []\n",
        "\n",
        "\n",
        "# misclassified = [17, 24, 25, 28, 68, 70, 101, 121, 200, 210, 211, 214, 215, 218, 221, 271, 291, 316, 323, 343, 344, 363, 384, 440, 448, 485, 526, 531, 544, 546, 558, 561, 568, 586, 617, 627, 629, 641, 649]\n",
        "# image_indices = misclassified\n",
        "\n",
        "#image_indices = list(range(0, 665))\n",
        "image_indices = list(range(0, 3))\n",
        "\n",
        "for i, (img_path, img_label) in enumerate(zip(val_list, val_list_label)):\n",
        "    if i in image_indices:\n",
        "        pilr_image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Convert the PIL Image to numpy array\n",
        "        numpy_image = np.array(pilr_image)\n",
        "        cv2_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
        "        image_tensor = test_data_transforms(pilr_image)\n",
        "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        # Compute Grad-CAM for class 0\n",
        "        cam_class_0 = compute_gradcam(model_ft, image_tensor, target_class=0)\n",
        "        heatmap_0 = cv2.applyColorMap(np.uint8(255 * cam_class_0), cv2.COLORMAP_JET)\n",
        "        heatmap_0 = cv2.cvtColor(heatmap_0, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Compute Grad-CAM for class 1\n",
        "        cam_class_1 = compute_gradcam(model_ft, image_tensor, target_class=1)\n",
        "        heatmap_1 = cv2.applyColorMap(np.uint8(255 * cam_class_1), cv2.COLORMAP_JET)\n",
        "        heatmap_1 = cv2.cvtColor(heatmap_1, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Resize the heatmaps\n",
        "        heatmap_0_resized = cv2.resize(heatmap_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        heatmap_1_resized = cv2.resize(heatmap_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "\n",
        "        # Overlay original image with the heatmaps\n",
        "        overlayed_image_0 = cv2.addWeighted(cv2_image, 0.5, heatmap_0_resized, 0.5, 0)\n",
        "        overlayed_image_1 = cv2.addWeighted(cv2_image, 0.5, heatmap_1_resized, 0.5, 0)\n",
        "\n",
        "        # Concatenate the images\n",
        "        result = np.hstack([cv2_image, overlayed_image_1, overlayed_image_0])\n",
        "        cv2_imshow(result)\n",
        "\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model_ft(image_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "\n",
        "        prob = nn.Softmax(dim=1)(output)  # calculate probability\n",
        "        prob = prob[0][1].cpu().detach()  # probability of being positive\n",
        "        prob = \"{:.3f}\".format(prob.item())\n",
        "        print(f\"{i}\")\n",
        "        print(f\"{os.path.basename(img_path)}\")\n",
        "        print(f\"target: {img_label}, prob: {prob}, pred: {pred.item()}\")\n",
        "        print(\"\")\n",
        "\n",
        "        # Append results\n",
        "        probs.append(float(prob))  # predicted probability\n",
        "        preds.append(int(pred))  # predicted result\n",
        "        targets.append(int(img_label))  # label\n",
        "\n",
        "        if int(pred) != int(img_label):\n",
        "            misclassified_indices.append(i)\n",
        "\n",
        "        # Cleanup\n",
        "        del pilr_image, numpy_image, cv2_image, image_tensor, cam_class_0, cam_class_1, heatmap_0, heatmap_1\n",
        "        gc.collect()  # Run garbage collector\n",
        "\n",
        "y_label = np.array(targets)\n",
        "y_pred = np.array(preds)\n",
        "y_prob = np.array(probs)\n",
        "print(f\"misclassified_indices: {misclassified_indices}\")"
      ],
      "metadata": {
        "id": "kghHA3ksgYUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import gc  # Import garbage collector module\n",
        "\n",
        "####################################\n",
        "# Inference MobileNetV3 with 黒塗りGradCAM_白黒バージョン追加 #\n",
        "####################################\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval()  # prep model for evaluation\n",
        "targets, probs, preds, misclassified_indices = [], [], [], []\n",
        "\n",
        "misclassified = [17, 24, 25, 28, 68, 70, 101, 121, 200, 210, 211, 214, 215, 218, 221, 271, 291, 316, 323, 343, 344, 363, 384, 440, 448, 485, 526, 531, 544, 546, 558, 561, 568, 586, 617, 627, 629, 641, 649]\n",
        "image_indices = misclassified\n",
        "\n",
        "for i, (img_path, img_label) in enumerate(zip(val_list, val_list_label)):\n",
        "    if i in image_indices:\n",
        "        pilr_image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        numpy_image = np.array(pilr_image)\n",
        "        cv2_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
        "        image_tensor = test_data_transforms(pilr_image)\n",
        "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        # Compute Grad-CAM for class 0\n",
        "        cam_class_0 = compute_gradcam(model_ft, image_tensor, target_class=0)\n",
        "        mask_0 = np.where(cam_class_0 > 0.5, 0, 1).astype(np.uint8)\n",
        "\n",
        "        # Compute Grad-CAM for class 1\n",
        "        cam_class_1 = compute_gradcam(model_ft, image_tensor, target_class=1)\n",
        "        mask_1 = np.where(cam_class_1 > 0.5, 0, 1).astype(np.uint8)\n",
        "\n",
        "        # 既存のマスクを反転させる\n",
        "        inverse_mask_0 = np.where(cam_class_0 > 0.5, 1, 0).astype(np.uint8)\n",
        "        inverse_mask_1 = np.where(cam_class_1 > 0.5, 1, 0).astype(np.uint8)\n",
        "\n",
        "        # マスクをリサイズ\n",
        "        mask_0_resized = cv2.resize(mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        mask_1_resized = cv2.resize(mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        inverse_mask_0_resized = cv2.resize(inverse_mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        inverse_mask_1_resized = cv2.resize(inverse_mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "\n",
        "        # Overlay original image with the masks\n",
        "        blacked_out_image_0 = cv2_image * np.stack([mask_0_resized]*3, axis=-1)\n",
        "        blacked_out_image_1 = cv2_image * np.stack([mask_1_resized]*3, axis=-1)\n",
        "\n",
        "        # 黒塗り部分以外を白で塗りつぶす\n",
        "        white_blacked_out_image_0 = (inverse_mask_0_resized * 255).astype(np.uint8)\n",
        "        white_blacked_out_image_1 = (inverse_mask_1_resized * 255).astype(np.uint8)\n",
        "\n",
        "        # 2次元の白マスクを3次元に変換\n",
        "        white_blacked_out_image_0 = np.stack([white_blacked_out_image_0]*3, axis=-1)\n",
        "        white_blacked_out_image_1 = np.stack([white_blacked_out_image_1]*3, axis=-1)\n",
        "\n",
        "        # Concatenate the images\n",
        "        result = np.hstack([cv2_image, blacked_out_image_1, blacked_out_image_0, white_blacked_out_image_1, white_blacked_out_image_0])\n",
        "        cv2_imshow(result)\n"
      ],
      "metadata": {
        "id": "0eu241VBwUdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import gc  # Import garbage collector module\n",
        "\n",
        "####################################\n",
        "# Inference MobileNetV3 with 黒塗りGradCAM #\n",
        "####################################\n",
        "\"\"\"\n",
        "GradCAMの注目点を黒塗りで隠してinferenceしたときに、どのように結果が変わるかを確認\n",
        "（結果としてあまり参考にならなさそう）\n",
        "\"\"\"\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval()  # prep model for evaluation\n",
        "targets, probs, preds, misclassified_indices = [], [], [], []\n",
        "\n",
        "\n",
        "# misclassified = [17, 24, 25, 28, 68, 70, 101, 121, 200, 210, 211, 214, 215, 218, 221, 271, 291, 316, 323, 343, 344, 363, 384, 440, 448, 485, 526, 531, 544, 546, 558, 561, 568, 586, 617, 627, 629, 641, 649]\n",
        "# image_indices = misclassified\n",
        "\n",
        "#image_indices = list(range(0, 665))\n",
        "image_indices = list(range(0, 3))\n",
        "for i, (img_path, img_label) in enumerate(zip(val_list, val_list_label)):\n",
        "    if i in image_indices:\n",
        "        pilr_image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        numpy_image = np.array(pilr_image)\n",
        "        cv2_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
        "        image_tensor = test_data_transforms(pilr_image)\n",
        "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        # Compute Grad-CAM for class 0\n",
        "        cam_class_0 = compute_gradcam(model_ft, image_tensor, target_class=0)\n",
        "        mask_0 = np.where(cam_class_0 > 0.5, 0, 1).astype(np.uint8)\n",
        "\n",
        "        # Compute Grad-CAM for class 1\n",
        "        cam_class_1 = compute_gradcam(model_ft, image_tensor, target_class=1)\n",
        "        mask_1 = np.where(cam_class_1 > 0.5, 0, 1).astype(np.uint8)\n",
        "\n",
        "        # Resize the masks\n",
        "        mask_0_resized = cv2.resize(mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        mask_1_resized = cv2.resize(mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "\n",
        "        # Overlay original image with the masks\n",
        "        blacked_out_image_0 = cv2_image * np.stack([mask_0_resized]*3, axis=-1)\n",
        "        blacked_out_image_1 = cv2_image * np.stack([mask_1_resized]*3, axis=-1)\n",
        "\n",
        "        # Concatenate the images\n",
        "        result = np.hstack([cv2_image, blacked_out_image_1, blacked_out_image_0])\n",
        "        cv2_imshow(result)\n",
        "\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model_ft(image_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "\n",
        "        prob = nn.Softmax(dim=1)(output)  # calculate probability\n",
        "        prob = prob[0][1].cpu().detach()  # probability of being positive\n",
        "        prob = \"{:.3f}\".format(prob.item())\n",
        "        print(f\"{i}\")\n",
        "        print(f\"{os.path.basename(img_path)}\")\n",
        "        print(f\"target: {img_label}, prob: {prob}, pred: {pred.item()}\")\n",
        "\n",
        "\n",
        "        # 黒く塗りつぶした画像をTensorに変換\n",
        "        blacked_out_tensor_0 = test_data_transforms(Image.fromarray(blacked_out_image_0)).unsqueeze(0).to(device)\n",
        "        blacked_out_tensor_1 = test_data_transforms(Image.fromarray(blacked_out_image_1)).unsqueeze(0).to(device)\n",
        "\n",
        "        # モデルで評価\n",
        "        output_0 = model_ft(blacked_out_tensor_0)\n",
        "        _, pred_0 = torch.max(output_0, 1)\n",
        "\n",
        "        prob_0 = nn.Softmax(dim=1)(output_0)\n",
        "        prob_0 = prob_0[0][1].cpu().detach()\n",
        "        prob_0 = \"{:.3f}\".format(prob_0.item())\n",
        "\n",
        "        output_1 = model_ft(blacked_out_tensor_1)\n",
        "        _, pred_1 = torch.max(output_1, 1)\n",
        "\n",
        "        prob_1 = nn.Softmax(dim=1)(output_1)\n",
        "        prob_1 = prob_1[0][1].cpu().detach()\n",
        "        prob_1 = \"{:.3f}\".format(prob_1.item())\n",
        "\n",
        "        # 結果を出力\n",
        "        print(f\"Blacked-out image (Class 1): prob: {prob_1}, pred: {pred_1.item()}\")\n",
        "        print(f\"Blacked-out image (Class 0): prob: {prob_0}, pred: {pred_0.item()}\")\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "        # Append results\n",
        "        probs.append(float(prob))  # predicted probability\n",
        "        preds.append(int(pred))  # predicted result\n",
        "        targets.append(int(img_label))  # label\n",
        "\n",
        "        if int(pred) != int(img_label):\n",
        "            misclassified_indices.append(i)\n",
        "\n",
        "        # Cleanup\n",
        "        del pilr_image, numpy_image, cv2_image, image_tensor, cam_class_0, cam_class_1\n",
        "        gc.collect()  # Run garbage collector\n",
        "\n",
        "y_label = np.array(targets)\n",
        "y_pred = np.array(preds)\n",
        "y_prob = np.array(probs)\n",
        "print(f\"misclassified_indices: {misclassified_indices}\")"
      ],
      "metadata": {
        "id": "wCvSB8X5OOkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import gc  # Import garbage collector module\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "\n",
        "####################################\n",
        "## Comparison GradCAM vs Periocular area ##\n",
        "####################################\n",
        "\"\"\"\n",
        "Protocol:\n",
        "GradCAMで提示された関心領域のマスクと、HaarCascadeで検出された眼周囲（縦はそのまま、横は幅を半分にした長方形）との重複領域を計算する。\n",
        "GradCAMについてはGravと判定する場合とContと判定する場合とで両方とも計算を行う。\n",
        "重複領域がGrav>Contであればmask_diagnosis = \"Grav\"、重複領域がGrav<Contであればmask_diagnosis = \"Cont\"とする。\n",
        "\"\"\"\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval()  # prep model for evaluation\n",
        "targets, probs, preds, misclassified_indices = [], [], [], []\n",
        "\n",
        "misclassified = [17, 24, 25, 28, 68, 70, 101, 121, 200, 210, 211, 214, 215, 218, 221, 271, 291, 316, 323, 343, 344, 363, 384, 440, 448, 485, 526, 531, 544, 546, 558, 561, 568, 586, 617, 627, 629, 641, 649]\n",
        "image_indices = misclassified\n",
        "\n",
        "for i, (img_path, img_label) in enumerate(zip(val_list, val_list_label)):\n",
        "    if i in image_indices:\n",
        "        pilr_image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        numpy_image = np.array(pilr_image)\n",
        "        cv2_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
        "        image_tensor = test_data_transforms(pilr_image)\n",
        "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        # Inference of classification\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model_ft(image_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "\n",
        "        prob = nn.Softmax(dim=1)(output)  # calculate probability\n",
        "        prob = prob[0][1].cpu().detach()  # probability of being positive\n",
        "        prob = \"{:.3f}\".format(prob.item())\n",
        "        print(f\"{i}\")\n",
        "        print(f\"{os.path.basename(img_path)}\")\n",
        "        print(f\"target: {img_label}, prob: {prob}, pred: {pred.item()}\")\n",
        "\n",
        "        # Compute Grad-CAM for class 0\n",
        "        cam_class_0 = compute_gradcam(model_ft, image_tensor, target_class=0)\n",
        "        mask_0 = np.where(cam_class_0 > 0.5, 1, 0).astype(np.uint8)\n",
        "\n",
        "        # Compute Grad-CAM for class 1\n",
        "        cam_class_1 = compute_gradcam(model_ft, image_tensor, target_class=1)\n",
        "        mask_1 = np.where(cam_class_1 > 0.5, 1, 0).astype(np.uint8)\n",
        "\n",
        "        # 既存のマスクを反転させる\n",
        "        inverse_mask_0 = np.where(cam_class_0 > 0.5, 1, 0).astype(np.uint8)\n",
        "        inverse_mask_1 = np.where(cam_class_1 > 0.5, 1, 0).astype(np.uint8)\n",
        "\n",
        "        # マスクをリサイズ\n",
        "        mask_0_resized = cv2.resize(mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        mask_1_resized = cv2.resize(mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        inverse_mask_0_resized = cv2.resize(inverse_mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        inverse_mask_1_resized = cv2.resize(inverse_mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "\n",
        "\n",
        "        #####眼周囲のマスクを作成する\n",
        "        def crop_bilateral(in_path, class_num, showImage=False):\n",
        "            img_resized_list, side_list = [], []\n",
        "\n",
        "            img = cv2.imread(in_path)\n",
        "            img2 = img.copy()\n",
        "\n",
        "            # Convert to grayscale for eye detection\n",
        "            grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            # Create a black mask of the same size as the grayscale image\n",
        "            mask = np.zeros_like(grayscale_img)\n",
        "\n",
        "            # Detect eyes\n",
        "            eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(40, 40))\n",
        "            #print(\"\\nimage path = \", in_path)\n",
        "\n",
        "            if len(eye_list) >= 1:\n",
        "                #print('目が' + str(len(eye_list)) + '個検出されました')\n",
        "                for (x, y, w, h) in eye_list:\n",
        "                    # Fill the detected eye region with value 255\n",
        "                    mask[y:y+h, int(x+w/4):int(x+3*w/4)] = 255\n",
        "            else:\n",
        "                print(\"no eye detected\")\n",
        "\n",
        "            #print(f\"eye_list: {eye_list}\")\n",
        "\n",
        "            # Show the mask if required using matplotlib for inline display in Colab\n",
        "            if showImage:\n",
        "                plt.imshow(mask, cmap='gray')\n",
        "                plt.axis('off')  # Hide axis\n",
        "                plt.show()\n",
        "\n",
        "            return mask\n",
        "\n",
        "        # Assuming you have initialized eye_cascade before\n",
        "        # eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "        test_path = img_path\n",
        "        periocular_mask =crop_bilateral(test_path, class_num=0)\n",
        "\n",
        "\n",
        "        def show_list_in_numpy(py_list):\n",
        "            # リストをNumPyの配列に変換\n",
        "            np_array = np.array(py_list)\n",
        "            # NumPyの表示オプションを変更\n",
        "            np.set_printoptions(threshold=np.inf)\n",
        "            print(np_array)\n",
        "\n",
        "        #####ここまで\n",
        "\n",
        "        # For inverse_mask_0 and mask\n",
        "        common_mask_0 = cv2.bitwise_and(inverse_mask_0_resized, periocular_mask)\n",
        "\n",
        "        # For inverse_mask_1 and mask\n",
        "        common_mask_1 = cv2.bitwise_and(inverse_mask_1_resized, periocular_mask)\n",
        "\n",
        "        # Overlay original image with the masks\n",
        "        blacked_out_image_0 = cv2_image * np.stack([mask_0_resized]*3, axis=-1)\n",
        "        blacked_out_image_1 = cv2_image * np.stack([mask_1_resized]*3, axis=-1)\n",
        "\n",
        "        # 黒塗り部分以外を白で塗りつぶす\n",
        "        white_blacked_out_image_0 = (inverse_mask_0_resized * 255).astype(np.uint8)\n",
        "        white_blacked_out_image_1 = (inverse_mask_1_resized * 255).astype(np.uint8)\n",
        "\n",
        "        # 2次元の白マスクを3次元に変換\n",
        "        white_blacked_out_image_0 = np.stack([white_blacked_out_image_0]*3, axis=-1)\n",
        "        white_blacked_out_image_1 = np.stack([white_blacked_out_image_1]*3, axis=-1)\n",
        "\n",
        "        # Convert the common masks to 3-channel images for visualization\n",
        "        common_mask_0 = np.stack([common_mask_0]*3, axis=-1) * 255\n",
        "        common_mask_1 = np.stack([common_mask_1]*3, axis=-1) * 255\n",
        "\n",
        "        # Calculate the areas\n",
        "        area_common_mask_0 = np.sum(common_mask_0) / 255\n",
        "        area_common_mask_1 = np.sum(common_mask_1) / 255\n",
        "        # Determine the mask_diagnosis based on the areas\n",
        "        mask_diagnosis = 0 if area_common_mask_0 > area_common_mask_1 else 1\n",
        "\n",
        "        print(f\"mask_diagnosis = {mask_diagnosis}\")\n",
        "\n",
        "\n",
        "        # Concatenate the images\n",
        "        result = np.hstack([cv2_image, blacked_out_image_1, blacked_out_image_0, white_blacked_out_image_1, white_blacked_out_image_0, common_mask_1, common_mask_0])\n",
        "\n",
        "        cv2_imshow(result)\n",
        "        print(\"\")\n"
      ],
      "metadata": {
        "id": "Mtc7lBGOdha3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import gc  # Import garbage collector module\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "\n",
        "####################################\n",
        "## Comparison GradCAM vs Periocular area ##\n",
        "####################################\n",
        "\"\"\"\n",
        "Protocol:\n",
        "GradCAMで提示された関心領域のマスクと、HaarCascadeで検出された眼周囲（縦はそのまま、横は幅を半分にした長方形）との重複領域を計算する。\n",
        "GradCAMについてはGravと判定する場合とContと判定する場合とで両方とも計算を行う。\n",
        "重複領域がGrav>Contであればmask_diagnosis = \"Grav\"、重複領域がGrav<Contであればmask_diagnosis = \"Cont\"とする。\n",
        "\"\"\"\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval()  # prep model for evaluation\n",
        "targets, probs, preds, misclassified_indices = [], [], [], []\n",
        "\n",
        "misclassified = [17, 24, 25, 28, 68, 70, 101, 121, 200, 210, 211, 214, 215, 218, 221, 271, 291, 316, 323, 343, 344, 363, 384, 440, 448, 485, 526, 531, 544, 546, 558, 561, 568, 586, 617, 627, 629, 641, 649]\n",
        "image_indices = misclassified\n",
        "\n",
        "for i, (img_path, img_label) in enumerate(zip(val_list, val_list_label)):\n",
        "    if i in image_indices:\n",
        "        pilr_image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        numpy_image = np.array(pilr_image)\n",
        "        cv2_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
        "        image_tensor = test_data_transforms(pilr_image)\n",
        "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        # Inference of classification\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model_ft(image_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "\n",
        "        prob = nn.Softmax(dim=1)(output)  # calculate probability\n",
        "        prob = prob[0][1].cpu().detach()  # probability of being positive\n",
        "        prob = \"{:.3f}\".format(prob.item())\n",
        "        print(f\"{i}\")\n",
        "        print(f\"{os.path.basename(img_path)}\")\n",
        "        print(f\"target: {img_label}, prob: {prob}, pred: {pred.item()}\")\n",
        "\n",
        "\n",
        "        # Compute Grad-CAM for class 0\n",
        "        cam_class_0 = compute_gradcam(model_ft, image_tensor, target_class=0)\n",
        "        heatmap_0 = cv2.applyColorMap(np.uint8(255 * cam_class_0), cv2.COLORMAP_JET)\n",
        "        heatmap_0 = cv2.cvtColor(heatmap_0, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Compute Grad-CAM for class 1\n",
        "        cam_class_1 = compute_gradcam(model_ft, image_tensor, target_class=1)\n",
        "        heatmap_1 = cv2.applyColorMap(np.uint8(255 * cam_class_1), cv2.COLORMAP_JET)\n",
        "        heatmap_1 = cv2.cvtColor(heatmap_1, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Resize the heatmaps\n",
        "        heatmap_0_resized = cv2.resize(heatmap_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        heatmap_1_resized = cv2.resize(heatmap_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "\n",
        "        # Overlay original image with the heatmaps\n",
        "        overlayed_image_0 = cv2.addWeighted(cv2_image, 0.5, heatmap_0_resized, 0.5, 0)\n",
        "        overlayed_image_1 = cv2.addWeighted(cv2_image, 0.5, heatmap_1_resized, 0.5, 0)\n",
        "\n",
        "\n",
        "\n",
        "        # Compute Grad-CAM for class 0\n",
        "        mask_0 = np.where(cam_class_0 > 0.5, 1, 0).astype(np.uint8)\n",
        "\n",
        "        # Compute Grad-CAM for class 1\n",
        "        mask_1 = np.where(cam_class_1 > 0.5, 1, 0).astype(np.uint8)\n",
        "\n",
        "        # 既存のマスクを反転させる\n",
        "        inverse_mask_0 = np.where(cam_class_0 > 0.5, 1, 0).astype(np.uint8)\n",
        "        inverse_mask_1 = np.where(cam_class_1 > 0.5, 1, 0).astype(np.uint8)\n",
        "\n",
        "        # マスクをリサイズ\n",
        "        mask_0_resized = cv2.resize(mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        mask_1_resized = cv2.resize(mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        inverse_mask_0_resized = cv2.resize(inverse_mask_0, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "        inverse_mask_1_resized = cv2.resize(inverse_mask_1, (cv2_image.shape[1], cv2_image.shape[0]))\n",
        "\n",
        "\n",
        "        #####眼周囲のマスクを作成する\n",
        "        def crop_bilateral(in_path, class_num, showImage=False):\n",
        "            img_resized_list, side_list = [], []\n",
        "\n",
        "            img = cv2.imread(in_path)\n",
        "            img2 = img.copy()\n",
        "\n",
        "            # Convert to grayscale for eye detection\n",
        "            grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            # Create a black mask of the same size as the grayscale image\n",
        "            mask = np.zeros_like(grayscale_img)\n",
        "\n",
        "            # Detect eyes\n",
        "            eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(40, 40))\n",
        "            #print(\"\\nimage path = \", in_path)\n",
        "\n",
        "            if len(eye_list) >= 1:\n",
        "                #print('目が' + str(len(eye_list)) + '個検出されました')\n",
        "                for (x, y, w, h) in eye_list:\n",
        "                    # Fill the detected eye region with value 255\n",
        "                    mask[y:y+h, int(x+w/4):int(x+3*w/4)] = 255\n",
        "            else:\n",
        "                print(\"no eye detected\")\n",
        "\n",
        "            #print(f\"eye_list: {eye_list}\")\n",
        "\n",
        "            # Show the mask if required using matplotlib for inline display in Colab\n",
        "            if showImage:\n",
        "                plt.imshow(mask, cmap='gray')\n",
        "                plt.axis('off')  # Hide axis\n",
        "                plt.show()\n",
        "\n",
        "            return mask\n",
        "\n",
        "        # Assuming you have initialized eye_cascade before\n",
        "        # eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "        test_path = img_path\n",
        "        periocular_mask =crop_bilateral(test_path, class_num=0)\n",
        "\n",
        "\n",
        "        def show_list_in_numpy(py_list):\n",
        "            # リストをNumPyの配列に変換\n",
        "            np_array = np.array(py_list)\n",
        "            # NumPyの表示オプションを変更\n",
        "            np.set_printoptions(threshold=np.inf)\n",
        "            print(np_array)\n",
        "\n",
        "        #####ここまで\n",
        "\n",
        "        # For inverse_mask_0 and mask\n",
        "        common_mask_0 = cv2.bitwise_and(inverse_mask_0_resized, periocular_mask)\n",
        "\n",
        "        # For inverse_mask_1 and mask\n",
        "        common_mask_1 = cv2.bitwise_and(inverse_mask_1_resized, periocular_mask)\n",
        "\n",
        "        # Overlay original image with the masks\n",
        "        blacked_out_image_0 = cv2_image * np.stack([mask_0_resized]*3, axis=-1)\n",
        "        blacked_out_image_1 = cv2_image * np.stack([mask_1_resized]*3, axis=-1)\n",
        "\n",
        "        # 黒塗り部分以外を白で塗りつぶす\n",
        "        white_blacked_out_image_0 = (inverse_mask_0_resized * 255).astype(np.uint8)\n",
        "        white_blacked_out_image_1 = (inverse_mask_1_resized * 255).astype(np.uint8)\n",
        "\n",
        "        # 2次元の白マスクを3次元に変換\n",
        "        white_blacked_out_image_0 = np.stack([white_blacked_out_image_0]*3, axis=-1)\n",
        "        white_blacked_out_image_1 = np.stack([white_blacked_out_image_1]*3, axis=-1)\n",
        "\n",
        "        # Convert the common masks to 3-channel images for visualization\n",
        "        common_mask_0 = np.stack([common_mask_0]*3, axis=-1) * 255\n",
        "        common_mask_1 = np.stack([common_mask_1]*3, axis=-1) * 255\n",
        "\n",
        "        # Calculate the areas\n",
        "        area_common_mask_0 = np.sum(common_mask_0) / 255\n",
        "        area_common_mask_1 = np.sum(common_mask_1) / 255\n",
        "        # Determine the mask_diagnosis based on the areas\n",
        "        mask_diagnosis = 0 if area_common_mask_0 > area_common_mask_1 else 1\n",
        "\n",
        "        print(f\"mask_diagnosis = {mask_diagnosis}\")\n",
        "\n",
        "\n",
        "        # Concatenate the images\n",
        "        result = np.hstack([cv2_image, overlayed_image_1, overlayed_image_0, white_blacked_out_image_1, white_blacked_out_image_0, common_mask_1, common_mask_0])\n",
        "\n",
        "        cv2_imshow(result)\n",
        "        print(\"\")\n"
      ],
      "metadata": {
        "id": "ap-a6G9ou27W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "####. HaarCascadeのテスト用 #####\n",
        "###########################\n",
        "\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def crop_bilateral(in_path, class_num, showImage=True):\n",
        "#     img_resized_list, side_list = [], []\n",
        "\n",
        "#     img = cv2.imread(in_path)\n",
        "#     img2 = img.copy()\n",
        "\n",
        "#     # Convert to grayscale for eye detection\n",
        "#     grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "#     # Create a black mask of the same size as the grayscale image\n",
        "#     mask = np.zeros_like(grayscale_img)\n",
        "\n",
        "#     # Detect eyes\n",
        "#     eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(40, 40))\n",
        "#     print(\"\\nimage path = \", in_path)\n",
        "\n",
        "#     if len(eye_list) >= 1:\n",
        "#         print('目が' + str(len(eye_list)) + '個検出されました')\n",
        "#         for (x, y, w, h) in eye_list:\n",
        "#             # Fill the detected eye region with value 255\n",
        "#             mask[y:y+h, int(x+w/4):int(x+3*w/4)] = 255\n",
        "#     else:\n",
        "#         print(\"no eye detected\")\n",
        "\n",
        "#     print(f\"eye_list: {eye_list}\")\n",
        "\n",
        "#     # Show the mask if required using matplotlib for inline display in Colab\n",
        "#     if showImage:\n",
        "#         plt.imshow(mask, cmap='gray')\n",
        "#         plt.axis('off')  # Hide axis\n",
        "#         plt.show()\n",
        "\n",
        "#     return mask\n",
        "\n",
        "# # Assuming you have initialized eye_cascade before\n",
        "# eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "# # Test\n",
        "# # Assuming val_list and class_num are previously defined\n",
        "# test_path = val_list[0]\n",
        "# crop_bilateral(test_path, class_num=0)\n"
      ],
      "metadata": {
        "id": "0G6x2rv9WnIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "# Interference MobileNetV3 (GradCAMなしバージョン)#\n",
        "########################################\n",
        "\n",
        "#define dataset and dataloader\n",
        "test_dataset = SimpleImageDataset(val_list, val_list_label, test_data_transforms)\n",
        "test_loader = DataLoader(val_dataset, batch_size = 1, shuffle = False, pin_memory=True, num_workers=0) #val_datasetを1枚ずつにしてtest_loadeerに格納\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval() # prep model for evaluation\n",
        "targets, probs, preds =[], [], []\n",
        "for image_tensor, target in test_loader:\n",
        "      #target = target.squeeze(1)\n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model_ft(image_tensor)\n",
        "      _, pred = torch.max(output, 1)\n",
        "\n",
        "      prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "      prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "      prob = \"{:.3f}\".format(prob.item())\n",
        "      print(f\"target: {target.item()}, prob: {prob}, pred: {pred.item()}\")\n",
        "\n",
        "\n",
        "      probs.append(float(prob)) #予測確率\n",
        "      preds.append(int(pred))  #予測結果\n",
        "      targets.append(int(target)) #ラベル\n",
        "y_label = np.array(targets)\n",
        "y_pred = np.array(preds)\n",
        "y_prob = np.array(probs)"
      ],
      "metadata": {
        "id": "QvHusSc_-3iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference MobileNet3"
      ],
      "metadata": {
        "id": "XvjkKZez_IrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc  # Import garbage collector module\n",
        "import os\n",
        "\n",
        "######################################\n",
        "# Inference MobileNetV3 ※GradCAMなし#\n",
        "######################################\n",
        "\n",
        "model_ft.to(device)\n",
        "model_ft.eval()  # prep model for evaluation\n",
        "paths, targets, probs, preds = [], [], [], []\n",
        "\n",
        "image_indices = list(range(0, 665))\n",
        "for i, (img_path, img_label) in enumerate(zip(val_list, val_list_label)):\n",
        "    if i in image_indices:\n",
        "        pilr_image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Convert the PIL Image to numpy array\n",
        "        numpy_image = np.array(pilr_image)\n",
        "        cv2_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)\n",
        "        image_tensor = test_data_transforms(pilr_image)\n",
        "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model_ft(image_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "\n",
        "        prob = nn.Softmax(dim=1)(output)  # calculate probability\n",
        "        prob = prob[0][1].cpu().detach()  # probability of being positive\n",
        "        prob = \"{:.3f}\".format(prob.item())\n",
        "        print(f\"{os.path.basename(img_path)}\")\n",
        "        print(f\"target: {img_label}, prob: {prob}, pred: {pred.item()}\")\n",
        "        print(\"\")\n",
        "\n",
        "        # Append results\n",
        "        paths.append(str(os.path.basename(img_path)))\n",
        "        probs.append(float(prob))  # predicted probability\n",
        "        preds.append(int(pred))  # predicted result\n",
        "        targets.append(int(img_label))  # label\n",
        "\n",
        "        # Cleanup\n",
        "        del pilr_image, numpy_image, cv2_image, image_tensor\n",
        "        gc.collect()  # Run garbage collector\n",
        "\n",
        "y_label = np.array(targets)\n",
        "y_pred = np.array(preds)\n",
        "y_prob = np.array(probs)\n",
        "print(f\"misclassified_indices: {misclassified_indices}\")"
      ],
      "metadata": {
        "id": "JFL4WogdahVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'paths': paths,\n",
        "    'Target': y_label,\n",
        "    'Probability': y_prob,\n",
        "    'Prediction': y_pred\n",
        "})\n",
        "pd.set_option('display.max_rows', 700)\n",
        "\n",
        "file_path = \"/content/result_list.csv\"\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "hbDCHbieT3Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_label\n",
        "y_pred\n",
        "y_prob"
      ],
      "metadata": {
        "id": "E0BPaOqaEnM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft"
      ],
      "metadata": {
        "id": "itGmZ613_5LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# #################################################\n",
        "# threshold = 0.5 #判定基準。ここは先に入力しておく\n",
        "# #################################################\n",
        "\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "#TP_list, FN_list, FP_list, FN_list = [], [], [], []\n",
        "#confusion_list = [[] for i in range(4)]  #[[TP],[FN],[FP],[FN]]\n",
        "confusion_arr = np.zeros((2,2))\n",
        "\n",
        "\n",
        "# X = y_prob\n",
        "# Y = y_label\n",
        "\n",
        "# Y_pred_proba = X\n",
        "# Y_pred = np.where(Y_pred_proba >= threshold, 1, 0)\n",
        "\n",
        "acc = accuracy_score(y_label, y_pred)\n",
        "print('Accuracy:',acc)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_label, y_pred).ravel()\n",
        "print(tp, fn, fp, tn)\n",
        "\n",
        "def specificity_score(label, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "print('confusion matrix = \\n', confusion_matrix(y_label, y_pred))\n",
        "print(f'Accuracy : {accuracy_score(y_label, y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(y_label, y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(y_label, y_pred)}')\n",
        "print(f'Specificity : {specificity_score(y_label, y_pred)}')\n",
        "print(f'F1 score : {f1_score(y_label, y_pred)}')\n",
        "\n",
        "#ROC curve\n",
        "\n",
        "# Compute the ROC curve values\n",
        "fpr, tpr, thresholds = roc_curve(y_label, y_prob)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc_score(y_label, y_prob):.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# fpr, tpr, thresholds = roc_curve(y_label, y_pred)\n",
        "# plt.plot(fpr, tpr, marker='o')\n",
        "# plt.xlabel('FPR')\n",
        "# plt.ylabel('TPR')\n",
        "# plt.grid()\n",
        "# print(f'Area_under_ROC : {roc_auc_score(y_label, y_pred)}')\n",
        "#plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "accuracy.append(accuracy_score(y_label, y_pred))\n",
        "precision.append(precision_score(y_label, y_pred))\n",
        "recall.append(recall_score(y_label, y_pred))\n",
        "specificity.append(specificity_score(y_label, y_pred))\n",
        "f1score.append(f1_score(y_label, y_pred))\n",
        "area_u_ROC.append(roc_auc_score(y_label, y_pred))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# confusion matrixをheatmapで表示\n",
        "cm = confusion_matrix(y_label, y_pred, labels=[1, 0])\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False,\n",
        "            xticklabels=['TED', 'control'],\n",
        "            yticklabels=['TED', 'control'])\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1CAhawNTE8k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Export MobileNetV3 model to CoreML**"
      ],
      "metadata": {
        "id": "2HaYNrrUvioo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# Output as CoreML\n",
        "###########################\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "!pip install --quiet coremltools\n",
        "import coremltools as ct\n",
        "\n",
        "# Load a pre-trained version of MobileNetV3\n",
        "class TorchClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchClassificationModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            model_ft,\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "# Set the model in evaluation mode\n",
        "torch_model = TorchClassificationModel().eval()\n",
        "torch_model = torch_model.to(\"cpu\")\n",
        "\n",
        "\n",
        "# Trace with random data\n",
        "example_input = torch.rand(1, 3, 224, 224) # after test, will get 'size mismatch' error message with size 256x256\n",
        "traced_model = torch.jit.trace(torch_model, example_input)\n",
        "\n",
        "\n",
        "# Download class labels (from a separate file)\n",
        "#import urllib\n",
        "#label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "#class_labels = urllib.request.urlopen(label_url).read().decode(\"utf-8\").splitlines()\n",
        "class_labels = [\"cont\", \"grav\"]\n",
        "\n",
        "\n",
        "\n",
        "# Convert to Core ML using the Unified Conversion API\n",
        "# mlmodel = ct.convert(\n",
        "#     traced_model,\n",
        "#     inputs=[ct.ImageType(name=\"input_1\", shape=example_input.shape)], #name \"input_1\" is used in 'quickstart'\n",
        "#     classifier_config = ct.ClassifierConfig(class_labels) # provide only if step 2 was performed\n",
        "# )\n",
        "\n",
        "\n",
        "#Set the image scale and bias for input image preprocessing.\n",
        "scale = 1.0 / (255.0 * 0.226)\n",
        "red_bias = -0.485 / 0.226\n",
        "green_bias = -0.456 / 0.226\n",
        "blue_bias = -0.406 / 0.226\n",
        "\n",
        "mlmodel = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[ct.ImageType(name=\"input_1\", shape=example_input.shape, scale=scale, bias=[red_bias, green_bias, blue_bias])],\n",
        "    classifier_config=ct.ClassifierConfig(class_labels)\n",
        ")\n",
        "\n",
        "# Save model\n",
        "model_parent_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/250px_for_MobileNetV3_training\"\n",
        "mlmodel.save(f\"{model_parent_path}/MobileNetV3_extended.mlmodel\")\n"
      ],
      "metadata": {
        "id": "Hp2FOqU89Qgh",
        "outputId": "852987b9-62c5-4da4-de93-4fa915bad38e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 467/468 [00:00<00:00, 2854.09 ops/s]\n",
            "Running MIL Common passes: 100%|██████████| 40/40 [00:00<00:00, 76.30 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 11/11 [00:00<00:00, 127.54 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 665/665 [00:00<00:00, 1664.59 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SpdWnl0EhsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WcHCKuiscqHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YPUmFvYREXMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nCSPS2omEXKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcDbxC9OEXG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lIgEoaLwEWsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Make folders for YOLO5 training**"
      ],
      "metadata": {
        "id": "Wmgd-xTbxFMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLOv5トレーニング用\n",
        "#もしdst_folderがあれば削除して新しく作り直す\n",
        "dst_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\"\n",
        "\n",
        "if os.path.exists(dst_folder):\n",
        "    shutil.rmtree(dst_folder)\n",
        "for i in [\"train\", \"valid\"]:\n",
        "    for j in [\"images\", \"labels\"]:\n",
        "        os.makedirs(f\"{dst_folder}/{i}/{j}\")\n",
        "        #os.makedirs(f\"{dst_folder}/labels\")\n",
        "\n",
        "for file in img_train[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/images/{os.path.basename(file)}\")\n",
        "for file in img_val[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/images/{os.path.basename(file)}\")\n",
        "for file in label_train[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/train/labels/{os.path.basename(file)}\")\n",
        "for file in label_val[0]:\n",
        "    shutil.copy(file, f\"{dst_folder}/valid/labels/{os.path.basename(file)}\")\n"
      ],
      "metadata": {
        "id": "lKe9k8SirUGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $dst_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAUdjy9A0YZw",
        "outputId": "5d8631eb-b096-471d-96c5-0f3913a7ff55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset.yaml\n",
        "# path\n",
        "train: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\n",
        "val: /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images\n",
        "\n",
        "# num of classes\n",
        "nc: 2\n",
        "\n",
        "#class names\n",
        "names: ['cont', 'grav'] # class名を定義"
      ],
      "metadata": {
        "id": "giDFflceMi9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e0bdb6-f54e-47f9-e9f4-413245975212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Setup YOLOv5**"
      ],
      "metadata": {
        "id": "cdEoEk_996YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjV_xXLpd5__",
        "outputId": "476d809b-269b-4cd6-a0fe-82f4da46dd53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (12 CPUs, 83.5 GB RAM, 31.0/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Train YOLOv5**"
      ],
      "metadata": {
        "id": "shiv0uvTdH7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "!python train.py --img 640 --batch 16 --epochs 100 --data /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/dataset.yaml --weights yolov5n.pt\n"
      ],
      "metadata": {
        "id": "spn1bRX60hYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best.pyをrenameしてgdriveに移動しておく\n",
        "orig_pt = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolov5/runs/train/exp/weights/best.pt\"\n",
        "dst_pt = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "shutil.copy(orig_pt, dst_pt)"
      ],
      "metadata": {
        "id": "2_mRrhFn-ONj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "951a6753-9a5b-4e71-e026-7416d32bcc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv5 Intereference**"
      ],
      "metadata": {
        "id": "kX9AdOK31h1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference (folder内全部)\n",
        "!python detect.py --weights /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt --img 640 --conf 0.25 --source /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images"
      ],
      "metadata": {
        "id": "Du5NiwCDdTcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid = os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images\")\n",
        "train = os.listdir(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\")\n",
        "\n",
        "print(len(train), len(valid))"
      ],
      "metadata": {
        "id": "oA6h6A4u_K7Z",
        "outputId": "430d02b5-7a51-42f0-f012-cd33f4d3178c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2649 664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interference (per image)\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt\"\n",
        "image_path = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/*\")\n",
        "img = image_path[100]"
      ],
      "metadata": {
        "id": "jmg05lZkDKnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt --img 640 --conf 0.25 --source $img"
      ],
      "metadata": {
        "id": "mQxqh5QMDrYR",
        "outputId": "66105c9d-2766-4fff-ef56-107bb88cda87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt'], source=/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/6540.JPG, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1761871 parameters, 0 gradients, 4.1 GFLOPs\n",
            "image 1/1 /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/6540.JPG: 448x640 1 grav, 18.4ms\n",
            "Speed: 0.7ms pre-process, 18.4ms inference, 38.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    print(img_tensor.shape)\n",
        "\n",
        "    print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "mLCs5mn32MvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/gravcont_yolo5n.pt\"\n",
        "image_path = glob.glob(\"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid/images/*\")\n",
        "img = image_path[2]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, weight)\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"診断は %s、確率は%.1f％です。\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img)\n",
        "cv2_imshow(img_cv2)\n"
      ],
      "metadata": {
        "id": "54vbyhSR-EY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference Olympia dataset**"
      ],
      "metadata": {
        "id": "uzZr3wMsrxJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "cpKHAnmE_wFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f69277f-119c-41dc-d348-1bccda7d470d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (12 CPUs, 83.5 GB RAM, 24.9/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "\n",
        "# 横幅を640pxにリサイズしたデータセット\n",
        "dataset_grav = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/treated_640px\"\n",
        "dataset_cont = \"/content/drive/MyDrive/Deep_learning/Olympia_dataset/untreated_640px\""
      ],
      "metadata": {
        "id": "CrVmlh1Csdxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    device = 'cpu'\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "VPTVErBetQT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = glob.glob(f\"{dataset_grav}/*\")\n",
        "img = image_path[100]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "pred = interference(img, weight)\n",
        "\n",
        "# output result\n",
        "x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "# probability\n",
        "prob = pred[0][0][4].item()\n",
        "\n",
        "# class\n",
        "class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "print(\"診断は %s、確率は%.1f％です。\" %(class_name, prob*100))\n",
        "\n",
        "img_cv2 = cv2.imread(img)\n",
        "\n",
        "# calculate coordinates of the bounding box (640*640にpaddingされている分の座標を足す)\n",
        "img_height, img_width, _ = img_cv2.shape[:3]\n",
        "print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "padding_x = (img_height - min(img_width, img_height))/2\n",
        "padding_y = (img_width - min(img_width, img_height))/2\n",
        "x1 = x1 - padding_x\n",
        "y1 = y1 - padding_y\n",
        "x2 = x2 - padding_x\n",
        "y2 = y2 - padding_y\n",
        "print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "\n",
        "# draw bounding box\n",
        "cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "\n",
        "# show image\n",
        "cv2_imshow(img_cv2)"
      ],
      "metadata": {
        "id": "_NeSLz6rtalH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Export coreML including non-max supression**"
      ],
      "metadata": {
        "id": "g7JhasvF89PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone Yolov5 repo\n",
        "import os\n",
        "%cd /content\n",
        "!git clone https://github.com/hietalajulius/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt -r requirements-export.txt"
      ],
      "metadata": {
        "id": "E7CfdEw-ylvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_path = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\""
      ],
      "metadata": {
        "id": "9uFOe6N9Aiwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python export-nms.py --include coreml --weights $weight_path\n"
      ],
      "metadata": {
        "id": "tBf-4p1BArEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference and crop Extended dataset**"
      ],
      "metadata": {
        "id": "mMbAS9qBSXsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup YOLOv5\n",
        "%cd /content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "argQTM34hQEI",
        "outputId": "0f8f99ad-cf66-430e-f771-1741a546d52f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (12 CPUs, 83.5 GB RAM, 24.9/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# パスを指定する\n",
        "weight = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/yolo5n_100epoch.pt\"\n",
        "input_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train/images\"\n",
        "output_folder = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/train\""
      ],
      "metadata": {
        "id": "SK0LQ6a7hpmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.common import DetectMultiBackend\n",
        "#from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
        "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,\n",
        "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
        "#from utils.plots import Annotator, colors, save_one_box\n",
        "from utils.torch_utils import select_device, time_sync\n",
        "from utils.augmentations import letterbox #padding\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def interference(img, weight):\n",
        "    #stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\n",
        "    #imgsz = check_img_size([640], s=stride)  # check image size\n",
        "\n",
        "    #class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "    # transform = transforms.Compose([\n",
        "    #             transforms.Resize(size=(480,640)),\n",
        "    #             transforms.ToTensor(),\n",
        "    #             # transforms.Normalize(\n",
        "    #             #     mean=[0.5, 0.5, 0.5],\n",
        "    #             #     std=[0.5, 0.5, 0.5]\n",
        "    #             #    )\n",
        "    #             ])\n",
        "\n",
        "    img_cv2 = cv2.imread(img) #CV2で開く\n",
        "    img_cv2 = letterbox(img_cv2, (640,640), stride=32, auto=False)[0] #resize, 上下padding (color 114)\n",
        "\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    img_cv2 = img_cv2.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img_cv2 = np.ascontiguousarray(img_cv2)\n",
        "    img_tensor = torch.from_numpy(img_cv2).float()\n",
        "\n",
        "    #img_tensor = transform(img_np)\n",
        "    img_tensor /= 255\n",
        "    #print(img_tensor.shape)\n",
        "\n",
        "    #print(img_tensor)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)  # バッチ対応\n",
        "\n",
        "\n",
        "    pred = model(img_tensor, visualize=False, augment=False)\n",
        "\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None,  max_det=1000)\n",
        "\n",
        "    print(f\"pred: {pred}\")\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "6qZSIfF5hjGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# image_path = glob.glob(f\"{dataset_grav}/*\")\n",
        "# img = image_path[100]\n",
        "\n",
        "class_names = {0:\"cont\", 1:\"grav\"}\n",
        "\n",
        "device = 'cpu' # device = None or 'cpu' or 0 or '0' or '0,1,2,3'\n",
        "device = select_device(device)\n",
        "model = DetectMultiBackend(weight, device=device, dnn=False)\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for img in tqdm(glob.glob(f\"{input_folder}/*\")):\n",
        "\n",
        "    pred = interference(img, weight)\n",
        "\n",
        "    # output result\n",
        "    x1, y1, x2, y2, prob, class_num = torch.round(pred[0][0])\n",
        "\n",
        "    # probability\n",
        "    prob = pred[0][0][4].item()\n",
        "\n",
        "    # class\n",
        "    class_name = class_names[pred[0][0][5].item()]\n",
        "\n",
        "    print(\"診断は %s、確率は%.1f％です。\" %(class_name, prob*100))\n",
        "\n",
        "    img_cv2 = cv2.imread(img)\n",
        "\n",
        "    # calculate coordinates of the bounding box (640*640にpaddingされている分の座標を足す)\n",
        "    img_height, img_width, _ = img_cv2.shape[:3]\n",
        "    print(f\"img_height: {img_height}, img_width: {img_width}\")\n",
        "    padding_x = (img_height - min(img_width, img_height))/2\n",
        "    padding_y = (img_width - min(img_width, img_height))/2\n",
        "    x1 = x1 - padding_x\n",
        "    y1 = y1 - padding_y\n",
        "    x2 = x2 - padding_x\n",
        "    y2 = y2 - padding_y\n",
        "    print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}\")\n",
        "\n",
        "    # draw bounding box\n",
        "    #cv2.rectangle(img_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "\n",
        "    # show image\n",
        "    #cv2_imshow(img_cv2)\n",
        "\n",
        "    # バウンディングボックスで画像を切り抜く」\n",
        "\n",
        "    if x1 < 0: #負の場合のエラー回避\n",
        "        x1 = 0\n",
        "\n",
        "    cropped_image = img_cv2[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "    # 切り抜いた画像を保存する\n",
        "    save_path = f\"{output_folder}/{os.path.basename(img)}\"\n",
        "    print(save_path)\n",
        "    #cv2_imshow(cropped_image)\n",
        "    cv2.imwrite(save_path, cropped_image)"
      ],
      "metadata": {
        "id": "iJqs6HmydRUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rewrite csv file (bootcamp用csvのimage_pathを改変)\n",
        "import pandas as pd\n",
        "\n",
        "csv_1_orig = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/train_list.csv\"\n",
        "csv_2_orig = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_for_YOLO_training/valid_list.csv\"\n",
        "csv_1 = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/train_list.csv\"\n",
        "csv_2 = \"/content/drive/MyDrive/Deep_learning/GO_extended_dataset/periocular_cropped_using_YOLO/valid_list.csv\"\n",
        "\n",
        "def rewrite_csv(df):\n",
        "    path_list = []\n",
        "    for path in df[\"image_path\"]:\n",
        "        path = path.replace(\"periocular_for_YOLO_training\", \"periocular_cropped_using_YOLO\")\n",
        "        path = path.replace(\"images/\", \"\")\n",
        "        path_list.append(path)\n",
        "    df[\"image_path\"] = path_list\n",
        "    return(df)\n",
        "\n",
        "df = pd.read_csv(csv_1_orig)\n",
        "df = rewrite_csv(df)\n",
        "print(df)\n",
        "df.to_csv(csv_1, index=False)\n",
        "\n",
        "df = pd.read_csv(csv_2_orig)\n",
        "df = rewrite_csv(df)\n",
        "df.to_csv(csv_2,  index=False)"
      ],
      "metadata": {
        "id": "z9kG4PiPlCyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Js-kBmr0vhqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ln9uTV9Nvhrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwPGcLe_vhu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}